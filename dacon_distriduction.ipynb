{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lightGBM_서은유 (최종) .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "60dcabebc96244059220d7e19c470375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_16086f28743349f09da0ad782b1fab4d",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a734d1ffc6dc4564b417687cc070864c"
          }
        },
        "16086f28743349f09da0ad782b1fab4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a734d1ffc6dc4564b417687cc070864c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cac1fe8f6a4d4b469521578446d0e17b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_be4edfab24ca4f4abf0ffd6085a24c2c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "TextModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Following data types have been inferred automatically, if they are correct press enter to continue or type 'quit' otherwise.",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d142a8332f5b4c8699924a3749bae888"
          }
        },
        "be4edfab24ca4f4abf0ffd6085a24c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d142a8332f5b4c8699924a3749bae888": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9792ece81a2d498996878f71cfaed252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dfe76d4533cf4117805652f41cbdce8a",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 104,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 104,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5f49579932340a8936a43a6a898f1d2"
          }
        },
        "dfe76d4533cf4117805652f41cbdce8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5f49579932340a8936a43a6a898f1d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c07c35b3c62542eba933b6805aed0465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7c23aa20206b48c5bdc971a30f14bc85",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 6,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0691a3aa2d8949ec81ab1d6cdfe0da83"
          }
        },
        "7c23aa20206b48c5bdc971a30f14bc85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0691a3aa2d8949ec81ab1d6cdfe0da83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 라이브러리, 데이터 불러오기"
      ],
      "metadata": {
        "id": "KnSBDDsVKyxn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1TOAgeO3qqK",
        "outputId": "66b48af1-704c-4e0b-ddb8-cf2aea39673b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 드라이브 연결\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 불러오기\n",
        "import lightgbm as lgb\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6Mw0AwRl4RN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1146faf-2214-4e77-ae91-fb8a8ed993f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "path='/content/drive/MyDrive/BOAZ/물류 유통량 예측 경진대회/'\n",
        "data = pd.read_csv(path+'train.csv')\n",
        "test = pd.read_csv(path+'test.csv')\n",
        "sample = pd.read_csv(path+'sample_submission.csv')"
      ],
      "metadata": {
        "id": "bjNBkw1o4aoJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = pd.read_csv(path+'sample_submission.csv')"
      ],
      "metadata": {
        "id": "lx-nG2QHx5k3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "54qtmMHJx64h",
        "outputId": "9e15ffda-5219-4aff-e28c-160703482d02"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a6df900b-f2c8-41a4-866c-8e0e1cb5d9d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>운송장_건수</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7915</th>\n",
              "      <td>7915</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7916</th>\n",
              "      <td>7916</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7917</th>\n",
              "      <td>7917</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7918</th>\n",
              "      <td>7918</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7919</th>\n",
              "      <td>7919</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7920 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6df900b-f2c8-41a4-866c-8e0e1cb5d9d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6df900b-f2c8-41a4-866c-8e0e1cb5d9d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6df900b-f2c8-41a4-866c-8e0e1cb5d9d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      index  운송장_건수\n",
              "0         0       0\n",
              "1         1       0\n",
              "2         2       0\n",
              "3         3       0\n",
              "4         4       0\n",
              "...     ...     ...\n",
              "7915   7915       0\n",
              "7916   7916       0\n",
              "7917   7917       0\n",
              "7918   7918       0\n",
              "7919   7919       0\n",
              "\n",
              "[7920 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "BQZK_8-w4ocX",
        "outputId": "d17c0910-aafe-4ab2-c6bc-00675609954a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-73143bbf-871a-48be-a98d-4860d3caaf2f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>송하인_격자공간고유번호</th>\n",
              "      <th>수하인_격자공간고유번호</th>\n",
              "      <th>물품_카테고리</th>\n",
              "      <th>운송장_건수</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5011000595017300</td>\n",
              "      <td>2871000192069300</td>\n",
              "      <td>음반</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4148000690043300</td>\n",
              "      <td>5011000264024400</td>\n",
              "      <td>문화컨텐츠</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5011000078068400</td>\n",
              "      <td>1120000007005400</td>\n",
              "      <td>농산물</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4127100048006400</td>\n",
              "      <td>5011000587019400</td>\n",
              "      <td>기타식품</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5011000078068400</td>\n",
              "      <td>2823700010076300</td>\n",
              "      <td>농산물</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31679</th>\n",
              "      <td>31679</td>\n",
              "      <td>4471000290087200</td>\n",
              "      <td>5011000213073200</td>\n",
              "      <td>스포츠잡화</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31680</th>\n",
              "      <td>31680</td>\n",
              "      <td>1129000014045300</td>\n",
              "      <td>5011000319087100</td>\n",
              "      <td>스마트디바이스</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31681</th>\n",
              "      <td>31681</td>\n",
              "      <td>1129000014045300</td>\n",
              "      <td>5011000263065200</td>\n",
              "      <td>스마트디바이스</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31682</th>\n",
              "      <td>31682</td>\n",
              "      <td>4127300065073100</td>\n",
              "      <td>5011000264061200</td>\n",
              "      <td>지갑</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31683</th>\n",
              "      <td>31683</td>\n",
              "      <td>2811000139076100</td>\n",
              "      <td>5011000520070100</td>\n",
              "      <td>세탁용품</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31684 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73143bbf-871a-48be-a98d-4860d3caaf2f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73143bbf-871a-48be-a98d-4860d3caaf2f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73143bbf-871a-48be-a98d-4860d3caaf2f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       index      송하인_격자공간고유번호      수하인_격자공간고유번호  물품_카테고리  운송장_건수\n",
              "0          0  5011000595017300  2871000192069300       음반       3\n",
              "1          1  4148000690043300  5011000264024400    문화컨텐츠       3\n",
              "2          2  5011000078068400  1120000007005400      농산물       3\n",
              "3          3  4127100048006400  5011000587019400     기타식품       7\n",
              "4          4  5011000078068400  2823700010076300      농산물       3\n",
              "...      ...               ...               ...      ...     ...\n",
              "31679  31679  4471000290087200  5011000213073200    스포츠잡화       3\n",
              "31680  31680  1129000014045300  5011000319087100  스마트디바이스       4\n",
              "31681  31681  1129000014045300  5011000263065200  스마트디바이스       6\n",
              "31682  31682  4127300065073100  5011000264061200       지갑       7\n",
              "31683  31683  2811000139076100  5011000520070100     세탁용품       4\n",
              "\n",
              "[31684 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 정보확인\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3COBz8NOZ6WD",
        "outputId": "4a0fd97a-f564-443c-dec2-5aa7a6665f89"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31684 entries, 0 to 31683\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   index         31684 non-null  int64 \n",
            " 1   송하인_격자공간고유번호  31684 non-null  int64 \n",
            " 2   수하인_격자공간고유번호  31684 non-null  int64 \n",
            " 3   물품_카테고리       31684 non-null  object\n",
            " 4   운송장_건수        31684 non-null  int64 \n",
            "dtypes: int64(4), object(1)\n",
            "memory usage: 1.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리"
      ],
      "metadata": {
        "id": "x12vCqqHaZZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) 칼럼명 변경\n",
        "\n",
        "대회 데이터가 재가공되었기 때문에 칼럼명을 변경해준다."
      ],
      "metadata": {
        "id": "a5xBMM5yK6VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 킬럼명 변경\n",
        "data.rename(columns={'송하인_격자공간고유번호' : 'SEND_SPG_INNB',\n",
        "                        '수하인_격자공간고유번호' : 'REC_SPG_INNB',\n",
        "                        '물품_카테고리' : 'DL_GD_MCLS_NM',\n",
        "                        '운송장_건수' : 'INVC_CONT'}, inplace=True)\n",
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "yaWVo38saNbr",
        "outputId": "67118b36-b16a-4bfa-bdf8-ba145ecc6340"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-760a2c27-68c1-44c2-b6cc-f846d2b5a40e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>SEND_SPG_INNB</th>\n",
              "      <th>REC_SPG_INNB</th>\n",
              "      <th>DL_GD_MCLS_NM</th>\n",
              "      <th>INVC_CONT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5011000595017300</td>\n",
              "      <td>2871000192069300</td>\n",
              "      <td>음반</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4148000690043300</td>\n",
              "      <td>5011000264024400</td>\n",
              "      <td>문화컨텐츠</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5011000078068400</td>\n",
              "      <td>1120000007005400</td>\n",
              "      <td>농산물</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4127100048006400</td>\n",
              "      <td>5011000587019400</td>\n",
              "      <td>기타식품</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5011000078068400</td>\n",
              "      <td>2823700010076300</td>\n",
              "      <td>농산물</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31679</th>\n",
              "      <td>31679</td>\n",
              "      <td>4471000290087200</td>\n",
              "      <td>5011000213073200</td>\n",
              "      <td>스포츠잡화</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31680</th>\n",
              "      <td>31680</td>\n",
              "      <td>1129000014045300</td>\n",
              "      <td>5011000319087100</td>\n",
              "      <td>스마트디바이스</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31681</th>\n",
              "      <td>31681</td>\n",
              "      <td>1129000014045300</td>\n",
              "      <td>5011000263065200</td>\n",
              "      <td>스마트디바이스</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31682</th>\n",
              "      <td>31682</td>\n",
              "      <td>4127300065073100</td>\n",
              "      <td>5011000264061200</td>\n",
              "      <td>지갑</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31683</th>\n",
              "      <td>31683</td>\n",
              "      <td>2811000139076100</td>\n",
              "      <td>5011000520070100</td>\n",
              "      <td>세탁용품</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31684 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-760a2c27-68c1-44c2-b6cc-f846d2b5a40e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-760a2c27-68c1-44c2-b6cc-f846d2b5a40e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-760a2c27-68c1-44c2-b6cc-f846d2b5a40e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       index     SEND_SPG_INNB      REC_SPG_INNB DL_GD_MCLS_NM  INVC_CONT\n",
              "0          0  5011000595017300  2871000192069300            음반          3\n",
              "1          1  4148000690043300  5011000264024400         문화컨텐츠          3\n",
              "2          2  5011000078068400  1120000007005400           농산물          3\n",
              "3          3  4127100048006400  5011000587019400          기타식품          7\n",
              "4          4  5011000078068400  2823700010076300           농산물          3\n",
              "...      ...               ...               ...           ...        ...\n",
              "31679  31679  4471000290087200  5011000213073200         스포츠잡화          3\n",
              "31680  31680  1129000014045300  5011000319087100       스마트디바이스          4\n",
              "31681  31681  1129000014045300  5011000263065200       스마트디바이스          6\n",
              "31682  31682  4127300065073100  5011000264061200            지갑          7\n",
              "31683  31683  2811000139076100  5011000520070100          세탁용품          4\n",
              "\n",
              "[31684 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.rename(columns={'송하인_격자공간고유번호' : 'SEND_SPG_INNB',\n",
        "                        '수하인_격자공간고유번호' : 'REC_SPG_INNB',\n",
        "                        '물품_카테고리' : 'DL_GD_MCLS_NM'}, inplace=True)\n",
        "\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "E8lfi6Nrq0yF",
        "outputId": "088486e2-f74d-48ca-bf3c-5fa35b86bc15"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1edbcc8b-3bec-4133-ac0a-56d50482485c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>SEND_SPG_INNB</th>\n",
              "      <th>REC_SPG_INNB</th>\n",
              "      <th>DL_GD_MCLS_NM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>4167000577042200</td>\n",
              "      <td>5011000435014100</td>\n",
              "      <td>선케어</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1156000009012200</td>\n",
              "      <td>5011000172034400</td>\n",
              "      <td>구강위생용품</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4122000363057300</td>\n",
              "      <td>5011000361097300</td>\n",
              "      <td>캠핑</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>5011000436041400</td>\n",
              "      <td>2826000084036400</td>\n",
              "      <td>아웃도어가구</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4150000241065200</td>\n",
              "      <td>5011000169044300</td>\n",
              "      <td>분유/이유식/아기간식</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7915</th>\n",
              "      <td>7915</td>\n",
              "      <td>5011000266051200</td>\n",
              "      <td>4623000417038100</td>\n",
              "      <td>농산물</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7916</th>\n",
              "      <td>7916</td>\n",
              "      <td>1154500001098300</td>\n",
              "      <td>5011000264055100</td>\n",
              "      <td>문화컨텐츠</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7917</th>\n",
              "      <td>7917</td>\n",
              "      <td>5013000610049100</td>\n",
              "      <td>1147000018091400</td>\n",
              "      <td>농산물</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7918</th>\n",
              "      <td>7918</td>\n",
              "      <td>5013000610049100</td>\n",
              "      <td>3117000039026100</td>\n",
              "      <td>농산물</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7919</th>\n",
              "      <td>7919</td>\n",
              "      <td>1165000014095200</td>\n",
              "      <td>5011000373086400</td>\n",
              "      <td>문화컨텐츠</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7920 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1edbcc8b-3bec-4133-ac0a-56d50482485c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1edbcc8b-3bec-4133-ac0a-56d50482485c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1edbcc8b-3bec-4133-ac0a-56d50482485c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      index     SEND_SPG_INNB      REC_SPG_INNB DL_GD_MCLS_NM\n",
              "0         0  4167000577042200  5011000435014100           선케어\n",
              "1         1  1156000009012200  5011000172034400        구강위생용품\n",
              "2         2  4122000363057300  5011000361097300            캠핑\n",
              "3         3  5011000436041400  2826000084036400        아웃도어가구\n",
              "4         4  4150000241065200  5011000169044300   분유/이유식/아기간식\n",
              "...     ...               ...               ...           ...\n",
              "7915   7915  5011000266051200  4623000417038100           농산물\n",
              "7916   7916  1154500001098300  5011000264055100         문화컨텐츠\n",
              "7917   7917  5013000610049100  1147000018091400           농산물\n",
              "7918   7918  5013000610049100  3117000039026100           농산물\n",
              "7919   7919  1165000014095200  5011000373086400         문화컨텐츠\n",
              "\n",
              "[7920 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 격자공간고유변호 칼럼 가공\n",
        "\n",
        "국토연구원 데이터 ( https://www.bigdata-region.kr/#/dataset/0ad3c882-f7ee-4faf-970d-00c53cb65a84) 를 참고해서 격자공간고유번호 칼럼을 가공해였다.\n",
        "\n",
        "---\n",
        "\n",
        "**<상세 내용>**\n",
        "\n",
        "\n",
        "격자공간고유번호의 1~5자리: 시군구\n",
        "\n",
        "격자공간고유번호의 1~10자리: 격자공간명\n",
        "\n",
        "격자공간고유번호의 1~2자리: 지역 \n",
        "\n",
        "을 나타낸다.\n",
        "\n",
        "<br>\n",
        "\n",
        "**이중 '시군구' (1~5자리) 기준으로 격자공간고유번호 칼럼을 가공하였다.**"
      ],
      "metadata": {
        "id": "IohBboS7alTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 격자공간고유번호 칼럼 가공\n",
        "data['round_send']=data['SEND_SPG_INNB'].round(-10)\n",
        "data['round_rec']=data['REC_SPG_INNB'].round(-10)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "CmZd3tww-O-T",
        "outputId": "ebbf9f00-010d-4d9e-83e7-208fa6410542"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-67e25436-46bb-48a1-8e15-6b1321d5269c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>SEND_SPG_INNB</th>\n",
              "      <th>REC_SPG_INNB</th>\n",
              "      <th>DL_GD_MCLS_NM</th>\n",
              "      <th>INVC_CONT</th>\n",
              "      <th>round_send</th>\n",
              "      <th>round_rec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5011000595017300</td>\n",
              "      <td>2871000192069300</td>\n",
              "      <td>음반</td>\n",
              "      <td>3</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>2871000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4148000690043300</td>\n",
              "      <td>5011000264024400</td>\n",
              "      <td>문화컨텐츠</td>\n",
              "      <td>3</td>\n",
              "      <td>4148000000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5011000078068400</td>\n",
              "      <td>1120000007005400</td>\n",
              "      <td>농산물</td>\n",
              "      <td>3</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>1120000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4127100048006400</td>\n",
              "      <td>5011000587019400</td>\n",
              "      <td>기타식품</td>\n",
              "      <td>7</td>\n",
              "      <td>4127100000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5011000078068400</td>\n",
              "      <td>2823700010076300</td>\n",
              "      <td>농산물</td>\n",
              "      <td>3</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>2823700000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31679</th>\n",
              "      <td>31679</td>\n",
              "      <td>4471000290087200</td>\n",
              "      <td>5011000213073200</td>\n",
              "      <td>스포츠잡화</td>\n",
              "      <td>3</td>\n",
              "      <td>4471000000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31680</th>\n",
              "      <td>31680</td>\n",
              "      <td>1129000014045300</td>\n",
              "      <td>5011000319087100</td>\n",
              "      <td>스마트디바이스</td>\n",
              "      <td>4</td>\n",
              "      <td>1129000000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31681</th>\n",
              "      <td>31681</td>\n",
              "      <td>1129000014045300</td>\n",
              "      <td>5011000263065200</td>\n",
              "      <td>스마트디바이스</td>\n",
              "      <td>6</td>\n",
              "      <td>1129000000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31682</th>\n",
              "      <td>31682</td>\n",
              "      <td>4127300065073100</td>\n",
              "      <td>5011000264061200</td>\n",
              "      <td>지갑</td>\n",
              "      <td>7</td>\n",
              "      <td>4127300000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31683</th>\n",
              "      <td>31683</td>\n",
              "      <td>2811000139076100</td>\n",
              "      <td>5011000520070100</td>\n",
              "      <td>세탁용품</td>\n",
              "      <td>4</td>\n",
              "      <td>2811000000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31684 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67e25436-46bb-48a1-8e15-6b1321d5269c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-67e25436-46bb-48a1-8e15-6b1321d5269c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-67e25436-46bb-48a1-8e15-6b1321d5269c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       index     SEND_SPG_INNB  ...        round_send         round_rec\n",
              "0          0  5011000595017300  ...  5011000000000000  2871000000000000\n",
              "1          1  4148000690043300  ...  4148000000000000  5011000000000000\n",
              "2          2  5011000078068400  ...  5011000000000000  1120000000000000\n",
              "3          3  4127100048006400  ...  4127100000000000  5011000000000000\n",
              "4          4  5011000078068400  ...  5011000000000000  2823700000000000\n",
              "...      ...               ...  ...               ...               ...\n",
              "31679  31679  4471000290087200  ...  4471000000000000  5011000000000000\n",
              "31680  31680  1129000014045300  ...  1129000000000000  5011000000000000\n",
              "31681  31681  1129000014045300  ...  1129000000000000  5011000000000000\n",
              "31682  31682  4127300065073100  ...  4127300000000000  5011000000000000\n",
              "31683  31683  2811000139076100  ...  2811000000000000  5011000000000000\n",
              "\n",
              "[31684 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 시군구 기준 주소정보 확인\n",
        "a=list(set(data.round_send.to_list())) # 송하인 \n",
        "b=list(set(data.round_rec.to_list())) # 수하인\n",
        "sums=list(set(a+b))\n",
        "print(\"송하인 주소 (시군구) 는 \", len(a), \"개이고 \\n수하인 주소 (시군구) 는 \", len(b), \"개이고 \\n송,수하인 주소 (시군구) 합은\", len(sums),\"개이다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-KKoxw7-Wgf",
        "outputId": "abcc576c-8e2b-461c-f038-333a35dac1ca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "송하인 주소 (시군구) 는  237 개이고 \n",
            "수하인 주소 (시군구) 는  251 개이고 \n",
            "송,수하인 주소 (시군구) 합은 251 개이다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결론적으로 주소가 31864개 (원본, 격자공간 기준) => 251개 (가공, 시군구 기준) 로 변경되었다."
      ],
      "metadata": {
        "id": "sAOAIWIydbYi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) featrue one-hot encoding"
      ],
      "metadata": {
        "id": "sgfdMO_Cc9cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 딕셔너리 생성 (송하인, 수하인 통합)\n",
        "nn=[]\n",
        "for _ in range(len(sums)):\n",
        "    n=[sums[_],_]\n",
        "    nn.append(n)\n",
        "\n",
        "nn=dict(nn)\n",
        "nn"
      ],
      "metadata": {
        "id": "FWHwFHqc-Ybq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8389c7ec-1246-4c4b-a821-098f8d75459b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1111000000000000: 202,\n",
              " 1114000000000000: 121,\n",
              " 1117000000000000: 20,\n",
              " 1120000000000000: 10,\n",
              " 1121500000000000: 88,\n",
              " 1123000000000000: 97,\n",
              " 1126000000000000: 14,\n",
              " 1129000000000000: 173,\n",
              " 1130500000000000: 151,\n",
              " 1132000000000000: 77,\n",
              " 1135000000000000: 181,\n",
              " 1138000000000000: 161,\n",
              " 1141000000000000: 57,\n",
              " 1144000000000000: 243,\n",
              " 1147000000000000: 142,\n",
              " 1150000000000000: 52,\n",
              " 1153000000000000: 228,\n",
              " 1154500000000000: 176,\n",
              " 1156000000000000: 129,\n",
              " 1159000000000000: 190,\n",
              " 1162000000000000: 211,\n",
              " 1165000000000000: 111,\n",
              " 1168000000000000: 30,\n",
              " 1171000000000000: 196,\n",
              " 1174000000000000: 119,\n",
              " 2611000000000000: 184,\n",
              " 2614000000000000: 166,\n",
              " 2617000000000000: 72,\n",
              " 2620000000000000: 249,\n",
              " 2623000000000000: 93,\n",
              " 2626000000000000: 115,\n",
              " 2629000000000000: 238,\n",
              " 2632000000000000: 138,\n",
              " 2635000000000000: 47,\n",
              " 2638000000000000: 216,\n",
              " 2641000000000000: 124,\n",
              " 2644000000000000: 35,\n",
              " 2647000000000000: 201,\n",
              " 2650000000000000: 108,\n",
              " 2653000000000000: 21,\n",
              " 2671000000000000: 44,\n",
              " 2711000000000000: 69,\n",
              " 2714000000000000: 247,\n",
              " 2717000000000000: 144,\n",
              " 2720000000000000: 58,\n",
              " 2723000000000000: 234,\n",
              " 2726000000000000: 133,\n",
              " 2729000000000000: 41,\n",
              " 2771000000000000: 64,\n",
              " 2811000000000000: 141,\n",
              " 2814000000000000: 114,\n",
              " 2817000000000000: 230,\n",
              " 2818500000000000: 156,\n",
              " 2820000000000000: 130,\n",
              " 2823700000000000: 31,\n",
              " 2824500000000000: 29,\n",
              " 2826000000000000: 210,\n",
              " 2871000000000000: 135,\n",
              " 2872000000000000: 104,\n",
              " 2911000000000000: 219,\n",
              " 2914000000000000: 125,\n",
              " 2915500000000000: 224,\n",
              " 2917000000000000: 36,\n",
              " 2920000000000000: 205,\n",
              " 3011000000000000: 188,\n",
              " 3014000000000000: 199,\n",
              " 3017000000000000: 105,\n",
              " 3020000000000000: 18,\n",
              " 3023000000000000: 191,\n",
              " 3111000000000000: 101,\n",
              " 3114000000000000: 112,\n",
              " 3117000000000000: 180,\n",
              " 3120000000000000: 91,\n",
              " 3171000000000000: 95,\n",
              " 3611000000000000: 214,\n",
              " 4111100000000000: 89,\n",
              " 4111300000000000: 149,\n",
              " 4111500000000000: 221,\n",
              " 4111700000000000: 28,\n",
              " 4113100000000000: 225,\n",
              " 4113300000000000: 26,\n",
              " 4113500000000000: 81,\n",
              " 4115000000000000: 195,\n",
              " 4117100000000000: 222,\n",
              " 4117300000000000: 27,\n",
              " 4119500000000000: 223,\n",
              " 4119700000000000: 50,\n",
              " 4119900000000000: 83,\n",
              " 4121000000000000: 59,\n",
              " 4122000000000000: 246,\n",
              " 4125000000000000: 145,\n",
              " 4127100000000000: 3,\n",
              " 4127300000000000: 154,\n",
              " 4128100000000000: 152,\n",
              " 4128500000000000: 9,\n",
              " 4128700000000000: 85,\n",
              " 4129000000000000: 33,\n",
              " 4131000000000000: 233,\n",
              " 4136000000000000: 4,\n",
              " 4137000000000000: 40,\n",
              " 4139000000000000: 248,\n",
              " 4141000000000000: 179,\n",
              " 4143000000000000: 204,\n",
              " 4145000000000000: 53,\n",
              " 4146100000000000: 25,\n",
              " 4146300000000000: 5,\n",
              " 4146500000000000: 148,\n",
              " 4148000000000000: 1,\n",
              " 4150000000000000: 7,\n",
              " 4155000000000000: 187,\n",
              " 4157000000000000: 215,\n",
              " 4159000000000000: 153,\n",
              " 4161000000000000: 90,\n",
              " 4163000000000000: 189,\n",
              " 4165000000000000: 237,\n",
              " 4167000000000000: 169,\n",
              " 4180000000000000: 34,\n",
              " 4182000000000000: 241,\n",
              " 4183000000000000: 203,\n",
              " 4211000000000000: 128,\n",
              " 4213000000000000: 56,\n",
              " 4215000000000000: 186,\n",
              " 4217000000000000: 207,\n",
              " 4219000000000000: 143,\n",
              " 4221000000000000: 79,\n",
              " 4223000000000000: 182,\n",
              " 4272000000000000: 92,\n",
              " 4273000000000000: 63,\n",
              " 4275000000000000: 183,\n",
              " 4276000000000000: 235,\n",
              " 4277000000000000: 198,\n",
              " 4278000000000000: 167,\n",
              " 4279000000000000: 136,\n",
              " 4280000000000000: 102,\n",
              " 4281000000000000: 71,\n",
              " 4282000000000000: 113,\n",
              " 4283000000000000: 17,\n",
              " 4311100000000000: 82,\n",
              " 4311300000000000: 193,\n",
              " 4313000000000000: 139,\n",
              " 4315000000000000: 75,\n",
              " 4371000000000000: 194,\n",
              " 4372000000000000: 163,\n",
              " 4373000000000000: 131,\n",
              " 4374000000000000: 118,\n",
              " 4374500000000000: 150,\n",
              " 4375000000000000: 68,\n",
              " 4376000000000000: 39,\n",
              " 4377000000000000: 61,\n",
              " 4380000000000000: 178,\n",
              " 4413100000000000: 218,\n",
              " 4413300000000000: 24,\n",
              " 4415000000000000: 206,\n",
              " 4418000000000000: 116,\n",
              " 4420000000000000: 13,\n",
              " 4421000000000000: 236,\n",
              " 4423000000000000: 170,\n",
              " 4425000000000000: 107,\n",
              " 4427000000000000: 46,\n",
              " 4471000000000000: 15,\n",
              " 4476000000000000: 110,\n",
              " 4477000000000000: 78,\n",
              " 4479000000000000: 140,\n",
              " 4480000000000000: 11,\n",
              " 4481000000000000: 229,\n",
              " 4482500000000000: 177,\n",
              " 4511100000000000: 87,\n",
              " 4511300000000000: 155,\n",
              " 4513000000000000: 32,\n",
              " 4514000000000000: 12,\n",
              " 4518000000000000: 134,\n",
              " 4519000000000000: 99,\n",
              " 4521000000000000: 42,\n",
              " 4571000000000000: 74,\n",
              " 4572000000000000: 49,\n",
              " 4573000000000000: 22,\n",
              " 4574000000000000: 250,\n",
              " 4575000000000000: 226,\n",
              " 4577000000000000: 160,\n",
              " 4579000000000000: 96,\n",
              " 4580000000000000: 66,\n",
              " 4611000000000000: 162,\n",
              " 4613000000000000: 98,\n",
              " 4615000000000000: 37,\n",
              " 4617000000000000: 245,\n",
              " 4623000000000000: 185,\n",
              " 4671000000000000: 157,\n",
              " 4672000000000000: 126,\n",
              " 4673000000000000: 94,\n",
              " 4677000000000000: 239,\n",
              " 4678000000000000: 200,\n",
              " 4679000000000000: 171,\n",
              " 4680000000000000: 137,\n",
              " 4681000000000000: 106,\n",
              " 4682000000000000: 8,\n",
              " 4683000000000000: 48,\n",
              " 4684000000000000: 19,\n",
              " 4686000000000000: 217,\n",
              " 4687000000000000: 209,\n",
              " 4688000000000000: 158,\n",
              " 4689000000000000: 123,\n",
              " 4690000000000000: 117,\n",
              " 4691000000000000: 65,\n",
              " 4711100000000000: 84,\n",
              " 4711300000000000: 232,\n",
              " 4713000000000000: 174,\n",
              " 4715000000000000: 109,\n",
              " 4717000000000000: 51,\n",
              " 4719000000000000: 175,\n",
              " 4721000000000000: 192,\n",
              " 4723000000000000: 127,\n",
              " 4725000000000000: 6,\n",
              " 4728000000000000: 242,\n",
              " 4729000000000000: 208,\n",
              " 4772000000000000: 197,\n",
              " 4773000000000000: 165,\n",
              " 4775000000000000: 100,\n",
              " 4776000000000000: 70,\n",
              " 4777000000000000: 43,\n",
              " 4782000000000000: 146,\n",
              " 4783000000000000: 122,\n",
              " 4784000000000000: 86,\n",
              " 4785000000000000: 55,\n",
              " 4790000000000000: 168,\n",
              " 4792000000000000: 103,\n",
              " 4793000000000000: 73,\n",
              " 4794000000000000: 45,\n",
              " 4812100000000000: 147,\n",
              " 4812300000000000: 220,\n",
              " 4812500000000000: 23,\n",
              " 4812700000000000: 80,\n",
              " 4812900000000000: 212,\n",
              " 4817000000000000: 54,\n",
              " 4822000000000000: 240,\n",
              " 4824000000000000: 172,\n",
              " 4825000000000000: 62,\n",
              " 4827000000000000: 76,\n",
              " 4831000000000000: 227,\n",
              " 4833000000000000: 159,\n",
              " 4872000000000000: 16,\n",
              " 4873000000000000: 244,\n",
              " 4874000000000000: 213,\n",
              " 4882000000000000: 231,\n",
              " 4884000000000000: 164,\n",
              " 4885000000000000: 132,\n",
              " 4886000000000000: 120,\n",
              " 4887000000000000: 67,\n",
              " 4888000000000000: 38,\n",
              " 4889000000000000: 60,\n",
              " 5011000000000000: 0,\n",
              " 5013000000000000: 2}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞서 언급한 것과 같이 주소 (송하인 + 수하인) 251개로 변경되었고 (시군구 시준) \n",
        "\n",
        "모든 수하인 주소는 송하인 주소에 포함된다는 것이 확인되었다."
      ],
      "metadata": {
        "id": "FYN_hKgffUJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature one-hot encoding\n",
        "from tqdm import tqdm\n",
        "for _ in tqdm(range(31684)): # 총 데이터 수\n",
        "    data.loc[_,'send_dict']=str(nn[data['round_send'][_]])\n",
        "    data.loc[_,'rec_dict']=str(nn[data['round_rec'][_]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yoDGMzQ-bWd",
        "outputId": "a8a79d0f-09c2-4432-f5ac-a5d9a77ed030"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31684/31684 [01:19<00:00, 399.55it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.get_dummies(data)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "U4SwQurK-gBa",
        "outputId": "e9e9c060-20c7-443f-d98c-29eb569431fe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bc75622b-cd6f-4c2b-abe8-79305ba80431\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>SEND_SPG_INNB</th>\n",
              "      <th>REC_SPG_INNB</th>\n",
              "      <th>INVC_CONT</th>\n",
              "      <th>round_send</th>\n",
              "      <th>round_rec</th>\n",
              "      <th>DL_GD_MCLS_NM_DIY자재/용품</th>\n",
              "      <th>DL_GD_MCLS_NM_PC</th>\n",
              "      <th>DL_GD_MCLS_NM_PC주변기기</th>\n",
              "      <th>DL_GD_MCLS_NM_가공식품</th>\n",
              "      <th>DL_GD_MCLS_NM_가방</th>\n",
              "      <th>DL_GD_MCLS_NM_건강식품</th>\n",
              "      <th>DL_GD_MCLS_NM_건강용품</th>\n",
              "      <th>DL_GD_MCLS_NM_게임기/타이틀</th>\n",
              "      <th>DL_GD_MCLS_NM_계절가전</th>\n",
              "      <th>DL_GD_MCLS_NM_골프</th>\n",
              "      <th>DL_GD_MCLS_NM_공구</th>\n",
              "      <th>DL_GD_MCLS_NM_과자</th>\n",
              "      <th>DL_GD_MCLS_NM_구강위생용품</th>\n",
              "      <th>DL_GD_MCLS_NM_기능성</th>\n",
              "      <th>DL_GD_MCLS_NM_기저귀/물티슈</th>\n",
              "      <th>DL_GD_MCLS_NM_기타디지털/가전</th>\n",
              "      <th>DL_GD_MCLS_NM_기타스포츠/레저</th>\n",
              "      <th>DL_GD_MCLS_NM_기타식품</th>\n",
              "      <th>DL_GD_MCLS_NM_기타출산/육아</th>\n",
              "      <th>DL_GD_MCLS_NM_기타패션의류</th>\n",
              "      <th>DL_GD_MCLS_NM_기타패션잡화</th>\n",
              "      <th>DL_GD_MCLS_NM_기타화장품/미용</th>\n",
              "      <th>DL_GD_MCLS_NM_김치</th>\n",
              "      <th>DL_GD_MCLS_NM_낚시</th>\n",
              "      <th>DL_GD_MCLS_NM_남성화장품</th>\n",
              "      <th>DL_GD_MCLS_NM_냉동/간편조리식품</th>\n",
              "      <th>DL_GD_MCLS_NM_네일케어</th>\n",
              "      <th>DL_GD_MCLS_NM_농산물</th>\n",
              "      <th>DL_GD_MCLS_NM_눈관리용품</th>\n",
              "      <th>DL_GD_MCLS_NM_다이어트식품</th>\n",
              "      <th>DL_GD_MCLS_NM_등산</th>\n",
              "      <th>DL_GD_MCLS_NM_모니터</th>\n",
              "      <th>DL_GD_MCLS_NM_모자</th>\n",
              "      <th>DL_GD_MCLS_NM_문구/사무용품</th>\n",
              "      <th>...</th>\n",
              "      <th>rec_dict_63</th>\n",
              "      <th>rec_dict_64</th>\n",
              "      <th>rec_dict_65</th>\n",
              "      <th>rec_dict_66</th>\n",
              "      <th>rec_dict_67</th>\n",
              "      <th>rec_dict_68</th>\n",
              "      <th>rec_dict_69</th>\n",
              "      <th>rec_dict_7</th>\n",
              "      <th>rec_dict_70</th>\n",
              "      <th>rec_dict_71</th>\n",
              "      <th>rec_dict_72</th>\n",
              "      <th>rec_dict_73</th>\n",
              "      <th>rec_dict_74</th>\n",
              "      <th>rec_dict_75</th>\n",
              "      <th>rec_dict_76</th>\n",
              "      <th>rec_dict_77</th>\n",
              "      <th>rec_dict_78</th>\n",
              "      <th>rec_dict_79</th>\n",
              "      <th>rec_dict_8</th>\n",
              "      <th>rec_dict_80</th>\n",
              "      <th>rec_dict_81</th>\n",
              "      <th>rec_dict_82</th>\n",
              "      <th>rec_dict_83</th>\n",
              "      <th>rec_dict_84</th>\n",
              "      <th>rec_dict_85</th>\n",
              "      <th>rec_dict_86</th>\n",
              "      <th>rec_dict_87</th>\n",
              "      <th>rec_dict_88</th>\n",
              "      <th>rec_dict_89</th>\n",
              "      <th>rec_dict_9</th>\n",
              "      <th>rec_dict_90</th>\n",
              "      <th>rec_dict_91</th>\n",
              "      <th>rec_dict_92</th>\n",
              "      <th>rec_dict_93</th>\n",
              "      <th>rec_dict_94</th>\n",
              "      <th>rec_dict_95</th>\n",
              "      <th>rec_dict_96</th>\n",
              "      <th>rec_dict_97</th>\n",
              "      <th>rec_dict_98</th>\n",
              "      <th>rec_dict_99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5011000595017300</td>\n",
              "      <td>2871000192069300</td>\n",
              "      <td>3</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>2871000000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4148000690043300</td>\n",
              "      <td>5011000264024400</td>\n",
              "      <td>3</td>\n",
              "      <td>4148000000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5011000078068400</td>\n",
              "      <td>1120000007005400</td>\n",
              "      <td>3</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>1120000000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4127100048006400</td>\n",
              "      <td>5011000587019400</td>\n",
              "      <td>7</td>\n",
              "      <td>4127100000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5011000078068400</td>\n",
              "      <td>2823700010076300</td>\n",
              "      <td>3</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>2823700000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31679</th>\n",
              "      <td>31679</td>\n",
              "      <td>4471000290087200</td>\n",
              "      <td>5011000213073200</td>\n",
              "      <td>3</td>\n",
              "      <td>4471000000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31680</th>\n",
              "      <td>31680</td>\n",
              "      <td>1129000014045300</td>\n",
              "      <td>5011000319087100</td>\n",
              "      <td>4</td>\n",
              "      <td>1129000000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31681</th>\n",
              "      <td>31681</td>\n",
              "      <td>1129000014045300</td>\n",
              "      <td>5011000263065200</td>\n",
              "      <td>6</td>\n",
              "      <td>1129000000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31682</th>\n",
              "      <td>31682</td>\n",
              "      <td>4127300065073100</td>\n",
              "      <td>5011000264061200</td>\n",
              "      <td>7</td>\n",
              "      <td>4127300000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31683</th>\n",
              "      <td>31683</td>\n",
              "      <td>2811000139076100</td>\n",
              "      <td>5011000520070100</td>\n",
              "      <td>4</td>\n",
              "      <td>2811000000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31684 rows × 594 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc75622b-cd6f-4c2b-abe8-79305ba80431')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc75622b-cd6f-4c2b-abe8-79305ba80431 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc75622b-cd6f-4c2b-abe8-79305ba80431');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       index     SEND_SPG_INNB  ...  rec_dict_98  rec_dict_99\n",
              "0          0  5011000595017300  ...            0            0\n",
              "1          1  4148000690043300  ...            0            0\n",
              "2          2  5011000078068400  ...            0            0\n",
              "3          3  4127100048006400  ...            0            0\n",
              "4          4  5011000078068400  ...            0            0\n",
              "...      ...               ...  ...          ...          ...\n",
              "31679  31679  4471000290087200  ...            0            0\n",
              "31680  31680  1129000014045300  ...            0            0\n",
              "31681  31681  1129000014045300  ...            0            0\n",
              "31682  31682  4127300065073100  ...            0            0\n",
              "31683  31683  2811000139076100  ...            0            0\n",
              "\n",
              "[31684 rows x 594 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# feature 확인\n",
        "feature=list(data.columns)[6:]\n",
        "feature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTqZWEZ3-jDf",
        "outputId": "2732ec22-5bab-442a-d5b6-66e09980ca2f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DL_GD_MCLS_NM_DIY자재/용품',\n",
              " 'DL_GD_MCLS_NM_PC',\n",
              " 'DL_GD_MCLS_NM_PC주변기기',\n",
              " 'DL_GD_MCLS_NM_가공식품',\n",
              " 'DL_GD_MCLS_NM_가방',\n",
              " 'DL_GD_MCLS_NM_건강식품',\n",
              " 'DL_GD_MCLS_NM_건강용품',\n",
              " 'DL_GD_MCLS_NM_게임기/타이틀',\n",
              " 'DL_GD_MCLS_NM_계절가전',\n",
              " 'DL_GD_MCLS_NM_골프',\n",
              " 'DL_GD_MCLS_NM_공구',\n",
              " 'DL_GD_MCLS_NM_과자',\n",
              " 'DL_GD_MCLS_NM_구강위생용품',\n",
              " 'DL_GD_MCLS_NM_기능성',\n",
              " 'DL_GD_MCLS_NM_기저귀/물티슈',\n",
              " 'DL_GD_MCLS_NM_기타디지털/가전',\n",
              " 'DL_GD_MCLS_NM_기타스포츠/레저',\n",
              " 'DL_GD_MCLS_NM_기타식품',\n",
              " 'DL_GD_MCLS_NM_기타출산/육아',\n",
              " 'DL_GD_MCLS_NM_기타패션의류',\n",
              " 'DL_GD_MCLS_NM_기타패션잡화',\n",
              " 'DL_GD_MCLS_NM_기타화장품/미용',\n",
              " 'DL_GD_MCLS_NM_김치',\n",
              " 'DL_GD_MCLS_NM_낚시',\n",
              " 'DL_GD_MCLS_NM_남성화장품',\n",
              " 'DL_GD_MCLS_NM_냉동/간편조리식품',\n",
              " 'DL_GD_MCLS_NM_네일케어',\n",
              " 'DL_GD_MCLS_NM_농산물',\n",
              " 'DL_GD_MCLS_NM_눈관리용품',\n",
              " 'DL_GD_MCLS_NM_다이어트식품',\n",
              " 'DL_GD_MCLS_NM_등산',\n",
              " 'DL_GD_MCLS_NM_모니터',\n",
              " 'DL_GD_MCLS_NM_모자',\n",
              " 'DL_GD_MCLS_NM_문구/사무용품',\n",
              " 'DL_GD_MCLS_NM_문화컨텐츠',\n",
              " 'DL_GD_MCLS_NM_바디케어',\n",
              " 'DL_GD_MCLS_NM_반려동물',\n",
              " 'DL_GD_MCLS_NM_반찬',\n",
              " 'DL_GD_MCLS_NM_베이스메이크업',\n",
              " 'DL_GD_MCLS_NM_분유/이유식/아기간식',\n",
              " 'DL_GD_MCLS_NM_뷰티소품',\n",
              " 'DL_GD_MCLS_NM_상의',\n",
              " 'DL_GD_MCLS_NM_색조메이크업',\n",
              " 'DL_GD_MCLS_NM_생활가전',\n",
              " 'DL_GD_MCLS_NM_생활용품',\n",
              " 'DL_GD_MCLS_NM_서재/사무용가구',\n",
              " 'DL_GD_MCLS_NM_선글라스/안경테',\n",
              " 'DL_GD_MCLS_NM_선케어',\n",
              " 'DL_GD_MCLS_NM_세탁용품',\n",
              " 'DL_GD_MCLS_NM_수납/정리용품',\n",
              " 'DL_GD_MCLS_NM_수납가구',\n",
              " 'DL_GD_MCLS_NM_수산',\n",
              " 'DL_GD_MCLS_NM_스마트디바이스',\n",
              " 'DL_GD_MCLS_NM_스마트디바이스액세서리',\n",
              " 'DL_GD_MCLS_NM_스킨케어',\n",
              " 'DL_GD_MCLS_NM_스포츠잡화',\n",
              " 'DL_GD_MCLS_NM_신발',\n",
              " 'DL_GD_MCLS_NM_아우터',\n",
              " 'DL_GD_MCLS_NM_아웃도어가구',\n",
              " 'DL_GD_MCLS_NM_양말/스타킹',\n",
              " 'DL_GD_MCLS_NM_언더웨어',\n",
              " 'DL_GD_MCLS_NM_완구/매트',\n",
              " 'DL_GD_MCLS_NM_욕실용품',\n",
              " 'DL_GD_MCLS_NM_원피스/점프슈트',\n",
              " 'DL_GD_MCLS_NM_위생/건강용품',\n",
              " 'DL_GD_MCLS_NM_유아가구',\n",
              " 'DL_GD_MCLS_NM_음료',\n",
              " 'DL_GD_MCLS_NM_음반',\n",
              " 'DL_GD_MCLS_NM_음향가전',\n",
              " 'DL_GD_MCLS_NM_의료용품',\n",
              " 'DL_GD_MCLS_NM_이미용가전',\n",
              " 'DL_GD_MCLS_NM_인테리어소품',\n",
              " 'DL_GD_MCLS_NM_자동차용품',\n",
              " 'DL_GD_MCLS_NM_잠옷',\n",
              " 'DL_GD_MCLS_NM_재활운동용품',\n",
              " 'DL_GD_MCLS_NM_주방가구',\n",
              " 'DL_GD_MCLS_NM_주방가전',\n",
              " 'DL_GD_MCLS_NM_주방용품',\n",
              " 'DL_GD_MCLS_NM_주얼리',\n",
              " 'DL_GD_MCLS_NM_지갑',\n",
              " 'DL_GD_MCLS_NM_축산',\n",
              " 'DL_GD_MCLS_NM_출산/유아동의류',\n",
              " 'DL_GD_MCLS_NM_출산/유아동잡화',\n",
              " 'DL_GD_MCLS_NM_취미용품',\n",
              " 'DL_GD_MCLS_NM_침구단품',\n",
              " 'DL_GD_MCLS_NM_침구세트',\n",
              " 'DL_GD_MCLS_NM_침실가구',\n",
              " 'DL_GD_MCLS_NM_카페트/러그',\n",
              " 'DL_GD_MCLS_NM_캠핑',\n",
              " 'DL_GD_MCLS_NM_커튼/블라인드',\n",
              " 'DL_GD_MCLS_NM_클렌징',\n",
              " 'DL_GD_MCLS_NM_태블릿PC/노트북액세서리',\n",
              " 'DL_GD_MCLS_NM_패션소품',\n",
              " 'DL_GD_MCLS_NM_하의',\n",
              " 'DL_GD_MCLS_NM_향수',\n",
              " 'DL_GD_MCLS_NM_헤어스타일링',\n",
              " 'DL_GD_MCLS_NM_헤어액세서리',\n",
              " 'DL_GD_MCLS_NM_헤어케어',\n",
              " 'DL_GD_MCLS_NM_헬스',\n",
              " 'DL_GD_MCLS_NM_홈데코',\n",
              " 'send_dict_0',\n",
              " 'send_dict_1',\n",
              " 'send_dict_10',\n",
              " 'send_dict_100',\n",
              " 'send_dict_102',\n",
              " 'send_dict_103',\n",
              " 'send_dict_105',\n",
              " 'send_dict_106',\n",
              " 'send_dict_107',\n",
              " 'send_dict_108',\n",
              " 'send_dict_109',\n",
              " 'send_dict_11',\n",
              " 'send_dict_111',\n",
              " 'send_dict_112',\n",
              " 'send_dict_113',\n",
              " 'send_dict_114',\n",
              " 'send_dict_115',\n",
              " 'send_dict_116',\n",
              " 'send_dict_117',\n",
              " 'send_dict_118',\n",
              " 'send_dict_119',\n",
              " 'send_dict_12',\n",
              " 'send_dict_120',\n",
              " 'send_dict_121',\n",
              " 'send_dict_122',\n",
              " 'send_dict_123',\n",
              " 'send_dict_124',\n",
              " 'send_dict_125',\n",
              " 'send_dict_126',\n",
              " 'send_dict_127',\n",
              " 'send_dict_128',\n",
              " 'send_dict_129',\n",
              " 'send_dict_13',\n",
              " 'send_dict_130',\n",
              " 'send_dict_131',\n",
              " 'send_dict_133',\n",
              " 'send_dict_134',\n",
              " 'send_dict_135',\n",
              " 'send_dict_137',\n",
              " 'send_dict_138',\n",
              " 'send_dict_139',\n",
              " 'send_dict_14',\n",
              " 'send_dict_140',\n",
              " 'send_dict_141',\n",
              " 'send_dict_142',\n",
              " 'send_dict_143',\n",
              " 'send_dict_144',\n",
              " 'send_dict_145',\n",
              " 'send_dict_146',\n",
              " 'send_dict_147',\n",
              " 'send_dict_148',\n",
              " 'send_dict_149',\n",
              " 'send_dict_15',\n",
              " 'send_dict_150',\n",
              " 'send_dict_151',\n",
              " 'send_dict_152',\n",
              " 'send_dict_153',\n",
              " 'send_dict_154',\n",
              " 'send_dict_155',\n",
              " 'send_dict_156',\n",
              " 'send_dict_157',\n",
              " 'send_dict_158',\n",
              " 'send_dict_159',\n",
              " 'send_dict_160',\n",
              " 'send_dict_161',\n",
              " 'send_dict_162',\n",
              " 'send_dict_163',\n",
              " 'send_dict_164',\n",
              " 'send_dict_165',\n",
              " 'send_dict_166',\n",
              " 'send_dict_167',\n",
              " 'send_dict_168',\n",
              " 'send_dict_169',\n",
              " 'send_dict_170',\n",
              " 'send_dict_171',\n",
              " 'send_dict_172',\n",
              " 'send_dict_173',\n",
              " 'send_dict_174',\n",
              " 'send_dict_175',\n",
              " 'send_dict_176',\n",
              " 'send_dict_177',\n",
              " 'send_dict_179',\n",
              " 'send_dict_18',\n",
              " 'send_dict_180',\n",
              " 'send_dict_181',\n",
              " 'send_dict_182',\n",
              " 'send_dict_183',\n",
              " 'send_dict_184',\n",
              " 'send_dict_185',\n",
              " 'send_dict_186',\n",
              " 'send_dict_187',\n",
              " 'send_dict_188',\n",
              " 'send_dict_189',\n",
              " 'send_dict_19',\n",
              " 'send_dict_190',\n",
              " 'send_dict_191',\n",
              " 'send_dict_192',\n",
              " 'send_dict_193',\n",
              " 'send_dict_194',\n",
              " 'send_dict_195',\n",
              " 'send_dict_196',\n",
              " 'send_dict_197',\n",
              " 'send_dict_198',\n",
              " 'send_dict_199',\n",
              " 'send_dict_2',\n",
              " 'send_dict_20',\n",
              " 'send_dict_200',\n",
              " 'send_dict_201',\n",
              " 'send_dict_202',\n",
              " 'send_dict_204',\n",
              " 'send_dict_205',\n",
              " 'send_dict_206',\n",
              " 'send_dict_207',\n",
              " 'send_dict_208',\n",
              " 'send_dict_209',\n",
              " 'send_dict_21',\n",
              " 'send_dict_210',\n",
              " 'send_dict_211',\n",
              " 'send_dict_212',\n",
              " 'send_dict_214',\n",
              " 'send_dict_215',\n",
              " 'send_dict_216',\n",
              " 'send_dict_217',\n",
              " 'send_dict_218',\n",
              " 'send_dict_219',\n",
              " 'send_dict_22',\n",
              " 'send_dict_220',\n",
              " 'send_dict_221',\n",
              " 'send_dict_222',\n",
              " 'send_dict_223',\n",
              " 'send_dict_224',\n",
              " 'send_dict_225',\n",
              " 'send_dict_226',\n",
              " 'send_dict_227',\n",
              " 'send_dict_228',\n",
              " 'send_dict_229',\n",
              " 'send_dict_23',\n",
              " 'send_dict_230',\n",
              " 'send_dict_231',\n",
              " 'send_dict_232',\n",
              " 'send_dict_233',\n",
              " 'send_dict_234',\n",
              " 'send_dict_235',\n",
              " 'send_dict_236',\n",
              " 'send_dict_237',\n",
              " 'send_dict_238',\n",
              " 'send_dict_239',\n",
              " 'send_dict_24',\n",
              " 'send_dict_240',\n",
              " 'send_dict_241',\n",
              " 'send_dict_242',\n",
              " 'send_dict_243',\n",
              " 'send_dict_244',\n",
              " 'send_dict_245',\n",
              " 'send_dict_246',\n",
              " 'send_dict_247',\n",
              " 'send_dict_248',\n",
              " 'send_dict_249',\n",
              " 'send_dict_25',\n",
              " 'send_dict_26',\n",
              " 'send_dict_27',\n",
              " 'send_dict_28',\n",
              " 'send_dict_29',\n",
              " 'send_dict_3',\n",
              " 'send_dict_30',\n",
              " 'send_dict_31',\n",
              " 'send_dict_32',\n",
              " 'send_dict_33',\n",
              " 'send_dict_34',\n",
              " 'send_dict_35',\n",
              " 'send_dict_36',\n",
              " 'send_dict_37',\n",
              " 'send_dict_38',\n",
              " 'send_dict_39',\n",
              " 'send_dict_4',\n",
              " 'send_dict_40',\n",
              " 'send_dict_41',\n",
              " 'send_dict_42',\n",
              " 'send_dict_43',\n",
              " 'send_dict_44',\n",
              " 'send_dict_46',\n",
              " 'send_dict_47',\n",
              " 'send_dict_48',\n",
              " 'send_dict_49',\n",
              " 'send_dict_5',\n",
              " 'send_dict_50',\n",
              " 'send_dict_51',\n",
              " 'send_dict_52',\n",
              " 'send_dict_53',\n",
              " 'send_dict_54',\n",
              " 'send_dict_55',\n",
              " 'send_dict_56',\n",
              " 'send_dict_57',\n",
              " 'send_dict_58',\n",
              " 'send_dict_59',\n",
              " 'send_dict_6',\n",
              " 'send_dict_60',\n",
              " 'send_dict_61',\n",
              " 'send_dict_62',\n",
              " 'send_dict_63',\n",
              " 'send_dict_64',\n",
              " 'send_dict_65',\n",
              " 'send_dict_66',\n",
              " 'send_dict_67',\n",
              " 'send_dict_68',\n",
              " 'send_dict_69',\n",
              " 'send_dict_7',\n",
              " 'send_dict_70',\n",
              " 'send_dict_71',\n",
              " 'send_dict_72',\n",
              " 'send_dict_74',\n",
              " 'send_dict_75',\n",
              " 'send_dict_76',\n",
              " 'send_dict_77',\n",
              " 'send_dict_78',\n",
              " 'send_dict_79',\n",
              " 'send_dict_8',\n",
              " 'send_dict_80',\n",
              " 'send_dict_81',\n",
              " 'send_dict_82',\n",
              " 'send_dict_83',\n",
              " 'send_dict_84',\n",
              " 'send_dict_85',\n",
              " 'send_dict_86',\n",
              " 'send_dict_87',\n",
              " 'send_dict_88',\n",
              " 'send_dict_89',\n",
              " 'send_dict_9',\n",
              " 'send_dict_90',\n",
              " 'send_dict_91',\n",
              " 'send_dict_92',\n",
              " 'send_dict_93',\n",
              " 'send_dict_95',\n",
              " 'send_dict_96',\n",
              " 'send_dict_97',\n",
              " 'send_dict_98',\n",
              " 'send_dict_99',\n",
              " 'rec_dict_0',\n",
              " 'rec_dict_1',\n",
              " 'rec_dict_10',\n",
              " 'rec_dict_100',\n",
              " 'rec_dict_101',\n",
              " 'rec_dict_102',\n",
              " 'rec_dict_103',\n",
              " 'rec_dict_104',\n",
              " 'rec_dict_105',\n",
              " 'rec_dict_106',\n",
              " 'rec_dict_107',\n",
              " 'rec_dict_108',\n",
              " 'rec_dict_109',\n",
              " 'rec_dict_11',\n",
              " 'rec_dict_110',\n",
              " 'rec_dict_111',\n",
              " 'rec_dict_112',\n",
              " 'rec_dict_113',\n",
              " 'rec_dict_114',\n",
              " 'rec_dict_115',\n",
              " 'rec_dict_116',\n",
              " 'rec_dict_117',\n",
              " 'rec_dict_118',\n",
              " 'rec_dict_119',\n",
              " 'rec_dict_12',\n",
              " 'rec_dict_120',\n",
              " 'rec_dict_121',\n",
              " 'rec_dict_122',\n",
              " 'rec_dict_123',\n",
              " 'rec_dict_124',\n",
              " 'rec_dict_125',\n",
              " 'rec_dict_126',\n",
              " 'rec_dict_127',\n",
              " 'rec_dict_128',\n",
              " 'rec_dict_129',\n",
              " 'rec_dict_13',\n",
              " 'rec_dict_130',\n",
              " 'rec_dict_131',\n",
              " 'rec_dict_132',\n",
              " 'rec_dict_133',\n",
              " 'rec_dict_134',\n",
              " 'rec_dict_135',\n",
              " 'rec_dict_136',\n",
              " 'rec_dict_137',\n",
              " 'rec_dict_138',\n",
              " 'rec_dict_139',\n",
              " 'rec_dict_14',\n",
              " 'rec_dict_140',\n",
              " 'rec_dict_141',\n",
              " 'rec_dict_142',\n",
              " 'rec_dict_143',\n",
              " 'rec_dict_144',\n",
              " 'rec_dict_145',\n",
              " 'rec_dict_146',\n",
              " 'rec_dict_147',\n",
              " 'rec_dict_148',\n",
              " 'rec_dict_149',\n",
              " 'rec_dict_15',\n",
              " 'rec_dict_150',\n",
              " 'rec_dict_151',\n",
              " 'rec_dict_152',\n",
              " 'rec_dict_153',\n",
              " 'rec_dict_154',\n",
              " 'rec_dict_155',\n",
              " 'rec_dict_156',\n",
              " 'rec_dict_157',\n",
              " 'rec_dict_158',\n",
              " 'rec_dict_159',\n",
              " 'rec_dict_16',\n",
              " 'rec_dict_160',\n",
              " 'rec_dict_161',\n",
              " 'rec_dict_162',\n",
              " 'rec_dict_163',\n",
              " 'rec_dict_164',\n",
              " 'rec_dict_165',\n",
              " 'rec_dict_166',\n",
              " 'rec_dict_167',\n",
              " 'rec_dict_168',\n",
              " 'rec_dict_169',\n",
              " 'rec_dict_17',\n",
              " 'rec_dict_170',\n",
              " 'rec_dict_171',\n",
              " 'rec_dict_172',\n",
              " 'rec_dict_173',\n",
              " 'rec_dict_174',\n",
              " 'rec_dict_175',\n",
              " 'rec_dict_176',\n",
              " 'rec_dict_177',\n",
              " 'rec_dict_178',\n",
              " 'rec_dict_179',\n",
              " 'rec_dict_18',\n",
              " 'rec_dict_180',\n",
              " 'rec_dict_181',\n",
              " 'rec_dict_182',\n",
              " 'rec_dict_183',\n",
              " 'rec_dict_184',\n",
              " 'rec_dict_185',\n",
              " 'rec_dict_186',\n",
              " 'rec_dict_187',\n",
              " 'rec_dict_188',\n",
              " 'rec_dict_189',\n",
              " 'rec_dict_19',\n",
              " 'rec_dict_190',\n",
              " 'rec_dict_191',\n",
              " 'rec_dict_192',\n",
              " 'rec_dict_193',\n",
              " 'rec_dict_194',\n",
              " 'rec_dict_195',\n",
              " 'rec_dict_196',\n",
              " 'rec_dict_197',\n",
              " 'rec_dict_198',\n",
              " 'rec_dict_199',\n",
              " 'rec_dict_2',\n",
              " 'rec_dict_20',\n",
              " 'rec_dict_200',\n",
              " 'rec_dict_201',\n",
              " 'rec_dict_202',\n",
              " 'rec_dict_203',\n",
              " 'rec_dict_204',\n",
              " 'rec_dict_205',\n",
              " 'rec_dict_206',\n",
              " 'rec_dict_207',\n",
              " 'rec_dict_208',\n",
              " 'rec_dict_209',\n",
              " 'rec_dict_21',\n",
              " 'rec_dict_210',\n",
              " 'rec_dict_211',\n",
              " 'rec_dict_212',\n",
              " 'rec_dict_213',\n",
              " 'rec_dict_214',\n",
              " 'rec_dict_215',\n",
              " 'rec_dict_216',\n",
              " 'rec_dict_217',\n",
              " 'rec_dict_218',\n",
              " 'rec_dict_219',\n",
              " 'rec_dict_22',\n",
              " 'rec_dict_220',\n",
              " 'rec_dict_221',\n",
              " 'rec_dict_222',\n",
              " 'rec_dict_223',\n",
              " 'rec_dict_224',\n",
              " 'rec_dict_225',\n",
              " 'rec_dict_226',\n",
              " 'rec_dict_227',\n",
              " 'rec_dict_228',\n",
              " 'rec_dict_229',\n",
              " 'rec_dict_23',\n",
              " 'rec_dict_230',\n",
              " 'rec_dict_231',\n",
              " 'rec_dict_232',\n",
              " 'rec_dict_233',\n",
              " 'rec_dict_234',\n",
              " 'rec_dict_235',\n",
              " 'rec_dict_236',\n",
              " 'rec_dict_237',\n",
              " 'rec_dict_238',\n",
              " 'rec_dict_239',\n",
              " 'rec_dict_24',\n",
              " 'rec_dict_240',\n",
              " 'rec_dict_241',\n",
              " 'rec_dict_242',\n",
              " 'rec_dict_243',\n",
              " 'rec_dict_244',\n",
              " 'rec_dict_245',\n",
              " 'rec_dict_246',\n",
              " 'rec_dict_247',\n",
              " 'rec_dict_248',\n",
              " 'rec_dict_249',\n",
              " 'rec_dict_25',\n",
              " 'rec_dict_250',\n",
              " 'rec_dict_26',\n",
              " 'rec_dict_27',\n",
              " 'rec_dict_28',\n",
              " 'rec_dict_29',\n",
              " 'rec_dict_3',\n",
              " 'rec_dict_30',\n",
              " 'rec_dict_31',\n",
              " 'rec_dict_32',\n",
              " 'rec_dict_33',\n",
              " 'rec_dict_34',\n",
              " 'rec_dict_35',\n",
              " 'rec_dict_36',\n",
              " 'rec_dict_37',\n",
              " 'rec_dict_38',\n",
              " 'rec_dict_39',\n",
              " 'rec_dict_4',\n",
              " 'rec_dict_40',\n",
              " 'rec_dict_41',\n",
              " 'rec_dict_42',\n",
              " 'rec_dict_43',\n",
              " 'rec_dict_44',\n",
              " 'rec_dict_45',\n",
              " 'rec_dict_46',\n",
              " 'rec_dict_47',\n",
              " 'rec_dict_48',\n",
              " 'rec_dict_49',\n",
              " 'rec_dict_5',\n",
              " 'rec_dict_50',\n",
              " 'rec_dict_51',\n",
              " 'rec_dict_52',\n",
              " 'rec_dict_53',\n",
              " 'rec_dict_54',\n",
              " 'rec_dict_55',\n",
              " 'rec_dict_56',\n",
              " 'rec_dict_57',\n",
              " 'rec_dict_58',\n",
              " 'rec_dict_59',\n",
              " 'rec_dict_6',\n",
              " 'rec_dict_60',\n",
              " 'rec_dict_61',\n",
              " 'rec_dict_62',\n",
              " 'rec_dict_63',\n",
              " 'rec_dict_64',\n",
              " 'rec_dict_65',\n",
              " 'rec_dict_66',\n",
              " 'rec_dict_67',\n",
              " 'rec_dict_68',\n",
              " 'rec_dict_69',\n",
              " 'rec_dict_7',\n",
              " 'rec_dict_70',\n",
              " 'rec_dict_71',\n",
              " 'rec_dict_72',\n",
              " 'rec_dict_73',\n",
              " 'rec_dict_74',\n",
              " 'rec_dict_75',\n",
              " 'rec_dict_76',\n",
              " 'rec_dict_77',\n",
              " 'rec_dict_78',\n",
              " 'rec_dict_79',\n",
              " 'rec_dict_8',\n",
              " 'rec_dict_80',\n",
              " 'rec_dict_81',\n",
              " 'rec_dict_82',\n",
              " 'rec_dict_83',\n",
              " 'rec_dict_84',\n",
              " 'rec_dict_85',\n",
              " 'rec_dict_86',\n",
              " 'rec_dict_87',\n",
              " 'rec_dict_88',\n",
              " 'rec_dict_89',\n",
              " 'rec_dict_9',\n",
              " 'rec_dict_90',\n",
              " 'rec_dict_91',\n",
              " 'rec_dict_92',\n",
              " 'rec_dict_93',\n",
              " 'rec_dict_94',\n",
              " 'rec_dict_95',\n",
              " 'rec_dict_96',\n",
              " 'rec_dict_97',\n",
              " 'rec_dict_98',\n",
              " 'rec_dict_99']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# feature 확인\n",
        "data[feature].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "aOOIgwbP-lUK",
        "outputId": "92dd8397-edf2-4381-b53e-394e4c6fc14f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b6990d51-b553-476f-9c5f-691778b2a483\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DL_GD_MCLS_NM_DIY자재/용품</th>\n",
              "      <th>DL_GD_MCLS_NM_PC</th>\n",
              "      <th>DL_GD_MCLS_NM_PC주변기기</th>\n",
              "      <th>DL_GD_MCLS_NM_가공식품</th>\n",
              "      <th>DL_GD_MCLS_NM_가방</th>\n",
              "      <th>DL_GD_MCLS_NM_건강식품</th>\n",
              "      <th>DL_GD_MCLS_NM_건강용품</th>\n",
              "      <th>DL_GD_MCLS_NM_게임기/타이틀</th>\n",
              "      <th>DL_GD_MCLS_NM_계절가전</th>\n",
              "      <th>DL_GD_MCLS_NM_골프</th>\n",
              "      <th>DL_GD_MCLS_NM_공구</th>\n",
              "      <th>DL_GD_MCLS_NM_과자</th>\n",
              "      <th>DL_GD_MCLS_NM_구강위생용품</th>\n",
              "      <th>DL_GD_MCLS_NM_기능성</th>\n",
              "      <th>DL_GD_MCLS_NM_기저귀/물티슈</th>\n",
              "      <th>DL_GD_MCLS_NM_기타디지털/가전</th>\n",
              "      <th>DL_GD_MCLS_NM_기타스포츠/레저</th>\n",
              "      <th>DL_GD_MCLS_NM_기타식품</th>\n",
              "      <th>DL_GD_MCLS_NM_기타출산/육아</th>\n",
              "      <th>DL_GD_MCLS_NM_기타패션의류</th>\n",
              "      <th>DL_GD_MCLS_NM_기타패션잡화</th>\n",
              "      <th>DL_GD_MCLS_NM_기타화장품/미용</th>\n",
              "      <th>DL_GD_MCLS_NM_김치</th>\n",
              "      <th>DL_GD_MCLS_NM_낚시</th>\n",
              "      <th>DL_GD_MCLS_NM_남성화장품</th>\n",
              "      <th>DL_GD_MCLS_NM_냉동/간편조리식품</th>\n",
              "      <th>DL_GD_MCLS_NM_네일케어</th>\n",
              "      <th>DL_GD_MCLS_NM_농산물</th>\n",
              "      <th>DL_GD_MCLS_NM_눈관리용품</th>\n",
              "      <th>DL_GD_MCLS_NM_다이어트식품</th>\n",
              "      <th>DL_GD_MCLS_NM_등산</th>\n",
              "      <th>DL_GD_MCLS_NM_모니터</th>\n",
              "      <th>DL_GD_MCLS_NM_모자</th>\n",
              "      <th>DL_GD_MCLS_NM_문구/사무용품</th>\n",
              "      <th>DL_GD_MCLS_NM_문화컨텐츠</th>\n",
              "      <th>DL_GD_MCLS_NM_바디케어</th>\n",
              "      <th>DL_GD_MCLS_NM_반려동물</th>\n",
              "      <th>DL_GD_MCLS_NM_반찬</th>\n",
              "      <th>DL_GD_MCLS_NM_베이스메이크업</th>\n",
              "      <th>DL_GD_MCLS_NM_분유/이유식/아기간식</th>\n",
              "      <th>...</th>\n",
              "      <th>rec_dict_63</th>\n",
              "      <th>rec_dict_64</th>\n",
              "      <th>rec_dict_65</th>\n",
              "      <th>rec_dict_66</th>\n",
              "      <th>rec_dict_67</th>\n",
              "      <th>rec_dict_68</th>\n",
              "      <th>rec_dict_69</th>\n",
              "      <th>rec_dict_7</th>\n",
              "      <th>rec_dict_70</th>\n",
              "      <th>rec_dict_71</th>\n",
              "      <th>rec_dict_72</th>\n",
              "      <th>rec_dict_73</th>\n",
              "      <th>rec_dict_74</th>\n",
              "      <th>rec_dict_75</th>\n",
              "      <th>rec_dict_76</th>\n",
              "      <th>rec_dict_77</th>\n",
              "      <th>rec_dict_78</th>\n",
              "      <th>rec_dict_79</th>\n",
              "      <th>rec_dict_8</th>\n",
              "      <th>rec_dict_80</th>\n",
              "      <th>rec_dict_81</th>\n",
              "      <th>rec_dict_82</th>\n",
              "      <th>rec_dict_83</th>\n",
              "      <th>rec_dict_84</th>\n",
              "      <th>rec_dict_85</th>\n",
              "      <th>rec_dict_86</th>\n",
              "      <th>rec_dict_87</th>\n",
              "      <th>rec_dict_88</th>\n",
              "      <th>rec_dict_89</th>\n",
              "      <th>rec_dict_9</th>\n",
              "      <th>rec_dict_90</th>\n",
              "      <th>rec_dict_91</th>\n",
              "      <th>rec_dict_92</th>\n",
              "      <th>rec_dict_93</th>\n",
              "      <th>rec_dict_94</th>\n",
              "      <th>rec_dict_95</th>\n",
              "      <th>rec_dict_96</th>\n",
              "      <th>rec_dict_97</th>\n",
              "      <th>rec_dict_98</th>\n",
              "      <th>rec_dict_99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 588 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6990d51-b553-476f-9c5f-691778b2a483')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b6990d51-b553-476f-9c5f-691778b2a483 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b6990d51-b553-476f-9c5f-691778b2a483');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   DL_GD_MCLS_NM_DIY자재/용품  DL_GD_MCLS_NM_PC  ...  rec_dict_98  rec_dict_99\n",
              "0                       0                 0  ...            0            0\n",
              "1                       0                 0  ...            0            0\n",
              "2                       0                 0  ...            0            0\n",
              "3                       0                 0  ...            0            0\n",
              "4                       0                 0  ...            0            0\n",
              "\n",
              "[5 rows x 588 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "물품 카테고리를 포함한 feature 를 one-hot encoding 하였으며 \n",
        "\n",
        "물품 카테고리 + 송하인 주소 + 수하인 주소를 모두 합쳐서 581개의 칼럼이 생성되었다."
      ],
      "metadata": {
        "id": "vP5-lijLf-rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 같은 방식으로 테스트 데이터셋 칼럼 가공\n",
        "test['round_send']=test.SEND_SPG_INNB.round(-10)\n",
        "test['round_rec']=test.REC_SPG_INNB.round(-10)"
      ],
      "metadata": {
        "id": "pkKGJBuT-vSN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expnum=[]\n",
        "from tqdm import tqdm\n",
        "for _ in tqdm(range(len(test))):\n",
        "\n",
        "    test.loc[_,'send_dict']=str(nn[test['round_send'][_]])\n",
        "    test.loc[_,'rec_dict']=str(nn[test['round_rec'][_]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIcjajr8_TPX",
        "outputId": "c5cd8074-0b7b-432c-9df2-1e78874a22fe"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7920/7920 [00:08<00:00, 956.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test=pd.get_dummies(test)\n",
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "_QEOrQCP_W_o",
        "outputId": "c3b9711c-a050-42dd-865e-e7d7541c2084"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0fe16922-229a-471f-89e8-0d4688733b4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>SEND_SPG_INNB</th>\n",
              "      <th>REC_SPG_INNB</th>\n",
              "      <th>round_send</th>\n",
              "      <th>round_rec</th>\n",
              "      <th>DL_GD_MCLS_NM_DIY자재/용품</th>\n",
              "      <th>DL_GD_MCLS_NM_PC</th>\n",
              "      <th>DL_GD_MCLS_NM_PC주변기기</th>\n",
              "      <th>DL_GD_MCLS_NM_가공식품</th>\n",
              "      <th>DL_GD_MCLS_NM_가방</th>\n",
              "      <th>DL_GD_MCLS_NM_건강식품</th>\n",
              "      <th>DL_GD_MCLS_NM_건강용품</th>\n",
              "      <th>DL_GD_MCLS_NM_게임기/타이틀</th>\n",
              "      <th>DL_GD_MCLS_NM_계절가전</th>\n",
              "      <th>DL_GD_MCLS_NM_골프</th>\n",
              "      <th>DL_GD_MCLS_NM_공구</th>\n",
              "      <th>DL_GD_MCLS_NM_과자</th>\n",
              "      <th>DL_GD_MCLS_NM_구강위생용품</th>\n",
              "      <th>DL_GD_MCLS_NM_기능성</th>\n",
              "      <th>DL_GD_MCLS_NM_기저귀/물티슈</th>\n",
              "      <th>DL_GD_MCLS_NM_기타디지털/가전</th>\n",
              "      <th>DL_GD_MCLS_NM_기타스포츠/레저</th>\n",
              "      <th>DL_GD_MCLS_NM_기타식품</th>\n",
              "      <th>DL_GD_MCLS_NM_기타출산/육아</th>\n",
              "      <th>DL_GD_MCLS_NM_기타패션의류</th>\n",
              "      <th>DL_GD_MCLS_NM_기타패션잡화</th>\n",
              "      <th>DL_GD_MCLS_NM_기타화장품/미용</th>\n",
              "      <th>DL_GD_MCLS_NM_김치</th>\n",
              "      <th>DL_GD_MCLS_NM_낚시</th>\n",
              "      <th>DL_GD_MCLS_NM_남성화장품</th>\n",
              "      <th>DL_GD_MCLS_NM_냉동/간편조리식품</th>\n",
              "      <th>DL_GD_MCLS_NM_네일케어</th>\n",
              "      <th>DL_GD_MCLS_NM_농산물</th>\n",
              "      <th>DL_GD_MCLS_NM_눈관리용품</th>\n",
              "      <th>DL_GD_MCLS_NM_다이어트식품</th>\n",
              "      <th>DL_GD_MCLS_NM_등산</th>\n",
              "      <th>DL_GD_MCLS_NM_모니터</th>\n",
              "      <th>DL_GD_MCLS_NM_모자</th>\n",
              "      <th>DL_GD_MCLS_NM_문구/사무용품</th>\n",
              "      <th>DL_GD_MCLS_NM_문화컨텐츠</th>\n",
              "      <th>...</th>\n",
              "      <th>rec_dict_63</th>\n",
              "      <th>rec_dict_64</th>\n",
              "      <th>rec_dict_65</th>\n",
              "      <th>rec_dict_66</th>\n",
              "      <th>rec_dict_67</th>\n",
              "      <th>rec_dict_68</th>\n",
              "      <th>rec_dict_69</th>\n",
              "      <th>rec_dict_7</th>\n",
              "      <th>rec_dict_70</th>\n",
              "      <th>rec_dict_71</th>\n",
              "      <th>rec_dict_72</th>\n",
              "      <th>rec_dict_73</th>\n",
              "      <th>rec_dict_74</th>\n",
              "      <th>rec_dict_75</th>\n",
              "      <th>rec_dict_76</th>\n",
              "      <th>rec_dict_77</th>\n",
              "      <th>rec_dict_78</th>\n",
              "      <th>rec_dict_79</th>\n",
              "      <th>rec_dict_8</th>\n",
              "      <th>rec_dict_80</th>\n",
              "      <th>rec_dict_81</th>\n",
              "      <th>rec_dict_82</th>\n",
              "      <th>rec_dict_83</th>\n",
              "      <th>rec_dict_84</th>\n",
              "      <th>rec_dict_85</th>\n",
              "      <th>rec_dict_86</th>\n",
              "      <th>rec_dict_87</th>\n",
              "      <th>rec_dict_88</th>\n",
              "      <th>rec_dict_89</th>\n",
              "      <th>rec_dict_9</th>\n",
              "      <th>rec_dict_90</th>\n",
              "      <th>rec_dict_91</th>\n",
              "      <th>rec_dict_92</th>\n",
              "      <th>rec_dict_93</th>\n",
              "      <th>rec_dict_94</th>\n",
              "      <th>rec_dict_95</th>\n",
              "      <th>rec_dict_96</th>\n",
              "      <th>rec_dict_97</th>\n",
              "      <th>rec_dict_98</th>\n",
              "      <th>rec_dict_99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>4167000577042200</td>\n",
              "      <td>5011000435014100</td>\n",
              "      <td>4167000000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1156000009012200</td>\n",
              "      <td>5011000172034400</td>\n",
              "      <td>1156000000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4122000363057300</td>\n",
              "      <td>5011000361097300</td>\n",
              "      <td>4122000000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>5011000436041400</td>\n",
              "      <td>2826000084036400</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>2826000000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4150000241065200</td>\n",
              "      <td>5011000169044300</td>\n",
              "      <td>4150000000000000</td>\n",
              "      <td>5011000000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 551 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fe16922-229a-471f-89e8-0d4688733b4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0fe16922-229a-471f-89e8-0d4688733b4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0fe16922-229a-471f-89e8-0d4688733b4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   index     SEND_SPG_INNB  ...  rec_dict_98  rec_dict_99\n",
              "0      0  4167000577042200  ...            0            0\n",
              "1      1  1156000009012200  ...            0            0\n",
              "2      2  4122000363057300  ...            0            0\n",
              "3      3  5011000436041400  ...            0            0\n",
              "4      4  4150000241065200  ...            0            0\n",
              "\n",
              "[5 rows x 551 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for f in tqdm(feature):\n",
        "    if f in list(test.columns):\n",
        "        pass\n",
        "    else:\n",
        "        test[f]=int(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwH8BNbp_a4a",
        "outputId": "c27f8a83-6447-4e9a-9b42-bcb301abe9a2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 588/588 [00:00<00:00, 9747.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_input=test[feature]\n",
        "test_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "0B6YoiQd_dcx",
        "outputId": "5c591481-31b0-49f5-856c-f2e54ecef699"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fcc7c111-ec14-46d0-b16b-1ed3ec672ad0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DL_GD_MCLS_NM_DIY자재/용품</th>\n",
              "      <th>DL_GD_MCLS_NM_PC</th>\n",
              "      <th>DL_GD_MCLS_NM_PC주변기기</th>\n",
              "      <th>DL_GD_MCLS_NM_가공식품</th>\n",
              "      <th>DL_GD_MCLS_NM_가방</th>\n",
              "      <th>DL_GD_MCLS_NM_건강식품</th>\n",
              "      <th>DL_GD_MCLS_NM_건강용품</th>\n",
              "      <th>DL_GD_MCLS_NM_게임기/타이틀</th>\n",
              "      <th>DL_GD_MCLS_NM_계절가전</th>\n",
              "      <th>DL_GD_MCLS_NM_골프</th>\n",
              "      <th>DL_GD_MCLS_NM_공구</th>\n",
              "      <th>DL_GD_MCLS_NM_과자</th>\n",
              "      <th>DL_GD_MCLS_NM_구강위생용품</th>\n",
              "      <th>DL_GD_MCLS_NM_기능성</th>\n",
              "      <th>DL_GD_MCLS_NM_기저귀/물티슈</th>\n",
              "      <th>DL_GD_MCLS_NM_기타디지털/가전</th>\n",
              "      <th>DL_GD_MCLS_NM_기타스포츠/레저</th>\n",
              "      <th>DL_GD_MCLS_NM_기타식품</th>\n",
              "      <th>DL_GD_MCLS_NM_기타출산/육아</th>\n",
              "      <th>DL_GD_MCLS_NM_기타패션의류</th>\n",
              "      <th>DL_GD_MCLS_NM_기타패션잡화</th>\n",
              "      <th>DL_GD_MCLS_NM_기타화장품/미용</th>\n",
              "      <th>DL_GD_MCLS_NM_김치</th>\n",
              "      <th>DL_GD_MCLS_NM_낚시</th>\n",
              "      <th>DL_GD_MCLS_NM_남성화장품</th>\n",
              "      <th>DL_GD_MCLS_NM_냉동/간편조리식품</th>\n",
              "      <th>DL_GD_MCLS_NM_네일케어</th>\n",
              "      <th>DL_GD_MCLS_NM_농산물</th>\n",
              "      <th>DL_GD_MCLS_NM_눈관리용품</th>\n",
              "      <th>DL_GD_MCLS_NM_다이어트식품</th>\n",
              "      <th>DL_GD_MCLS_NM_등산</th>\n",
              "      <th>DL_GD_MCLS_NM_모니터</th>\n",
              "      <th>DL_GD_MCLS_NM_모자</th>\n",
              "      <th>DL_GD_MCLS_NM_문구/사무용품</th>\n",
              "      <th>DL_GD_MCLS_NM_문화컨텐츠</th>\n",
              "      <th>DL_GD_MCLS_NM_바디케어</th>\n",
              "      <th>DL_GD_MCLS_NM_반려동물</th>\n",
              "      <th>DL_GD_MCLS_NM_반찬</th>\n",
              "      <th>DL_GD_MCLS_NM_베이스메이크업</th>\n",
              "      <th>DL_GD_MCLS_NM_분유/이유식/아기간식</th>\n",
              "      <th>...</th>\n",
              "      <th>rec_dict_63</th>\n",
              "      <th>rec_dict_64</th>\n",
              "      <th>rec_dict_65</th>\n",
              "      <th>rec_dict_66</th>\n",
              "      <th>rec_dict_67</th>\n",
              "      <th>rec_dict_68</th>\n",
              "      <th>rec_dict_69</th>\n",
              "      <th>rec_dict_7</th>\n",
              "      <th>rec_dict_70</th>\n",
              "      <th>rec_dict_71</th>\n",
              "      <th>rec_dict_72</th>\n",
              "      <th>rec_dict_73</th>\n",
              "      <th>rec_dict_74</th>\n",
              "      <th>rec_dict_75</th>\n",
              "      <th>rec_dict_76</th>\n",
              "      <th>rec_dict_77</th>\n",
              "      <th>rec_dict_78</th>\n",
              "      <th>rec_dict_79</th>\n",
              "      <th>rec_dict_8</th>\n",
              "      <th>rec_dict_80</th>\n",
              "      <th>rec_dict_81</th>\n",
              "      <th>rec_dict_82</th>\n",
              "      <th>rec_dict_83</th>\n",
              "      <th>rec_dict_84</th>\n",
              "      <th>rec_dict_85</th>\n",
              "      <th>rec_dict_86</th>\n",
              "      <th>rec_dict_87</th>\n",
              "      <th>rec_dict_88</th>\n",
              "      <th>rec_dict_89</th>\n",
              "      <th>rec_dict_9</th>\n",
              "      <th>rec_dict_90</th>\n",
              "      <th>rec_dict_91</th>\n",
              "      <th>rec_dict_92</th>\n",
              "      <th>rec_dict_93</th>\n",
              "      <th>rec_dict_94</th>\n",
              "      <th>rec_dict_95</th>\n",
              "      <th>rec_dict_96</th>\n",
              "      <th>rec_dict_97</th>\n",
              "      <th>rec_dict_98</th>\n",
              "      <th>rec_dict_99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7915</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7916</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7917</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7918</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7919</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7920 rows × 588 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcc7c111-ec14-46d0-b16b-1ed3ec672ad0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcc7c111-ec14-46d0-b16b-1ed3ec672ad0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcc7c111-ec14-46d0-b16b-1ed3ec672ad0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      DL_GD_MCLS_NM_DIY자재/용품  DL_GD_MCLS_NM_PC  ...  rec_dict_98  rec_dict_99\n",
              "0                          0                 0  ...            0            0\n",
              "1                          0                 0  ...            0            0\n",
              "2                          0                 0  ...            0            0\n",
              "3                          0                 0  ...            0            0\n",
              "4                          0                 0  ...            0            0\n",
              "...                      ...               ...  ...          ...          ...\n",
              "7915                       0                 0  ...            0            0\n",
              "7916                       0                 0  ...            0            0\n",
              "7917                       0                 0  ...            0            0\n",
              "7918                       0                 0  ...            0            0\n",
              "7919                       0                 0  ...            0            0\n",
              "\n",
              "[7920 rows x 588 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "MBSTxx-Fv0jp",
        "outputId": "02b5101a-6d52-42f0-e001-f74982e5ea64"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-051b6c41-bf43-4392-9555-94a581b617c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DL_GD_MCLS_NM_DIY자재/용품</th>\n",
              "      <th>DL_GD_MCLS_NM_PC</th>\n",
              "      <th>DL_GD_MCLS_NM_PC주변기기</th>\n",
              "      <th>DL_GD_MCLS_NM_가공식품</th>\n",
              "      <th>DL_GD_MCLS_NM_가방</th>\n",
              "      <th>DL_GD_MCLS_NM_건강식품</th>\n",
              "      <th>DL_GD_MCLS_NM_건강용품</th>\n",
              "      <th>DL_GD_MCLS_NM_게임기/타이틀</th>\n",
              "      <th>DL_GD_MCLS_NM_계절가전</th>\n",
              "      <th>DL_GD_MCLS_NM_골프</th>\n",
              "      <th>DL_GD_MCLS_NM_공구</th>\n",
              "      <th>DL_GD_MCLS_NM_과자</th>\n",
              "      <th>DL_GD_MCLS_NM_구강위생용품</th>\n",
              "      <th>DL_GD_MCLS_NM_기능성</th>\n",
              "      <th>DL_GD_MCLS_NM_기저귀/물티슈</th>\n",
              "      <th>DL_GD_MCLS_NM_기타디지털/가전</th>\n",
              "      <th>DL_GD_MCLS_NM_기타스포츠/레저</th>\n",
              "      <th>DL_GD_MCLS_NM_기타식품</th>\n",
              "      <th>DL_GD_MCLS_NM_기타출산/육아</th>\n",
              "      <th>DL_GD_MCLS_NM_기타패션의류</th>\n",
              "      <th>DL_GD_MCLS_NM_기타패션잡화</th>\n",
              "      <th>DL_GD_MCLS_NM_기타화장품/미용</th>\n",
              "      <th>DL_GD_MCLS_NM_김치</th>\n",
              "      <th>DL_GD_MCLS_NM_낚시</th>\n",
              "      <th>DL_GD_MCLS_NM_남성화장품</th>\n",
              "      <th>DL_GD_MCLS_NM_냉동/간편조리식품</th>\n",
              "      <th>DL_GD_MCLS_NM_네일케어</th>\n",
              "      <th>DL_GD_MCLS_NM_농산물</th>\n",
              "      <th>DL_GD_MCLS_NM_눈관리용품</th>\n",
              "      <th>DL_GD_MCLS_NM_다이어트식품</th>\n",
              "      <th>DL_GD_MCLS_NM_등산</th>\n",
              "      <th>DL_GD_MCLS_NM_모니터</th>\n",
              "      <th>DL_GD_MCLS_NM_모자</th>\n",
              "      <th>DL_GD_MCLS_NM_문구/사무용품</th>\n",
              "      <th>DL_GD_MCLS_NM_문화컨텐츠</th>\n",
              "      <th>DL_GD_MCLS_NM_바디케어</th>\n",
              "      <th>DL_GD_MCLS_NM_반려동물</th>\n",
              "      <th>DL_GD_MCLS_NM_반찬</th>\n",
              "      <th>DL_GD_MCLS_NM_베이스메이크업</th>\n",
              "      <th>DL_GD_MCLS_NM_분유/이유식/아기간식</th>\n",
              "      <th>...</th>\n",
              "      <th>rec_dict_63</th>\n",
              "      <th>rec_dict_64</th>\n",
              "      <th>rec_dict_65</th>\n",
              "      <th>rec_dict_66</th>\n",
              "      <th>rec_dict_67</th>\n",
              "      <th>rec_dict_68</th>\n",
              "      <th>rec_dict_69</th>\n",
              "      <th>rec_dict_7</th>\n",
              "      <th>rec_dict_70</th>\n",
              "      <th>rec_dict_71</th>\n",
              "      <th>rec_dict_72</th>\n",
              "      <th>rec_dict_73</th>\n",
              "      <th>rec_dict_74</th>\n",
              "      <th>rec_dict_75</th>\n",
              "      <th>rec_dict_76</th>\n",
              "      <th>rec_dict_77</th>\n",
              "      <th>rec_dict_78</th>\n",
              "      <th>rec_dict_79</th>\n",
              "      <th>rec_dict_8</th>\n",
              "      <th>rec_dict_80</th>\n",
              "      <th>rec_dict_81</th>\n",
              "      <th>rec_dict_82</th>\n",
              "      <th>rec_dict_83</th>\n",
              "      <th>rec_dict_84</th>\n",
              "      <th>rec_dict_85</th>\n",
              "      <th>rec_dict_86</th>\n",
              "      <th>rec_dict_87</th>\n",
              "      <th>rec_dict_88</th>\n",
              "      <th>rec_dict_89</th>\n",
              "      <th>rec_dict_9</th>\n",
              "      <th>rec_dict_90</th>\n",
              "      <th>rec_dict_91</th>\n",
              "      <th>rec_dict_92</th>\n",
              "      <th>rec_dict_93</th>\n",
              "      <th>rec_dict_94</th>\n",
              "      <th>rec_dict_95</th>\n",
              "      <th>rec_dict_96</th>\n",
              "      <th>rec_dict_97</th>\n",
              "      <th>rec_dict_98</th>\n",
              "      <th>rec_dict_99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7915</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7916</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7917</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7918</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7919</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7920 rows × 588 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-051b6c41-bf43-4392-9555-94a581b617c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-051b6c41-bf43-4392-9555-94a581b617c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-051b6c41-bf43-4392-9555-94a581b617c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      DL_GD_MCLS_NM_DIY자재/용품  DL_GD_MCLS_NM_PC  ...  rec_dict_98  rec_dict_99\n",
              "0                          0                 0  ...            0            0\n",
              "1                          0                 0  ...            0            0\n",
              "2                          0                 0  ...            0            0\n",
              "3                          0                 0  ...            0            0\n",
              "4                          0                 0  ...            0            0\n",
              "...                      ...               ...  ...          ...          ...\n",
              "7915                       0                 0  ...            0            0\n",
              "7916                       0                 0  ...            0            0\n",
              "7917                       0                 0  ...            0            0\n",
              "7918                       0                 0  ...            0            0\n",
              "7919                       0                 0  ...            0            0\n",
              "\n",
              "[7920 rows x 588 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 모델링 진행"
      ],
      "metadata": {
        "id": "gp8tbkuUhBxC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) pycaret 을 이용한 모델 선택"
      ],
      "metadata": {
        "id": "crdn-CiYp__r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pycaret"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfjfas4BLjKm",
        "outputId": "e73a164f-f464-493f-e2c2-440961f0a197"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycaret in /usr/local/lib/python3.7/dist-packages (2.3.6)\n",
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.3.7)\n",
            "Requirement already satisfied: gensim<4.0.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.6.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn==0.23.2 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.23.2)\n",
            "Requirement already satisfied: yellowbrick>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.3.post1)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.3.2)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.15.3)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.23.1)\n",
            "Requirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (5.5.0)\n",
            "Requirement already satisfied: imbalanced-learn==0.7.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.7.0)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.5.0)\n",
            "Requirement already satisfied: pyod in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.9.7)\n",
            "Requirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.17.3)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.11.2)\n",
            "Requirement already satisfied: scipy<=1.5.4 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.5.4)\n",
            "Requirement already satisfied: pyyaml<6.0.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (5.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from pycaret) (7.6.5)\n",
            "Requirement already satisfied: spacy<2.4.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (2.2.4)\n",
            "Requirement already satisfied: kmodes>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.11.1)\n",
            "Requirement already satisfied: pandas-profiling>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.1.0)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.3.5)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from pycaret) (5.5.0)\n",
            "Requirement already satisfied: Boruta in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.5)\n",
            "Requirement already satisfied: mlxtend>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn==0.7.0->pycaret) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->pycaret) (3.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (57.4.0)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (0.3.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->pycaret) (5.2.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (0.7.5)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (3.5.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (5.1.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (4.10.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (1.0.2)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.3.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->pycaret) (0.37.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (1.3.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.9.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (4.11.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (5.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (3.10.0.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (0.18.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (3.7.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pycaret) (2018.9)\n",
            "Requirement already satisfied: tangled-up-in-unicode==0.1.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.1.0)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.27.1)\n",
            "Requirement already satisfied: htmlmin>=0.1.12 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.1.12)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.5.0)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.11.3)\n",
            "Requirement already satisfied: markupsafe~=2.0.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.0.1)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (4.62.3)\n",
            "Requirement already satisfied: visions[type_image_path]==0.7.4 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.7.4)\n",
            "Requirement already satisfied: pydantic>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (1.9.0)\n",
            "Requirement already satisfied: phik>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.12.0)\n",
            "Requirement already satisfied: multimethod>=1.4 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (1.7)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (2.6.3)\n",
            "Requirement already satisfied: imagehash in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (4.2.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (7.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.4.1->pycaret) (8.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->pycaret) (0.2.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2.10)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (2.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (0.9.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (3.0.6)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.13.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.0)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash->visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (1.2.0)\n",
            "Requirement already satisfied: prometheus-flask-exporter in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.18.7)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.4.31)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.3.0)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.7.6)\n",
            "Requirement already satisfied: gunicorn in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (20.1.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (7.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (21.3)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.4.2)\n",
            "Requirement already satisfied: docker>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (5.0.3)\n",
            "Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (3.17.3)\n",
            "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.2.4)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.1.4)\n",
            "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (3.1.27)\n",
            "Requirement already satisfied: databricks-cli>=0.8.7 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.16.4)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow->pycaret) (0.8.9)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from docker>=4.0.0->mlflow->pycaret) (1.3.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow->pycaret) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow->pycaret) (5.0.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->mlflow->pycaret) (1.1.6)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow->pycaret) (1.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret) (1.0.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (4.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow->pycaret) (0.13.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (0.16.0)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (1.17)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (2.8.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod->pycaret) (0.10.2)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.7/dist-packages (from pyod->pycaret) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod->pycaret) (0.34.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod->pycaret) (0.5.2)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn->pycaret) (0.5.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install --use-deprecated=legacy-resolver pycaret[full] # 위의 코드 불가시 사용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZMvFkY4Mb6M",
        "outputId": "cebc1dc1-2b39-45cb-b37d-2bcdc4b21489"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycaret[full] in /usr/local/lib/python3.7/dist-packages (2.3.6)\n",
            "Requirement already satisfied: pyyaml<6.0.0 in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (5.4.1)\n",
            "Requirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (5.5.0)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (5.5.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (7.6.5)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (3.2.2)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.15.3)\n",
            "Requirement already satisfied: gensim<4.0.0 in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (3.6.0)\n",
            "Requirement already satisfied: pyod in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.9.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (3.2.2)\n",
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.3.7)\n",
            "Requirement already satisfied: kmodes>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.11.1)\n",
            "Requirement already satisfied: scipy<=1.5.4 in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (1.5.4)\n",
            "Requirement already satisfied: pandas-profiling>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (3.1.0)\n",
            "Requirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.17.3)\n",
            "Requirement already satisfied: yellowbrick>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (1.3.post1)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.5.2)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (1.23.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (1.3.5)\n",
            "Requirement already satisfied: imbalanced-learn==0.7.0 in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.7.0)\n",
            "Requirement already satisfied: mlxtend>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.19.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (1.0.1)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (3.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (3.2.5)\n",
            "Requirement already satisfied: scikit-learn==0.23.2 in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.23.2)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (1.5.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.11.2)\n",
            "Requirement already satisfied: spacy<2.4.0 in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (2.2.4)\n",
            "Requirement already satisfied: Boruta in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.3)\n",
            "Requirement already satisfied: boto3; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (1.21.8)\n",
            "Requirement already satisfied: psutil; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (5.4.8)\n",
            "Requirement already satisfied: hyperopt; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.1.2)\n",
            "Requirement already satisfied: google-cloud-storage; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (1.18.1)\n",
            "Requirement already satisfied: uvicorn; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.17.5)\n",
            "Requirement already satisfied: gradio; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (2.8.5)\n",
            "Requirement already satisfied: m2cgen; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.9.0)\n",
            "Requirement already satisfied: fastapi; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.74.1)\n",
            "Requirement already satisfied: explainerdashboard; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.3.8)\n",
            "Requirement already satisfied: tune-sklearn>=0.2.1; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.4.1)\n",
            "Requirement already satisfied: ray[tune]>=1.0.0; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (1.10.0)\n",
            "Requirement already satisfied: optuna>=2.2.0; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (2.10.0)\n",
            "Requirement already satisfied: scikit-optimize>=0.8.1; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.9.0)\n",
            "Requirement already satisfied: shap; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.40.0)\n",
            "Requirement already satisfied: xgboost>=1.1.0; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (1.5.2)\n",
            "Requirement already satisfied: interpret<=0.2.4; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.2.4)\n",
            "Requirement already satisfied: fairlearn; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.7.0)\n",
            "Requirement already satisfied: azure-storage-blob; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (12.9.0)\n",
            "Requirement already satisfied: catboost>=0.23.2; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (1.0.4)\n",
            "Requirement already satisfied: autoviz; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.1.36)\n",
            "Requirement already satisfied: evidently; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from pycaret[full]) (0.1.45.dev0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.4.1->pycaret[full]) (8.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly>=4.4.1->pycaret[full]) (1.15.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret[full]) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret[full]) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret[full]) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret[full]) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret[full]) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret[full]) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret[full]) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret[full]) (0.7.5)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret[full]) (3.5.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret[full]) (5.1.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret[full]) (4.10.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret[full]) (1.0.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret[full]) (0.2.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret[full]) (2.8.1)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret[full]) (1.17)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret[full]) (0.16.0)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret[full]) (0.37.1)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret[full]) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret[full]) (1.19.5)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->pycaret[full]) (5.2.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod->pycaret[full]) (0.10.2)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.7/dist-packages (from pyod->pycaret[full]) (0.51.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret[full]) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret[full]) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret[full]) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret[full]) (0.11.0)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret[full]) (0.5.0)\n",
            "Requirement already satisfied: tangled-up-in-unicode==0.1.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret[full]) (0.1.0)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret[full]) (2.27.1)\n",
            "Requirement already satisfied: markupsafe~=2.0.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret[full]) (2.0.1)\n",
            "Requirement already satisfied: htmlmin>=0.1.12 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret[full]) (0.1.12)\n",
            "Requirement already satisfied: pydantic>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret[full]) (1.9.0)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret[full]) (4.62.3)\n",
            "Requirement already satisfied: multimethod>=1.4 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret[full]) (1.7)\n",
            "Requirement already satisfied: phik>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret[full]) (0.12.0)\n",
            "Requirement already satisfied: visions[type_image_path]==0.7.4 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret[full]) (0.7.4)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret[full]) (0.3.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn->pycaret[full]) (0.5.6)\n",
            "Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret[full]) (3.17.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret[full]) (1.3.0)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret[full]) (0.4.2)\n",
            "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret[full]) (1.2.4)\n",
            "Requirement already satisfied: prometheus-flask-exporter in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret[full]) (0.18.7)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret[full]) (1.4.31)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret[full]) (7.1.2)\n",
            "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret[full]) (3.1.27)\n",
            "Requirement already satisfied: docker>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret[full]) (5.0.3)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret[full]) (1.1.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret[full]) (2018.9)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret[full]) (0.4)\n",
            "Requirement already satisfied: databricks-cli>=0.8.7 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret[full]) (0.16.4)\n",
            "Requirement already satisfied: gunicorn; platform_system != \"Windows\" in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret[full]) (20.1.0)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret[full]) (1.7.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret[full]) (21.3)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret[full]) (4.11.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->pycaret[full]) (3.1.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud->pycaret[full]) (7.1.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret[full]) (0.9.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret[full]) (2.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret[full]) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret[full]) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret[full]) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret[full]) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret[full]) (1.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret[full]) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret[full]) (1.0.5)\n",
            "Requirement already satisfied: botocore<1.25.0,>=1.24.8 in /usr/local/lib/python3.7/dist-packages (from boto3; extra == \"full\"->pycaret[full]) (1.24.8)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3; extra == \"full\"->pycaret[full]) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3; extra == \"full\"->pycaret[full]) (0.5.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt; extra == \"full\"->pycaret[full]) (2.6.3)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt; extra == \"full\"->pycaret[full]) (4.0.1)\n",
            "Requirement already satisfied: google-auth>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage; extra == \"full\"->pycaret[full]) (1.35.0)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage; extra == \"full\"->pycaret[full]) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage; extra == \"full\"->pycaret[full]) (1.0.3)\n",
            "Requirement already satisfied: asgiref>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn; extra == \"full\"->pycaret[full]) (3.5.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.7/dist-packages (from uvicorn; extra == \"full\"->pycaret[full]) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from uvicorn; extra == \"full\"->pycaret[full]) (3.10.0.2)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.7/dist-packages (from gradio; extra == \"full\"->pycaret[full]) (3.6.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (from gradio; extra == \"full\"->pycaret[full]) (0.25.1)\n",
            "Requirement already satisfied: analytics-python in /usr/local/lib/python3.7/dist-packages (from gradio; extra == \"full\"->pycaret[full]) (1.4.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.7/dist-packages (from gradio; extra == \"full\"->pycaret[full]) (3.14.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.7/dist-packages (from gradio; extra == \"full\"->pycaret[full]) (0.3.0)\n",
            "Requirement already satisfied: paramiko in /usr/local/lib/python3.7/dist-packages (from gradio; extra == \"full\"->pycaret[full]) (2.9.2)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.7/dist-packages (from gradio; extra == \"full\"->pycaret[full]) (0.0.5)\n",
            "Requirement already satisfied: markdown-it-py[linkify,plugins] in /usr/local/lib/python3.7/dist-packages (from gradio; extra == \"full\"->pycaret[full]) (2.0.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from gradio; extra == \"full\"->pycaret[full]) (3.8.1)\n",
            "Requirement already satisfied: starlette==0.17.1 in /usr/local/lib/python3.7/dist-packages (from fastapi; extra == \"full\"->pycaret[full]) (0.17.1)\n",
            "Requirement already satisfied: dash-bootstrap-components<1 in /usr/local/lib/python3.7/dist-packages (from explainerdashboard; extra == \"full\"->pycaret[full]) (0.13.1)\n",
            "Requirement already satisfied: flask-simplelogin in /usr/local/lib/python3.7/dist-packages (from explainerdashboard; extra == \"full\"->pycaret[full]) (0.1.1)\n",
            "Requirement already satisfied: dtreeviz>=1.3 in /usr/local/lib/python3.7/dist-packages (from explainerdashboard; extra == \"full\"->pycaret[full]) (1.3.3)\n",
            "Requirement already satisfied: waitress in /usr/local/lib/python3.7/dist-packages (from explainerdashboard; extra == \"full\"->pycaret[full]) (2.0.0)\n",
            "Requirement already satisfied: oyaml in /usr/local/lib/python3.7/dist-packages (from explainerdashboard; extra == \"full\"->pycaret[full]) (1.0)\n",
            "Requirement already satisfied: dash-auth in /usr/local/lib/python3.7/dist-packages (from explainerdashboard; extra == \"full\"->pycaret[full]) (1.4.1)\n",
            "Requirement already satisfied: jupyter-dash in /usr/local/lib/python3.7/dist-packages (from explainerdashboard; extra == \"full\"->pycaret[full]) (0.4.1)\n",
            "Requirement already satisfied: dash>=2 in /usr/local/lib/python3.7/dist-packages (from explainerdashboard; extra == \"full\"->pycaret[full]) (2.2.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (21.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (3.6.0)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (1.43.0)\n",
            "Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (4.1.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (4.3.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (1.0.3)\n",
            "Requirement already satisfied: tensorboardX>=1.9; extra == \"tune\" in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (2.5)\n",
            "Requirement already satisfied: tabulate; extra == \"tune\" in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (0.8.9)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna>=2.2.0; extra == \"full\"->pycaret[full]) (0.8.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna>=2.2.0; extra == \"full\"->pycaret[full]) (6.6.0)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna>=2.2.0; extra == \"full\"->pycaret[full]) (3.10.1)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize>=0.8.1; extra == \"full\"->pycaret[full]) (21.10.1)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.7/dist-packages (from shap; extra == \"full\"->pycaret[full]) (0.0.7)\n",
            "Requirement already satisfied: interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from interpret<=0.2.4; extra == \"full\"->pycaret[full]) (0.2.7)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from azure-storage-blob; extra == \"full\"->pycaret[full]) (1.22.1)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from azure-storage-blob; extra == \"full\"->pycaret[full]) (36.0.1)\n",
            "Requirement already satisfied: msrest>=0.6.21 in /usr/local/lib/python3.7/dist-packages (from azure-storage-blob; extra == \"full\"->pycaret[full]) (0.6.21)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23.2; extra == \"full\"->pycaret[full]) (0.10.1)\n",
            "Requirement already satisfied: holoviews==1.14.6 in /usr/local/lib/python3.7/dist-packages (from autoviz; extra == \"full\"->pycaret[full]) (1.14.6)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (from autoviz; extra == \"full\"->pycaret[full]) (1.6.3)\n",
            "Requirement already satisfied: fsspec==0.8.3 in /usr/local/lib/python3.7/dist-packages (from autoviz; extra == \"full\"->pycaret[full]) (0.8.3)\n",
            "Requirement already satisfied: panel==0.12.6 in /usr/local/lib/python3.7/dist-packages (from autoviz; extra == \"full\"->pycaret[full]) (0.12.6)\n",
            "Requirement already satisfied: bokeh==2.4.2 in /usr/local/lib/python3.7/dist-packages (from autoviz; extra == \"full\"->pycaret[full]) (2.4.2)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.7/dist-packages (from autoviz; extra == \"full\"->pycaret[full]) (1.1.0)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from autoviz; extra == \"full\"->pycaret[full]) (1.0.0)\n",
            "Requirement already satisfied: hvplot==0.7.3 in /usr/local/lib/python3.7/dist-packages (from autoviz; extra == \"full\"->pycaret[full]) (0.7.3)\n",
            "Requirement already satisfied: dataclasses>=0.6 in /usr/local/lib/python3.7/dist-packages (from evidently; extra == \"full\"->pycaret[full]) (0.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->pycaret[full]) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->pycaret[full]) (0.7.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (5.3.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret[full]) (4.9.2)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret[full]) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret[full]) (5.3.5)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod->pycaret[full]) (0.5.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod->pycaret[full]) (0.34.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret[full]) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret[full]) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret[full]) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret[full]) (1.24.3)\n",
            "Requirement already satisfied: imagehash; extra == \"type_image_path\" in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret[full]) (4.2.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow->pycaret[full]) (0.13.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow->pycaret[full]) (1.1.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow->pycaret[full]) (4.0.9)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from docker>=4.0.0->mlflow->pycaret[full]) (1.3.1)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret[full]) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret[full]) (1.1.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->mlflow->pycaret[full]) (1.1.6)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from alembic->mlflow->pycaret[full]) (5.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow->pycaret[full]) (3.7.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage; extra == \"full\"->pycaret[full]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage; extra == \"full\"->pycaret[full]) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage; extra == \"full\"->pycaret[full]) (4.2.4)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage; extra == \"full\"->pycaret[full]) (1.26.3)\n",
            "Requirement already satisfied: backoff==1.10.0 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio; extra == \"full\"->pycaret[full]) (1.10.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio; extra == \"full\"->pycaret[full]) (1.6)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio; extra == \"full\"->pycaret[full]) (1.5.0)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio; extra == \"full\"->pycaret[full]) (3.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.7/dist-packages (from markdown-it-py[linkify,plugins]->gradio; extra == \"full\"->pycaret[full]) (0.1.0)\n",
            "Requirement already satisfied: linkify-it-py~=1.0; extra == \"linkify\" in /usr/local/lib/python3.7/dist-packages (from markdown-it-py[linkify,plugins]->gradio; extra == \"full\"->pycaret[full]) (1.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins; extra == \"plugins\" in /usr/local/lib/python3.7/dist-packages (from markdown-it-py[linkify,plugins]->gradio; extra == \"full\"->pycaret[full]) (0.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio; extra == \"full\"->pycaret[full]) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio; extra == \"full\"->pycaret[full]) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio; extra == \"full\"->pycaret[full]) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio; extra == \"full\"->pycaret[full]) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio; extra == \"full\"->pycaret[full]) (1.7.2)\n",
            "Requirement already satisfied: asynctest==0.13.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio; extra == \"full\"->pycaret[full]) (0.13.0)\n",
            "Requirement already satisfied: anyio<4,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from starlette==0.17.1->fastapi; extra == \"full\"->pycaret[full]) (3.5.0)\n",
            "Requirement already satisfied: WTForms>=2.1 in /usr/local/lib/python3.7/dist-packages (from flask-simplelogin->explainerdashboard; extra == \"full\"->pycaret[full]) (3.0.1)\n",
            "Requirement already satisfied: Flask-WTF<0.16.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from flask-simplelogin->explainerdashboard; extra == \"full\"->pycaret[full]) (0.15.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from dtreeviz>=1.3->explainerdashboard; extra == \"full\"->pycaret[full]) (3.6.4)\n",
            "Requirement already satisfied: colour in /usr/local/lib/python3.7/dist-packages (from dtreeviz>=1.3->explainerdashboard; extra == \"full\"->pycaret[full]) (0.1.5)\n",
            "Requirement already satisfied: ua-parser in /usr/local/lib/python3.7/dist-packages (from dash-auth->explainerdashboard; extra == \"full\"->pycaret[full]) (0.10.0)\n",
            "Requirement already satisfied: flask-compress in /usr/local/lib/python3.7/dist-packages (from dash-auth->explainerdashboard; extra == \"full\"->pycaret[full]) (1.10.1)\n",
            "Requirement already satisfied: flask-seasurf in /usr/local/lib/python3.7/dist-packages (from dash-auth->explainerdashboard; extra == \"full\"->pycaret[full]) (0.3.1)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.7/dist-packages (from dash-auth->explainerdashboard; extra == \"full\"->pycaret[full]) (1.3.3)\n",
            "Requirement already satisfied: chart-studio>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from dash-auth->explainerdashboard; extra == \"full\"->pycaret[full]) (1.1.0)\n",
            "Requirement already satisfied: ansi2html in /usr/local/lib/python3.7/dist-packages (from jupyter-dash->explainerdashboard; extra == \"full\"->pycaret[full]) (1.7.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.7/dist-packages (from dash>=2->explainerdashboard; extra == \"full\"->pycaret[full]) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.7/dist-packages (from dash>=2->explainerdashboard; extra == \"full\"->pycaret[full]) (5.0.0)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.7/dist-packages (from dash>=2->explainerdashboard; extra == \"full\"->pycaret[full]) (2.0.0)\n",
            "Requirement already satisfied: deprecated>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (1.2.13)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (0.18.1)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna>=2.2.0; extra == \"full\"->pycaret[full]) (5.8.1)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna>=2.2.0; extra == \"full\"->pycaret[full]) (2.4.0)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna>=2.2.0; extra == \"full\"->pycaret[full]) (3.1.1)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna>=2.2.0; extra == \"full\"->pycaret[full]) (0.5.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna>=2.2.0; extra == \"full\"->pycaret[full]) (3.5.0)\n",
            "Requirement already satisfied: gevent>=1.3.6; extra == \"dash\" in /usr/local/lib/python3.7/dist-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4; extra == \"full\"->pycaret[full]) (21.12.0)\n",
            "Requirement already satisfied: dash-cytoscape>=0.1.1; extra == \"dash\" in /usr/local/lib/python3.7/dist-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4; extra == \"full\"->pycaret[full]) (0.3.0)\n",
            "Requirement already satisfied: lime>=0.1.1.33; extra == \"lime\" in /usr/local/lib/python3.7/dist-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4; extra == \"full\"->pycaret[full]) (0.2.0.1)\n",
            "Requirement already satisfied: SALib>=1.3.3; extra == \"sensitivity\" in /usr/local/lib/python3.7/dist-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4; extra == \"full\"->pycaret[full]) (1.4.5)\n",
            "Requirement already satisfied: dill>=0.2.5; extra == \"shap\" in /usr/local/lib/python3.7/dist-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4; extra == \"full\"->pycaret[full]) (0.3.4)\n",
            "Requirement already satisfied: skope-rules>=1.0.1; extra == \"skoperules\" in /usr/local/lib/python3.7/dist-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4; extra == \"full\"->pycaret[full]) (1.0.1)\n",
            "Requirement already satisfied: treeinterpreter>=0.2.2; extra == \"treeinterpreter\" in /usr/local/lib/python3.7/dist-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4; extra == \"full\"->pycaret[full]) (0.2.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.1.4->azure-storage-blob; extra == \"full\"->pycaret[full]) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.6.21->azure-storage-blob; extra == \"full\"->pycaret[full]) (1.3.1)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.6.21->azure-storage-blob; extra == \"full\"->pycaret[full]) (0.6.1)\n",
            "Requirement already satisfied: pyviz-comms>=0.7.4 in /usr/local/lib/python3.7/dist-packages (from holoviews==1.14.6->autoviz; extra == \"full\"->pycaret[full]) (2.1.0)\n",
            "Requirement already satisfied: param<2.0,>=1.9.3 in /usr/local/lib/python3.7/dist-packages (from holoviews==1.14.6->autoviz; extra == \"full\"->pycaret[full]) (1.12.0)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.7/dist-packages (from holoviews==1.14.6->autoviz; extra == \"full\"->pycaret[full]) (3.0.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from panel==0.12.6->autoviz; extra == \"full\"->pycaret[full]) (4.1.0)\n",
            "Requirement already satisfied: pyct>=0.4.4 in /usr/local/lib/python3.7/dist-packages (from panel==0.12.6->autoviz; extra == \"full\"->pycaret[full]) (0.4.8)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.7/dist-packages (from panel==0.12.6->autoviz; extra == \"full\"->pycaret[full]) (3.3.6)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->autoviz; extra == \"full\"->pycaret[full]) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->autoviz; extra == \"full\"->pycaret[full]) (5.2.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->autoviz; extra == \"full\"->pycaret[full]) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (0.13.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret[full]) (22.3.0)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret[full]) (1.2.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow->pycaret[full]) (5.0.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2.0->google-cloud-storage; extra == \"full\"->pycaret[full]) (0.4.8)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage; extra == \"full\"->pycaret[full]) (1.54.0)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.7/dist-packages (from linkify-it-py~=1.0; extra == \"linkify\"->markdown-it-py[linkify,plugins]->gradio; extra == \"full\"->pycaret[full]) (1.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.0.0->starlette==0.17.1->fastapi; extra == \"full\"->pycaret[full]) (1.2.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->dtreeviz>=1.3->explainerdashboard; extra == \"full\"->pycaret[full]) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->dtreeviz>=1.3->explainerdashboard; extra == \"full\"->pycaret[full]) (8.12.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->dtreeviz>=1.3->explainerdashboard; extra == \"full\"->pycaret[full]) (1.11.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->dtreeviz>=1.3->explainerdashboard; extra == \"full\"->pycaret[full]) (1.4.0)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.7/dist-packages (from flask-compress->dash-auth->explainerdashboard; extra == \"full\"->pycaret[full]) (1.0.9)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (1.13.3)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna>=2.2.0; extra == \"full\"->pycaret[full]) (1.8.2)\n",
            "Requirement already satisfied: zope.event in /usr/local/lib/python3.7/dist-packages (from gevent>=1.3.6; extra == \"dash\"->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4; extra == \"full\"->pycaret[full]) (4.5.0)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.7/dist-packages (from gevent>=1.3.6; extra == \"dash\"->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4; extra == \"full\"->pycaret[full]) (5.4.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime>=0.1.1.33; extra == \"lime\"->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4; extra == \"full\"->pycaret[full]) (0.18.3)\n",
            "Requirement already satisfied: pathos in /usr/local/lib/python3.7/dist-packages (from SALib>=1.3.3; extra == \"sensitivity\"->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4; extra == \"full\"->pycaret[full]) (0.2.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob; extra == \"full\"->pycaret[full]) (2.21)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-storage-blob; extra == \"full\"->pycaret[full]) (3.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->panel==0.12.6->autoviz; extra == \"full\"->pycaret[full]) (0.5.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->autoviz; extra == \"full\"->pycaret[full]) (2.0.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->autoviz; extra == \"full\"->pycaret[full]) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->autoviz; extra == \"full\"->pycaret[full]) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->autoviz; extra == \"full\"->pycaret[full]) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->autoviz; extra == \"full\"->pycaret[full]) (0.5.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime>=0.1.1.33; extra == \"lime\"->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4; extra == \"full\"->pycaret[full]) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime>=0.1.1.33; extra == \"lime\"->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4; extra == \"full\"->pycaret[full]) (2.4.1)\n",
            "Requirement already satisfied: pox>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from pathos->SALib>=1.3.3; extra == \"sensitivity\"->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4; extra == \"full\"->pycaret[full]) (0.3.0)\n",
            "Requirement already satisfied: multiprocess>=0.70.12 in /usr/local/lib/python3.7/dist-packages (from pathos->SALib>=1.3.3; extra == \"sensitivity\"->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4; extra == \"full\"->pycaret[full]) (0.70.12.2)\n",
            "Requirement already satisfied: ppft>=1.6.6.4 in /usr/local/lib/python3.7/dist-packages (from pathos->SALib>=1.3.3; extra == \"sensitivity\"->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4->interpret<=0.2.4; extra == \"full\"->pycaret[full]) (1.6.6.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 형태의 pycaret\n",
        "from pycaret.regression import *\n",
        "\n",
        "exp_101=setup(data=data, \n",
        "              target='INVC_CONT', # 따로 파라미터 조정 X\n",
        "              session_id=123,\n",
        "              ignore_features=['index'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "60dcabebc96244059220d7e19c470375",
            "16086f28743349f09da0ad782b1fab4d",
            "a734d1ffc6dc4564b417687cc070864c",
            "cac1fe8f6a4d4b469521578446d0e17b",
            "be4edfab24ca4f4abf0ffd6085a24c2c",
            "d142a8332f5b4c8699924a3749bae888"
          ]
        },
        "id": "iQpfxc9TigwU",
        "outputId": "5384aced-aaf6-43b5-8f71-56ce7f3794eb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6892d944-4089-46ce-9084-eae528c1eb62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>session_id</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Target</td>\n",
              "      <td>INVC_CONT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Original Data</td>\n",
              "      <td>(31684, 594)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Missing Values</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Numeric Features</td>\n",
              "      <td>592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Categorical Features</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ordinal Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>High Cardinality Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>High Cardinality Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Transformed Train Set</td>\n",
              "      <td>(22178, 590)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Transformed Test Set</td>\n",
              "      <td>(9506, 590)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Shuffle Train-Test</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Stratify Train-Test</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Fold Generator</td>\n",
              "      <td>KFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Fold Number</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>CPU Jobs</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Use GPU</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Log Experiment</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Experiment Name</td>\n",
              "      <td>reg-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>USI</td>\n",
              "      <td>ff5b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Imputation Type</td>\n",
              "      <td>simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Iterative Imputation Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Numeric Imputer</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Iterative Imputation Numeric Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Categorical Imputer</td>\n",
              "      <td>constant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Iterative Imputation Categorical Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Unknown Categoricals Handling</td>\n",
              "      <td>least_frequent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Normalize</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Normalize Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Transformation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Transformation Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>PCA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>PCA Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>PCA Components</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Ignore Low Variance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Combine Rare Levels</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Rare Level Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Numeric Binning</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Remove Outliers</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Outliers Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Remove Multicollinearity</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Multicollinearity Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Remove Perfect Collinearity</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Clustering</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Clustering Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Polynomial Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Polynomial Degree</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Trignometry Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Polynomial Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Group Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Feature Selection</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Feature Selection Method</td>\n",
              "      <td>classic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Features Selection Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Feature Interaction</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Feature Ratio</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Interaction Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Transform Target</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Transform Target Method</td>\n",
              "      <td>box-cox</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6892d944-4089-46ce-9084-eae528c1eb62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6892d944-4089-46ce-9084-eae528c1eb62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6892d944-4089-46ce-9084-eae528c1eb62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                               Description             Value\n",
              "0                               session_id               123\n",
              "1                                   Target         INVC_CONT\n",
              "2                            Original Data      (31684, 594)\n",
              "3                           Missing Values             False\n",
              "4                         Numeric Features               592\n",
              "5                     Categorical Features                 0\n",
              "6                         Ordinal Features             False\n",
              "7                High Cardinality Features             False\n",
              "8                  High Cardinality Method              None\n",
              "9                    Transformed Train Set      (22178, 590)\n",
              "10                    Transformed Test Set       (9506, 590)\n",
              "11                      Shuffle Train-Test              True\n",
              "12                     Stratify Train-Test             False\n",
              "13                          Fold Generator             KFold\n",
              "14                             Fold Number                10\n",
              "15                                CPU Jobs                -1\n",
              "16                                 Use GPU             False\n",
              "17                          Log Experiment             False\n",
              "18                         Experiment Name  reg-default-name\n",
              "19                                     USI              ff5b\n",
              "20                         Imputation Type            simple\n",
              "21          Iterative Imputation Iteration              None\n",
              "22                         Numeric Imputer              mean\n",
              "23      Iterative Imputation Numeric Model              None\n",
              "24                     Categorical Imputer          constant\n",
              "25  Iterative Imputation Categorical Model              None\n",
              "26           Unknown Categoricals Handling    least_frequent\n",
              "27                               Normalize             False\n",
              "28                        Normalize Method              None\n",
              "29                          Transformation             False\n",
              "30                   Transformation Method              None\n",
              "31                                     PCA             False\n",
              "32                              PCA Method              None\n",
              "33                          PCA Components              None\n",
              "34                     Ignore Low Variance             False\n",
              "35                     Combine Rare Levels             False\n",
              "36                    Rare Level Threshold              None\n",
              "37                         Numeric Binning             False\n",
              "38                         Remove Outliers             False\n",
              "39                      Outliers Threshold              None\n",
              "40                Remove Multicollinearity             False\n",
              "41             Multicollinearity Threshold              None\n",
              "42             Remove Perfect Collinearity              True\n",
              "43                              Clustering             False\n",
              "44                    Clustering Iteration              None\n",
              "45                     Polynomial Features             False\n",
              "46                       Polynomial Degree              None\n",
              "47                    Trignometry Features             False\n",
              "48                    Polynomial Threshold              None\n",
              "49                          Group Features             False\n",
              "50                       Feature Selection             False\n",
              "51                Feature Selection Method           classic\n",
              "52            Features Selection Threshold              None\n",
              "53                     Feature Interaction             False\n",
              "54                           Feature Ratio             False\n",
              "55                   Interaction Threshold              None\n",
              "56                        Transform Target             False\n",
              "57                 Transform Target Method           box-cox"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 상위 모델 확인\n",
        "best_3_l = compare_models(sort='RMSE', n_select=3) # 3으로 우선 지정"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515,
          "referenced_widgets": [
            "9792ece81a2d498996878f71cfaed252",
            "dfe76d4533cf4117805652f41cbdce8a",
            "b5f49579932340a8936a43a6a898f1d2"
          ]
        },
        "id": "R4wsGCU1kFo7",
        "outputId": "56d0f121-de7e-46d2-dd24-4531458f3571"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a9a53680-4a4f-42ef-8b8d-82f89b0de157\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2</th>\n",
              "      <th>RMSLE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>catboost</th>\n",
              "      <td>CatBoost Regressor</td>\n",
              "      <td>2.2907</td>\n",
              "      <td>39.5044</td>\n",
              "      <td>6.1741</td>\n",
              "      <td>0.1199</td>\n",
              "      <td>0.4203</td>\n",
              "      <td>0.4242</td>\n",
              "      <td>7.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbr</th>\n",
              "      <td>Gradient Boosting Regressor</td>\n",
              "      <td>2.3385</td>\n",
              "      <td>40.3233</td>\n",
              "      <td>6.2442</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.4224</td>\n",
              "      <td>0.4384</td>\n",
              "      <td>13.707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>2.3563</td>\n",
              "      <td>40.4916</td>\n",
              "      <td>6.2589</td>\n",
              "      <td>0.1029</td>\n",
              "      <td>0.4342</td>\n",
              "      <td>0.4446</td>\n",
              "      <td>0.476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xgboost</th>\n",
              "      <td>Extreme Gradient Boosting</td>\n",
              "      <td>2.2961</td>\n",
              "      <td>40.6948</td>\n",
              "      <td>6.2795</td>\n",
              "      <td>0.0688</td>\n",
              "      <td>0.4224</td>\n",
              "      <td>0.4238</td>\n",
              "      <td>49.101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Regressor</td>\n",
              "      <td>2.3484</td>\n",
              "      <td>41.4730</td>\n",
              "      <td>6.3561</td>\n",
              "      <td>0.0522</td>\n",
              "      <td>0.4487</td>\n",
              "      <td>0.4211</td>\n",
              "      <td>105.484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Regression</td>\n",
              "      <td>2.4560</td>\n",
              "      <td>43.8455</td>\n",
              "      <td>6.5098</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.4546</td>\n",
              "      <td>0.4695</td>\n",
              "      <td>0.265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>omp</th>\n",
              "      <td>Orthogonal Matching Pursuit</td>\n",
              "      <td>2.4210</td>\n",
              "      <td>44.0271</td>\n",
              "      <td>6.5238</td>\n",
              "      <td>0.0323</td>\n",
              "      <td>0.4442</td>\n",
              "      <td>0.4593</td>\n",
              "      <td>0.287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Regressor</td>\n",
              "      <td>2.4085</td>\n",
              "      <td>44.9290</td>\n",
              "      <td>6.6092</td>\n",
              "      <td>-0.0312</td>\n",
              "      <td>0.4647</td>\n",
              "      <td>0.4290</td>\n",
              "      <td>155.202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>br</th>\n",
              "      <td>Bayesian Ridge</td>\n",
              "      <td>2.4188</td>\n",
              "      <td>46.2091</td>\n",
              "      <td>6.6391</td>\n",
              "      <td>0.0160</td>\n",
              "      <td>0.4360</td>\n",
              "      <td>0.4604</td>\n",
              "      <td>2.615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>2.4428</td>\n",
              "      <td>46.7662</td>\n",
              "      <td>6.6799</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.4414</td>\n",
              "      <td>0.4658</td>\n",
              "      <td>0.965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>en</th>\n",
              "      <td>Elastic Net</td>\n",
              "      <td>2.4428</td>\n",
              "      <td>46.7662</td>\n",
              "      <td>6.6799</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.4414</td>\n",
              "      <td>0.4658</td>\n",
              "      <td>8.143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lasso</th>\n",
              "      <td>Lasso Regression</td>\n",
              "      <td>2.4428</td>\n",
              "      <td>46.7662</td>\n",
              "      <td>6.6799</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.4414</td>\n",
              "      <td>0.4658</td>\n",
              "      <td>8.127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>llar</th>\n",
              "      <td>Lasso Least Angle Regression</td>\n",
              "      <td>2.4430</td>\n",
              "      <td>46.9466</td>\n",
              "      <td>6.6934</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>0.4420</td>\n",
              "      <td>0.4662</td>\n",
              "      <td>0.570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dummy</th>\n",
              "      <td>Dummy Regressor</td>\n",
              "      <td>2.4430</td>\n",
              "      <td>46.9466</td>\n",
              "      <td>6.6934</td>\n",
              "      <td>-0.0005</td>\n",
              "      <td>0.4420</td>\n",
              "      <td>0.4662</td>\n",
              "      <td>0.096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Regressor</td>\n",
              "      <td>2.5543</td>\n",
              "      <td>46.0228</td>\n",
              "      <td>6.7076</td>\n",
              "      <td>-0.0447</td>\n",
              "      <td>0.4877</td>\n",
              "      <td>0.4733</td>\n",
              "      <td>2.038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Regressor</td>\n",
              "      <td>2.4301</td>\n",
              "      <td>46.3482</td>\n",
              "      <td>6.7197</td>\n",
              "      <td>-0.0764</td>\n",
              "      <td>0.4670</td>\n",
              "      <td>0.4342</td>\n",
              "      <td>1.553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>huber</th>\n",
              "      <td>Huber Regressor</td>\n",
              "      <td>2.0005</td>\n",
              "      <td>48.6756</td>\n",
              "      <td>6.8222</td>\n",
              "      <td>-0.0411</td>\n",
              "      <td>0.4419</td>\n",
              "      <td>0.2674</td>\n",
              "      <td>2.641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>par</th>\n",
              "      <td>Passive Aggressive Regressor</td>\n",
              "      <td>2.3629</td>\n",
              "      <td>50.8751</td>\n",
              "      <td>6.9680</td>\n",
              "      <td>-0.0847</td>\n",
              "      <td>0.5512</td>\n",
              "      <td>0.3599</td>\n",
              "      <td>0.428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>AdaBoost Regressor</td>\n",
              "      <td>3.6223</td>\n",
              "      <td>66.6718</td>\n",
              "      <td>7.5012</td>\n",
              "      <td>-0.2466</td>\n",
              "      <td>0.5495</td>\n",
              "      <td>0.8345</td>\n",
              "      <td>4.442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9a53680-4a4f-42ef-8b8d-82f89b0de157')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a9a53680-4a4f-42ef-8b8d-82f89b0de157 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a9a53680-4a4f-42ef-8b8d-82f89b0de157');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    Model     MAE      MSE    RMSE      R2  \\\n",
              "catboost               CatBoost Regressor  2.2907  39.5044  6.1741  0.1199   \n",
              "gbr           Gradient Boosting Regressor  2.3385  40.3233  6.2442  0.0974   \n",
              "lightgbm  Light Gradient Boosting Machine  2.3563  40.4916  6.2589  0.1029   \n",
              "xgboost         Extreme Gradient Boosting  2.2961  40.6948  6.2795  0.0688   \n",
              "rf                Random Forest Regressor  2.3484  41.4730  6.3561  0.0522   \n",
              "ridge                    Ridge Regression  2.4560  43.8455  6.5098  0.0371   \n",
              "omp           Orthogonal Matching Pursuit  2.4210  44.0271  6.5238  0.0323   \n",
              "et                  Extra Trees Regressor  2.4085  44.9290  6.6092 -0.0312   \n",
              "br                         Bayesian Ridge  2.4188  46.2091  6.6391  0.0160   \n",
              "lr                      Linear Regression  2.4428  46.7662  6.6799  0.0037   \n",
              "en                            Elastic Net  2.4428  46.7662  6.6799  0.0037   \n",
              "lasso                    Lasso Regression  2.4428  46.7662  6.6799  0.0037   \n",
              "llar         Lasso Least Angle Regression  2.4430  46.9466  6.6934 -0.0005   \n",
              "dummy                     Dummy Regressor  2.4430  46.9466  6.6934 -0.0005   \n",
              "knn                 K Neighbors Regressor  2.5543  46.0228  6.7076 -0.0447   \n",
              "dt                Decision Tree Regressor  2.4301  46.3482  6.7197 -0.0764   \n",
              "huber                     Huber Regressor  2.0005  48.6756  6.8222 -0.0411   \n",
              "par          Passive Aggressive Regressor  2.3629  50.8751  6.9680 -0.0847   \n",
              "ada                    AdaBoost Regressor  3.6223  66.6718  7.5012 -0.2466   \n",
              "\n",
              "           RMSLE    MAPE  TT (Sec)  \n",
              "catboost  0.4203  0.4242     7.106  \n",
              "gbr       0.4224  0.4384    13.707  \n",
              "lightgbm  0.4342  0.4446     0.476  \n",
              "xgboost   0.4224  0.4238    49.101  \n",
              "rf        0.4487  0.4211   105.484  \n",
              "ridge     0.4546  0.4695     0.265  \n",
              "omp       0.4442  0.4593     0.287  \n",
              "et        0.4647  0.4290   155.202  \n",
              "br        0.4360  0.4604     2.615  \n",
              "lr        0.4414  0.4658     0.965  \n",
              "en        0.4414  0.4658     8.143  \n",
              "lasso     0.4414  0.4658     8.127  \n",
              "llar      0.4420  0.4662     0.570  \n",
              "dummy     0.4420  0.4662     0.096  \n",
              "knn       0.4877  0.4733     2.038  \n",
              "dt        0.4670  0.4342     1.553  \n",
              "huber     0.4419  0.2674     2.641  \n",
              "par       0.5512  0.3599     0.428  \n",
              "ada       0.5495  0.8345     4.442  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "< 참고>\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "-  pycaret 을 통해 상품 카테고리 칼럼을 one-hot encoding 하지 않았을 경우보다 one-hot encoding 처리를 진행했을 때 모델의 성능이 더 우수하다는 것을 확인할 수 있었다. (RMSE 기준)"
      ],
      "metadata": {
        "id": "1fA8ExRKLQ2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blended_l = blend_models(estimator_list= best_3_l, fold=5, optimize='RMSE') # 추출한 상위 3가지 모델 블랜딩\n",
        "pred_holdout = predict_model(blended_l)\n",
        "final_blended_model_l = finalize_model(blended_l)"
      ],
      "metadata": {
        "id": "6yxOO9fWpmvG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "c07c35b3c62542eba933b6805aed0465",
            "7c23aa20206b48c5bdc971a30f14bc85",
            "0691a3aa2d8949ec81ab1d6cdfe0da83"
          ]
        },
        "outputId": "43b94d3f-a4d8-491a-dadd-e972bc2ece7c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-60129835-7a42-4ebb-90f5-b5d9afa66d5f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2</th>\n",
              "      <th>RMSLE</th>\n",
              "      <th>MAPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.3927</td>\n",
              "      <td>39.9042</td>\n",
              "      <td>6.3170</td>\n",
              "      <td>0.3310</td>\n",
              "      <td>0.4260</td>\n",
              "      <td>0.4198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.1929</td>\n",
              "      <td>23.9149</td>\n",
              "      <td>4.8903</td>\n",
              "      <td>0.1768</td>\n",
              "      <td>0.4144</td>\n",
              "      <td>0.4446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.2760</td>\n",
              "      <td>30.7709</td>\n",
              "      <td>5.5472</td>\n",
              "      <td>-0.0022</td>\n",
              "      <td>0.4208</td>\n",
              "      <td>0.4288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.3188</td>\n",
              "      <td>51.5215</td>\n",
              "      <td>7.1778</td>\n",
              "      <td>0.2301</td>\n",
              "      <td>0.4216</td>\n",
              "      <td>0.4332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.3687</td>\n",
              "      <td>44.5179</td>\n",
              "      <td>6.6722</td>\n",
              "      <td>0.0791</td>\n",
              "      <td>0.4224</td>\n",
              "      <td>0.4370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>2.3098</td>\n",
              "      <td>38.1259</td>\n",
              "      <td>6.1209</td>\n",
              "      <td>0.1629</td>\n",
              "      <td>0.4210</td>\n",
              "      <td>0.4327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0710</td>\n",
              "      <td>9.7930</td>\n",
              "      <td>0.8128</td>\n",
              "      <td>0.1160</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.0083</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60129835-7a42-4ebb-90f5-b5d9afa66d5f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-60129835-7a42-4ebb-90f5-b5d9afa66d5f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-60129835-7a42-4ebb-90f5-b5d9afa66d5f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         MAE      MSE    RMSE      R2   RMSLE    MAPE\n",
              "0     2.3927  39.9042  6.3170  0.3310  0.4260  0.4198\n",
              "1     2.1929  23.9149  4.8903  0.1768  0.4144  0.4446\n",
              "2     2.2760  30.7709  5.5472 -0.0022  0.4208  0.4288\n",
              "3     2.3188  51.5215  7.1778  0.2301  0.4216  0.4332\n",
              "4     2.3687  44.5179  6.6722  0.0791  0.4224  0.4370\n",
              "Mean  2.3098  38.1259  6.1209  0.1629  0.4210  0.4327\n",
              "SD    0.0710   9.7930  0.8128  0.1160  0.0037  0.0083"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a6285cab-c2fa-43f7-a711-3973f5e7d44a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2</th>\n",
              "      <th>RMSLE</th>\n",
              "      <th>MAPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Voting Regressor</td>\n",
              "      <td>2.2723</td>\n",
              "      <td>34.8495</td>\n",
              "      <td>5.9033</td>\n",
              "      <td>0.1825</td>\n",
              "      <td>0.4218</td>\n",
              "      <td>0.4336</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6285cab-c2fa-43f7-a711-3973f5e7d44a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6285cab-c2fa-43f7-a711-3973f5e7d44a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6285cab-c2fa-43f7-a711-3973f5e7d44a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              Model     MAE      MSE    RMSE      R2   RMSLE    MAPE\n",
              "0  Voting Regressor  2.2723  34.8495  5.9033  0.1825  0.4218  0.4336"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 단일 모델을 사용했을 때보다 상위 모델 3개를 블랜딩해서 사용했을 때의 RMSE가 더 낮은 것으로 확인된다. \n",
        "\n",
        "- 그러나 해당 경우에는 하이퍼 파라미터 튜닝이 어렵기 때문에 pycaret 으로 확인했을 때 우수한 성능을 보인 lightGBM 모델을 사용하기로 결정하였다."
      ],
      "metadata": {
        "id": "vBG5jc0rMooP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) lightGBM 초기 모델\n",
        "\n",
        "LightGBM은 의사 결정 트리를 결합하기 위해 부스팅 기술을 사용하는 앙상블 방법이다."
      ],
      "metadata": {
        "id": "AWr3IuAtnsbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습, 검증 데이터 분할 \n",
        "from sklearn.model_selection import train_test_split\n",
        "raw_x=data[feature]\n",
        "raw_y=data[['INVC_CONT']]\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(raw_x, raw_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# LightGBM에 맞는 데이터 세트 포맷으로 변환\n",
        "train_ds = lgb.Dataset(train_x, label = train_y) \n",
        "test_ds = lgb.Dataset(test_x, label = test_y) \n",
        "\n",
        "print(train_y.max())\n",
        "print(test_y.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_B9iJdL-nHD",
        "outputId": "b1695450-ab31-4b49-be35-a6b1809d3462"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INVC_CONT    413\n",
            "dtype: int64\n",
            "INVC_CONT    179\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 데이터 개수 확인\n",
        "print(\"train_x:\",len(train_x))\n",
        "print(\"train_y:\",len(train_y))\n",
        "print(\"test_x:\",len(test_x))\n",
        "print(\"test_y:\",len(test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1nMmOwSyEew",
        "outputId": "4096a029-0605-4221-b3e9-5388ed576c27"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x: 25347\n",
            "train_y: 25347\n",
            "test_x: 6337\n",
            "test_y: 6337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lightGBM 관련 파라미터는 여러개가 있다.\n",
        "\n",
        "우선 초기 모델은 다음과 같다."
      ],
      "metadata": {
        "id": "HhB1mKFhom8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 초기 모델 파라미터 지정\n",
        "params_1 = { \n",
        "          'learning_rate': 0.1, \n",
        "          'max_depth': 5, \n",
        "          'boosting': 'gbdt', # traditional gradient boosting decision tree\n",
        "          'objective': 'regression', \n",
        "          'metric': 'rmse',\n",
        "          'is_training_metric': True, \n",
        "         }\n",
        "\n",
        "model_1 = lgb.train(params_1, \n",
        "                    train_ds, \n",
        "                    num_boost_round=500, # 부스팅 수\n",
        "                    valid_sets=[train_ds, test_ds ],\n",
        "                    early_stopping_rounds=100, # 조기종료 설정\n",
        "                    verbose_eval=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqR0ifUkJq5Q",
        "outputId": "9f5c98fb-eaa7-4fac-a5b0-89991d0ffd82"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001773 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 632\n",
            "[LightGBM] [Info] Number of data points in the train set: 25347, number of used features: 316\n",
            "[LightGBM] [Info] Start training from score 4.880972\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[1]\ttraining's rmse: 6.84166\tvalid_1's rmse: 6.15059\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[2]\ttraining's rmse: 6.80089\tvalid_1's rmse: 6.12319\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[3]\ttraining's rmse: 6.76757\tvalid_1's rmse: 6.09964\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[4]\ttraining's rmse: 6.74028\tvalid_1's rmse: 6.08123\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[5]\ttraining's rmse: 6.71794\tvalid_1's rmse: 6.06713\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[6]\ttraining's rmse: 6.69959\tvalid_1's rmse: 6.05616\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[7]\ttraining's rmse: 6.68381\tvalid_1's rmse: 6.0457\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[8]\ttraining's rmse: 6.67101\tvalid_1's rmse: 6.03701\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[9]\ttraining's rmse: 6.66052\tvalid_1's rmse: 6.03143\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[10]\ttraining's rmse: 6.65126\tvalid_1's rmse: 6.02582\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[11]\ttraining's rmse: 6.63896\tvalid_1's rmse: 6.01866\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[12]\ttraining's rmse: 6.63177\tvalid_1's rmse: 6.01422\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[13]\ttraining's rmse: 6.62224\tvalid_1's rmse: 6.01171\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[14]\ttraining's rmse: 6.61585\tvalid_1's rmse: 6.00757\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[15]\ttraining's rmse: 6.60856\tvalid_1's rmse: 6.00625\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[16]\ttraining's rmse: 6.60346\tvalid_1's rmse: 6.00367\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[17]\ttraining's rmse: 6.59737\tvalid_1's rmse: 6.00161\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[18]\ttraining's rmse: 6.59311\tvalid_1's rmse: 6.00005\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[19]\ttraining's rmse: 6.58824\tvalid_1's rmse: 5.99865\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[20]\ttraining's rmse: 6.58467\tvalid_1's rmse: 5.99708\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[21]\ttraining's rmse: 6.58087\tvalid_1's rmse: 5.99702\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[22]\ttraining's rmse: 6.57685\tvalid_1's rmse: 5.99384\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[23]\ttraining's rmse: 6.5735\tvalid_1's rmse: 5.99319\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[24]\ttraining's rmse: 6.57027\tvalid_1's rmse: 5.99316\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[25]\ttraining's rmse: 6.56649\tvalid_1's rmse: 5.98969\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[26]\ttraining's rmse: 6.56357\tvalid_1's rmse: 5.99\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[27]\ttraining's rmse: 6.56006\tvalid_1's rmse: 5.986\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[28]\ttraining's rmse: 6.55755\tvalid_1's rmse: 5.9863\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[29]\ttraining's rmse: 6.5549\tvalid_1's rmse: 5.98564\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[30]\ttraining's rmse: 6.55295\tvalid_1's rmse: 5.98642\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[31]\ttraining's rmse: 6.54943\tvalid_1's rmse: 5.98292\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[32]\ttraining's rmse: 6.54734\tvalid_1's rmse: 5.98332\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[33]\ttraining's rmse: 6.54562\tvalid_1's rmse: 5.98366\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[34]\ttraining's rmse: 6.54208\tvalid_1's rmse: 5.97987\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[35]\ttraining's rmse: 6.54015\tvalid_1's rmse: 5.97993\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[36]\ttraining's rmse: 6.53864\tvalid_1's rmse: 5.9806\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[37]\ttraining's rmse: 6.53709\tvalid_1's rmse: 5.98172\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[38]\ttraining's rmse: 6.53358\tvalid_1's rmse: 5.97755\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[39]\ttraining's rmse: 6.53227\tvalid_1's rmse: 5.97835\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[40]\ttraining's rmse: 6.53108\tvalid_1's rmse: 5.97854\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[41]\ttraining's rmse: 6.5273\tvalid_1's rmse: 5.97371\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[42]\ttraining's rmse: 6.52602\tvalid_1's rmse: 5.97443\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[43]\ttraining's rmse: 6.52491\tvalid_1's rmse: 5.97496\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[44]\ttraining's rmse: 6.52377\tvalid_1's rmse: 5.97595\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[45]\ttraining's rmse: 6.51997\tvalid_1's rmse: 5.97109\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[46]\ttraining's rmse: 6.51853\tvalid_1's rmse: 5.97221\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[47]\ttraining's rmse: 6.51753\tvalid_1's rmse: 5.97317\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[48]\ttraining's rmse: 6.51644\tvalid_1's rmse: 5.97329\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[49]\ttraining's rmse: 6.51537\tvalid_1's rmse: 5.97236\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[50]\ttraining's rmse: 6.51452\tvalid_1's rmse: 5.97177\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[51]\ttraining's rmse: 6.51375\tvalid_1's rmse: 5.97217\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[52]\ttraining's rmse: 6.51276\tvalid_1's rmse: 5.97187\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[53]\ttraining's rmse: 6.51192\tvalid_1's rmse: 5.97248\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[54]\ttraining's rmse: 6.5112\tvalid_1's rmse: 5.97199\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[55]\ttraining's rmse: 6.50625\tvalid_1's rmse: 5.96609\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[56]\ttraining's rmse: 6.50554\tvalid_1's rmse: 5.96723\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[57]\ttraining's rmse: 6.50471\tvalid_1's rmse: 5.96744\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[58]\ttraining's rmse: 6.50374\tvalid_1's rmse: 5.9666\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[59]\ttraining's rmse: 6.50317\tvalid_1's rmse: 5.96793\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[60]\ttraining's rmse: 6.50263\tvalid_1's rmse: 5.96751\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[61]\ttraining's rmse: 6.49866\tvalid_1's rmse: 5.96272\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[62]\ttraining's rmse: 6.49799\tvalid_1's rmse: 5.9632\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[63]\ttraining's rmse: 6.49734\tvalid_1's rmse: 5.96345\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[64]\ttraining's rmse: 6.49665\tvalid_1's rmse: 5.96447\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[65]\ttraining's rmse: 6.49553\tvalid_1's rmse: 5.96429\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[66]\ttraining's rmse: 6.49129\tvalid_1's rmse: 5.95906\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[67]\ttraining's rmse: 6.49062\tvalid_1's rmse: 5.95971\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[68]\ttraining's rmse: 6.49002\tvalid_1's rmse: 5.96028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[69]\ttraining's rmse: 6.48949\tvalid_1's rmse: 5.9609\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[70]\ttraining's rmse: 6.48899\tvalid_1's rmse: 5.96189\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[71]\ttraining's rmse: 6.48832\tvalid_1's rmse: 5.96241\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[72]\ttraining's rmse: 6.48743\tvalid_1's rmse: 5.96111\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[73]\ttraining's rmse: 6.48672\tvalid_1's rmse: 5.96121\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[74]\ttraining's rmse: 6.48629\tvalid_1's rmse: 5.96114\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[75]\ttraining's rmse: 6.48582\tvalid_1's rmse: 5.96046\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[76]\ttraining's rmse: 6.48541\tvalid_1's rmse: 5.96003\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[77]\ttraining's rmse: 6.48505\tvalid_1's rmse: 5.96057\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[78]\ttraining's rmse: 6.48456\tvalid_1's rmse: 5.96024\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[79]\ttraining's rmse: 6.48416\tvalid_1's rmse: 5.96064\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[80]\ttraining's rmse: 6.48367\tvalid_1's rmse: 5.96076\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[81]\ttraining's rmse: 6.48316\tvalid_1's rmse: 5.96143\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[82]\ttraining's rmse: 6.48201\tvalid_1's rmse: 5.96007\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[83]\ttraining's rmse: 6.48163\tvalid_1's rmse: 5.96002\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[84]\ttraining's rmse: 6.48133\tvalid_1's rmse: 5.9601\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[85]\ttraining's rmse: 6.48087\tvalid_1's rmse: 5.95917\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[86]\ttraining's rmse: 6.48049\tvalid_1's rmse: 5.95919\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[87]\ttraining's rmse: 6.47996\tvalid_1's rmse: 5.95902\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[88]\ttraining's rmse: 6.47946\tvalid_1's rmse: 5.9584\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[89]\ttraining's rmse: 6.47913\tvalid_1's rmse: 5.95808\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[90]\ttraining's rmse: 6.47878\tvalid_1's rmse: 5.95769\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[91]\ttraining's rmse: 6.47852\tvalid_1's rmse: 5.95775\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[92]\ttraining's rmse: 6.47437\tvalid_1's rmse: 5.95242\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[93]\ttraining's rmse: 6.4739\tvalid_1's rmse: 5.9528\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[94]\ttraining's rmse: 6.47341\tvalid_1's rmse: 5.95301\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[95]\ttraining's rmse: 6.47292\tvalid_1's rmse: 5.95378\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[96]\ttraining's rmse: 6.47262\tvalid_1's rmse: 5.95406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[97]\ttraining's rmse: 6.47237\tvalid_1's rmse: 5.95454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[98]\ttraining's rmse: 6.47182\tvalid_1's rmse: 5.95448\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[99]\ttraining's rmse: 6.47148\tvalid_1's rmse: 5.95436\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[100]\ttraining's rmse: 6.46766\tvalid_1's rmse: 5.94922\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[101]\ttraining's rmse: 6.46728\tvalid_1's rmse: 5.94987\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[102]\ttraining's rmse: 6.46673\tvalid_1's rmse: 5.94956\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[103]\ttraining's rmse: 6.46317\tvalid_1's rmse: 5.94477\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[104]\ttraining's rmse: 6.4627\tvalid_1's rmse: 5.94525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[105]\ttraining's rmse: 6.46226\tvalid_1's rmse: 5.94574\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[106]\ttraining's rmse: 6.46176\tvalid_1's rmse: 5.94642\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[107]\ttraining's rmse: 6.4614\tvalid_1's rmse: 5.94674\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[108]\ttraining's rmse: 6.45796\tvalid_1's rmse: 5.94234\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[109]\ttraining's rmse: 6.45745\tvalid_1's rmse: 5.94266\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[110]\ttraining's rmse: 6.45704\tvalid_1's rmse: 5.94322\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[111]\ttraining's rmse: 6.4564\tvalid_1's rmse: 5.94386\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[112]\ttraining's rmse: 6.45609\tvalid_1's rmse: 5.94439\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[113]\ttraining's rmse: 6.45264\tvalid_1's rmse: 5.93942\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[114]\ttraining's rmse: 6.4522\tvalid_1's rmse: 5.93998\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[115]\ttraining's rmse: 6.45183\tvalid_1's rmse: 5.94044\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[116]\ttraining's rmse: 6.45141\tvalid_1's rmse: 5.94133\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[117]\ttraining's rmse: 6.451\tvalid_1's rmse: 5.94215\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[118]\ttraining's rmse: 6.44766\tvalid_1's rmse: 5.93789\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[119]\ttraining's rmse: 6.44723\tvalid_1's rmse: 5.93856\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[120]\ttraining's rmse: 6.4468\tvalid_1's rmse: 5.93914\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[121]\ttraining's rmse: 6.44646\tvalid_1's rmse: 5.93984\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[122]\ttraining's rmse: 6.44613\tvalid_1's rmse: 5.94034\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[123]\ttraining's rmse: 6.44278\tvalid_1's rmse: 5.93597\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[124]\ttraining's rmse: 6.44234\tvalid_1's rmse: 5.93631\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[125]\ttraining's rmse: 6.44183\tvalid_1's rmse: 5.93598\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[126]\ttraining's rmse: 6.44145\tvalid_1's rmse: 5.93651\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[127]\ttraining's rmse: 6.4409\tvalid_1's rmse: 5.93617\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[128]\ttraining's rmse: 6.43759\tvalid_1's rmse: 5.9314\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[129]\ttraining's rmse: 6.43715\tvalid_1's rmse: 5.93177\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[130]\ttraining's rmse: 6.43681\tvalid_1's rmse: 5.93244\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[131]\ttraining's rmse: 6.43628\tvalid_1's rmse: 5.93273\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[132]\ttraining's rmse: 6.43589\tvalid_1's rmse: 5.93364\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[133]\ttraining's rmse: 6.43268\tvalid_1's rmse: 5.92951\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[134]\ttraining's rmse: 6.43228\tvalid_1's rmse: 5.93031\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[135]\ttraining's rmse: 6.4319\tvalid_1's rmse: 5.93097\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[136]\ttraining's rmse: 6.43142\tvalid_1's rmse: 5.93144\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[137]\ttraining's rmse: 6.43094\tvalid_1's rmse: 5.93213\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[138]\ttraining's rmse: 6.42773\tvalid_1's rmse: 5.92765\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[139]\ttraining's rmse: 6.42733\tvalid_1's rmse: 5.92806\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[140]\ttraining's rmse: 6.42699\tvalid_1's rmse: 5.92861\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[141]\ttraining's rmse: 6.4267\tvalid_1's rmse: 5.9291\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[142]\ttraining's rmse: 6.42645\tvalid_1's rmse: 5.92968\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[143]\ttraining's rmse: 6.42328\tvalid_1's rmse: 5.92512\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[144]\ttraining's rmse: 6.4229\tvalid_1's rmse: 5.92534\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[145]\ttraining's rmse: 6.42244\tvalid_1's rmse: 5.92514\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[146]\ttraining's rmse: 6.4221\tvalid_1's rmse: 5.92576\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[147]\ttraining's rmse: 6.42173\tvalid_1's rmse: 5.92571\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[148]\ttraining's rmse: 6.41865\tvalid_1's rmse: 5.92175\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[149]\ttraining's rmse: 6.41828\tvalid_1's rmse: 5.92261\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[150]\ttraining's rmse: 6.41797\tvalid_1's rmse: 5.92298\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[151]\ttraining's rmse: 6.41765\tvalid_1's rmse: 5.92386\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[152]\ttraining's rmse: 6.41724\tvalid_1's rmse: 5.92437\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[153]\ttraining's rmse: 6.41422\tvalid_1's rmse: 5.9203\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[154]\ttraining's rmse: 6.41377\tvalid_1's rmse: 5.92041\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[155]\ttraining's rmse: 6.41343\tvalid_1's rmse: 5.92054\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[156]\ttraining's rmse: 6.41307\tvalid_1's rmse: 5.9213\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[157]\ttraining's rmse: 6.41275\tvalid_1's rmse: 5.92192\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[158]\ttraining's rmse: 6.40971\tvalid_1's rmse: 5.91794\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[159]\ttraining's rmse: 6.40933\tvalid_1's rmse: 5.91854\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[160]\ttraining's rmse: 6.409\tvalid_1's rmse: 5.91919\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[161]\ttraining's rmse: 6.40873\tvalid_1's rmse: 5.91967\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[162]\ttraining's rmse: 6.4084\tvalid_1's rmse: 5.91974\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[163]\ttraining's rmse: 6.40544\tvalid_1's rmse: 5.9158\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[164]\ttraining's rmse: 6.40508\tvalid_1's rmse: 5.91638\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[165]\ttraining's rmse: 6.40475\tvalid_1's rmse: 5.91683\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[166]\ttraining's rmse: 6.40448\tvalid_1's rmse: 5.91741\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[167]\ttraining's rmse: 6.40424\tvalid_1's rmse: 5.91787\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[168]\ttraining's rmse: 6.40131\tvalid_1's rmse: 5.91392\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[169]\ttraining's rmse: 6.40086\tvalid_1's rmse: 5.91476\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[170]\ttraining's rmse: 6.40057\tvalid_1's rmse: 5.9153\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[171]\ttraining's rmse: 6.40028\tvalid_1's rmse: 5.91588\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[172]\ttraining's rmse: 6.40005\tvalid_1's rmse: 5.91629\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[173]\ttraining's rmse: 6.39714\tvalid_1's rmse: 5.91227\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[174]\ttraining's rmse: 6.39665\tvalid_1's rmse: 5.91233\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[175]\ttraining's rmse: 6.39631\tvalid_1's rmse: 5.91333\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[176]\ttraining's rmse: 6.39602\tvalid_1's rmse: 5.91419\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[177]\ttraining's rmse: 6.3956\tvalid_1's rmse: 5.91426\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[178]\ttraining's rmse: 6.39277\tvalid_1's rmse: 5.91078\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[179]\ttraining's rmse: 6.39243\tvalid_1's rmse: 5.91165\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[180]\ttraining's rmse: 6.392\tvalid_1's rmse: 5.91167\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[181]\ttraining's rmse: 6.39172\tvalid_1's rmse: 5.91275\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[182]\ttraining's rmse: 6.39149\tvalid_1's rmse: 5.9132\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[183]\ttraining's rmse: 6.38869\tvalid_1's rmse: 5.90955\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[184]\ttraining's rmse: 6.38794\tvalid_1's rmse: 5.90976\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[185]\ttraining's rmse: 6.38765\tvalid_1's rmse: 5.91052\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[186]\ttraining's rmse: 6.3874\tvalid_1's rmse: 5.91132\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[187]\ttraining's rmse: 6.38702\tvalid_1's rmse: 5.91143\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[188]\ttraining's rmse: 6.38401\tvalid_1's rmse: 5.90794\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[189]\ttraining's rmse: 6.38367\tvalid_1's rmse: 5.90873\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[190]\ttraining's rmse: 6.38338\tvalid_1's rmse: 5.90916\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[191]\ttraining's rmse: 6.383\tvalid_1's rmse: 5.90921\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[192]\ttraining's rmse: 6.38276\tvalid_1's rmse: 5.90993\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[193]\ttraining's rmse: 6.38007\tvalid_1's rmse: 5.90655\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[194]\ttraining's rmse: 6.37962\tvalid_1's rmse: 5.90666\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[195]\ttraining's rmse: 6.37933\tvalid_1's rmse: 5.90739\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[196]\ttraining's rmse: 6.379\tvalid_1's rmse: 5.90823\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[197]\ttraining's rmse: 6.37863\tvalid_1's rmse: 5.90845\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[198]\ttraining's rmse: 6.37596\tvalid_1's rmse: 5.9051\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[199]\ttraining's rmse: 6.37564\tvalid_1's rmse: 5.90595\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[200]\ttraining's rmse: 6.37525\tvalid_1's rmse: 5.90604\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[201]\ttraining's rmse: 6.37499\tvalid_1's rmse: 5.90674\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[202]\ttraining's rmse: 6.37476\tvalid_1's rmse: 5.90756\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[203]\ttraining's rmse: 6.372\tvalid_1's rmse: 5.90359\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[204]\ttraining's rmse: 6.37169\tvalid_1's rmse: 5.90438\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[205]\ttraining's rmse: 6.37142\tvalid_1's rmse: 5.90525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[206]\ttraining's rmse: 6.37106\tvalid_1's rmse: 5.90548\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[207]\ttraining's rmse: 6.37084\tvalid_1's rmse: 5.90642\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[208]\ttraining's rmse: 6.36823\tvalid_1's rmse: 5.90313\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[209]\ttraining's rmse: 6.3677\tvalid_1's rmse: 5.90384\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[210]\ttraining's rmse: 6.36732\tvalid_1's rmse: 5.90393\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[211]\ttraining's rmse: 6.36707\tvalid_1's rmse: 5.90473\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[212]\ttraining's rmse: 6.36683\tvalid_1's rmse: 5.90531\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[213]\ttraining's rmse: 6.36426\tvalid_1's rmse: 5.90178\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[214]\ttraining's rmse: 6.36366\tvalid_1's rmse: 5.90207\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[215]\ttraining's rmse: 6.36339\tvalid_1's rmse: 5.90281\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[216]\ttraining's rmse: 6.36316\tvalid_1's rmse: 5.90352\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[217]\ttraining's rmse: 6.36284\tvalid_1's rmse: 5.90364\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[218]\ttraining's rmse: 6.3603\tvalid_1's rmse: 5.90042\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[219]\ttraining's rmse: 6.36\tvalid_1's rmse: 5.9012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[220]\ttraining's rmse: 6.35963\tvalid_1's rmse: 5.90131\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[221]\ttraining's rmse: 6.3594\tvalid_1's rmse: 5.90202\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[222]\ttraining's rmse: 6.35912\tvalid_1's rmse: 5.90218\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[223]\ttraining's rmse: 6.35661\tvalid_1's rmse: 5.89863\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[224]\ttraining's rmse: 6.35621\tvalid_1's rmse: 5.89881\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[225]\ttraining's rmse: 6.35595\tvalid_1's rmse: 5.89951\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[226]\ttraining's rmse: 6.3557\tvalid_1's rmse: 5.90027\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[227]\ttraining's rmse: 6.35531\tvalid_1's rmse: 5.90038\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[228]\ttraining's rmse: 6.35283\tvalid_1's rmse: 5.89722\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[229]\ttraining's rmse: 6.35254\tvalid_1's rmse: 5.898\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[230]\ttraining's rmse: 6.35219\tvalid_1's rmse: 5.89808\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[231]\ttraining's rmse: 6.35196\tvalid_1's rmse: 5.89887\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[232]\ttraining's rmse: 6.35172\tvalid_1's rmse: 5.89964\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[233]\ttraining's rmse: 6.34928\tvalid_1's rmse: 5.89633\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[234]\ttraining's rmse: 6.34885\tvalid_1's rmse: 5.89706\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[235]\ttraining's rmse: 6.34851\tvalid_1's rmse: 5.89724\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[236]\ttraining's rmse: 6.34828\tvalid_1's rmse: 5.89801\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[237]\ttraining's rmse: 6.34809\tvalid_1's rmse: 5.89873\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[238]\ttraining's rmse: 6.34778\tvalid_1's rmse: 5.89889\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[239]\ttraining's rmse: 6.34528\tvalid_1's rmse: 5.89569\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[240]\ttraining's rmse: 6.34502\tvalid_1's rmse: 5.89642\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[241]\ttraining's rmse: 6.3447\tvalid_1's rmse: 5.89652\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[242]\ttraining's rmse: 6.3445\tvalid_1's rmse: 5.89716\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[243]\ttraining's rmse: 6.34215\tvalid_1's rmse: 5.89412\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[244]\ttraining's rmse: 6.34165\tvalid_1's rmse: 5.89446\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[245]\ttraining's rmse: 6.3414\tvalid_1's rmse: 5.89516\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[246]\ttraining's rmse: 6.34116\tvalid_1's rmse: 5.89596\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[247]\ttraining's rmse: 6.34087\tvalid_1's rmse: 5.89618\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[248]\ttraining's rmse: 6.33854\tvalid_1's rmse: 5.89319\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[249]\ttraining's rmse: 6.33818\tvalid_1's rmse: 5.89404\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[250]\ttraining's rmse: 6.33785\tvalid_1's rmse: 5.89433\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[251]\ttraining's rmse: 6.33763\tvalid_1's rmse: 5.89505\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[252]\ttraining's rmse: 6.33725\tvalid_1's rmse: 5.89558\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[253]\ttraining's rmse: 6.33494\tvalid_1's rmse: 5.89245\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[254]\ttraining's rmse: 6.33458\tvalid_1's rmse: 5.89316\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[255]\ttraining's rmse: 6.33425\tvalid_1's rmse: 5.89358\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[256]\ttraining's rmse: 6.33391\tvalid_1's rmse: 5.89424\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[257]\ttraining's rmse: 6.33366\tvalid_1's rmse: 5.89471\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[258]\ttraining's rmse: 6.33116\tvalid_1's rmse: 5.89175\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[259]\ttraining's rmse: 6.3308\tvalid_1's rmse: 5.89192\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[260]\ttraining's rmse: 6.33055\tvalid_1's rmse: 5.89263\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[261]\ttraining's rmse: 6.33027\tvalid_1's rmse: 5.89318\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[262]\ttraining's rmse: 6.32999\tvalid_1's rmse: 5.89328\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[263]\ttraining's rmse: 6.32776\tvalid_1's rmse: 5.89038\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[264]\ttraining's rmse: 6.32749\tvalid_1's rmse: 5.89115\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[265]\ttraining's rmse: 6.32717\tvalid_1's rmse: 5.89127\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[266]\ttraining's rmse: 6.32696\tvalid_1's rmse: 5.892\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[267]\ttraining's rmse: 6.32673\tvalid_1's rmse: 5.89265\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[268]\ttraining's rmse: 6.3245\tvalid_1's rmse: 5.88939\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[269]\ttraining's rmse: 6.32417\tvalid_1's rmse: 5.8901\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[270]\ttraining's rmse: 6.32381\tvalid_1's rmse: 5.8904\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[271]\ttraining's rmse: 6.32359\tvalid_1's rmse: 5.89114\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[272]\ttraining's rmse: 6.32341\tvalid_1's rmse: 5.89176\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[273]\ttraining's rmse: 6.32121\tvalid_1's rmse: 5.88864\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[274]\ttraining's rmse: 6.32084\tvalid_1's rmse: 5.88926\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[275]\ttraining's rmse: 6.32062\tvalid_1's rmse: 5.88983\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[276]\ttraining's rmse: 6.32036\tvalid_1's rmse: 5.89001\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[277]\ttraining's rmse: 6.32017\tvalid_1's rmse: 5.89054\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[278]\ttraining's rmse: 6.31799\tvalid_1's rmse: 5.88742\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[279]\ttraining's rmse: 6.31768\tvalid_1's rmse: 5.88809\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[280]\ttraining's rmse: 6.31737\tvalid_1's rmse: 5.88837\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[281]\ttraining's rmse: 6.31718\tvalid_1's rmse: 5.88898\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[282]\ttraining's rmse: 6.31699\tvalid_1's rmse: 5.88959\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[283]\ttraining's rmse: 6.31478\tvalid_1's rmse: 5.88631\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[284]\ttraining's rmse: 6.31444\tvalid_1's rmse: 5.88649\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[285]\ttraining's rmse: 6.3142\tvalid_1's rmse: 5.88734\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[286]\ttraining's rmse: 6.314\tvalid_1's rmse: 5.8878\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[287]\ttraining's rmse: 6.31381\tvalid_1's rmse: 5.88802\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[288]\ttraining's rmse: 6.31169\tvalid_1's rmse: 5.88497\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[289]\ttraining's rmse: 6.31138\tvalid_1's rmse: 5.88571\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[290]\ttraining's rmse: 6.31118\tvalid_1's rmse: 5.88621\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[291]\ttraining's rmse: 6.31096\tvalid_1's rmse: 5.88667\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[292]\ttraining's rmse: 6.31078\tvalid_1's rmse: 5.88715\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[293]\ttraining's rmse: 6.30869\tvalid_1's rmse: 5.88415\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[294]\ttraining's rmse: 6.30839\tvalid_1's rmse: 5.88485\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[295]\ttraining's rmse: 6.30819\tvalid_1's rmse: 5.88552\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[296]\ttraining's rmse: 6.30782\tvalid_1's rmse: 5.88578\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[297]\ttraining's rmse: 6.30762\tvalid_1's rmse: 5.88647\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[298]\ttraining's rmse: 6.30549\tvalid_1's rmse: 5.8834\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[299]\ttraining's rmse: 6.30526\tvalid_1's rmse: 5.88409\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[300]\ttraining's rmse: 6.30501\tvalid_1's rmse: 5.88472\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[301]\ttraining's rmse: 6.30479\tvalid_1's rmse: 5.88532\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[302]\ttraining's rmse: 6.30454\tvalid_1's rmse: 5.88545\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[303]\ttraining's rmse: 6.30249\tvalid_1's rmse: 5.88267\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[304]\ttraining's rmse: 6.30225\tvalid_1's rmse: 5.88338\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[305]\ttraining's rmse: 6.30196\tvalid_1's rmse: 5.8835\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[306]\ttraining's rmse: 6.30177\tvalid_1's rmse: 5.88419\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[307]\ttraining's rmse: 6.30162\tvalid_1's rmse: 5.88493\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[308]\ttraining's rmse: 6.2996\tvalid_1's rmse: 5.88199\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[309]\ttraining's rmse: 6.29923\tvalid_1's rmse: 5.8823\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[310]\ttraining's rmse: 6.29903\tvalid_1's rmse: 5.88303\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[311]\ttraining's rmse: 6.29883\tvalid_1's rmse: 5.88384\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[312]\ttraining's rmse: 6.29859\tvalid_1's rmse: 5.88397\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[313]\ttraining's rmse: 6.29659\tvalid_1's rmse: 5.88127\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[314]\ttraining's rmse: 6.29636\tvalid_1's rmse: 5.88198\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[315]\ttraining's rmse: 6.29608\tvalid_1's rmse: 5.88211\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[316]\ttraining's rmse: 6.2959\tvalid_1's rmse: 5.88279\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[317]\ttraining's rmse: 6.29571\tvalid_1's rmse: 5.88348\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[318]\ttraining's rmse: 6.29375\tvalid_1's rmse: 5.88062\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[319]\ttraining's rmse: 6.29347\tvalid_1's rmse: 5.88129\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[320]\ttraining's rmse: 6.29328\tvalid_1's rmse: 5.88178\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[321]\ttraining's rmse: 6.29307\tvalid_1's rmse: 5.88243\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[322]\ttraining's rmse: 6.29289\tvalid_1's rmse: 5.88293\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[323]\ttraining's rmse: 6.29266\tvalid_1's rmse: 5.88331\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[324]\ttraining's rmse: 6.29065\tvalid_1's rmse: 5.8804\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[325]\ttraining's rmse: 6.2904\tvalid_1's rmse: 5.88104\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[326]\ttraining's rmse: 6.29018\tvalid_1's rmse: 5.88129\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[327]\ttraining's rmse: 6.28992\tvalid_1's rmse: 5.88167\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[328]\ttraining's rmse: 6.28803\tvalid_1's rmse: 5.87889\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[329]\ttraining's rmse: 6.28776\tvalid_1's rmse: 5.87959\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[330]\ttraining's rmse: 6.28757\tvalid_1's rmse: 5.88026\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[331]\ttraining's rmse: 6.28738\tvalid_1's rmse: 5.88083\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[332]\ttraining's rmse: 6.28723\tvalid_1's rmse: 5.88134\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[333]\ttraining's rmse: 6.28536\tvalid_1's rmse: 5.8785\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[334]\ttraining's rmse: 6.28509\tvalid_1's rmse: 5.87888\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[335]\ttraining's rmse: 6.28482\tvalid_1's rmse: 5.87903\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[336]\ttraining's rmse: 6.28464\tvalid_1's rmse: 5.87964\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[337]\ttraining's rmse: 6.28448\tvalid_1's rmse: 5.88025\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[338]\ttraining's rmse: 6.28262\tvalid_1's rmse: 5.87741\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[339]\ttraining's rmse: 6.28228\tvalid_1's rmse: 5.87772\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[340]\ttraining's rmse: 6.28208\tvalid_1's rmse: 5.87845\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[341]\ttraining's rmse: 6.28182\tvalid_1's rmse: 5.87916\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[342]\ttraining's rmse: 6.28159\tvalid_1's rmse: 5.87928\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[343]\ttraining's rmse: 6.27977\tvalid_1's rmse: 5.87681\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[344]\ttraining's rmse: 6.27952\tvalid_1's rmse: 5.87749\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[345]\ttraining's rmse: 6.27926\tvalid_1's rmse: 5.87764\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[346]\ttraining's rmse: 6.27909\tvalid_1's rmse: 5.87826\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[347]\ttraining's rmse: 6.27895\tvalid_1's rmse: 5.87871\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[348]\ttraining's rmse: 6.27713\tvalid_1's rmse: 5.87605\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[349]\ttraining's rmse: 6.27681\tvalid_1's rmse: 5.87636\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[350]\ttraining's rmse: 6.27662\tvalid_1's rmse: 5.87703\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[351]\ttraining's rmse: 6.27631\tvalid_1's rmse: 5.8778\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[352]\ttraining's rmse: 6.27609\tvalid_1's rmse: 5.87797\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[353]\ttraining's rmse: 6.27412\tvalid_1's rmse: 5.87505\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[354]\ttraining's rmse: 6.27391\tvalid_1's rmse: 5.87575\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[355]\ttraining's rmse: 6.27372\tvalid_1's rmse: 5.87626\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[356]\ttraining's rmse: 6.27342\tvalid_1's rmse: 5.87655\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[357]\ttraining's rmse: 6.27327\tvalid_1's rmse: 5.87714\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[358]\ttraining's rmse: 6.27149\tvalid_1's rmse: 5.87466\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[359]\ttraining's rmse: 6.27125\tvalid_1's rmse: 5.87528\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[360]\ttraining's rmse: 6.27101\tvalid_1's rmse: 5.87545\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[361]\ttraining's rmse: 6.27084\tvalid_1's rmse: 5.87606\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[362]\ttraining's rmse: 6.27061\tvalid_1's rmse: 5.87656\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[363]\ttraining's rmse: 6.26885\tvalid_1's rmse: 5.87403\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[364]\ttraining's rmse: 6.26862\tvalid_1's rmse: 5.87464\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[365]\ttraining's rmse: 6.26842\tvalid_1's rmse: 5.87513\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[366]\ttraining's rmse: 6.26826\tvalid_1's rmse: 5.87567\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[367]\ttraining's rmse: 6.26802\tvalid_1's rmse: 5.87595\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[368]\ttraining's rmse: 6.26629\tvalid_1's rmse: 5.87338\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[369]\ttraining's rmse: 6.26606\tvalid_1's rmse: 5.874\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[370]\ttraining's rmse: 6.26586\tvalid_1's rmse: 5.87458\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[371]\ttraining's rmse: 6.2657\tvalid_1's rmse: 5.8751\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[372]\ttraining's rmse: 6.26556\tvalid_1's rmse: 5.87582\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[373]\ttraining's rmse: 6.26385\tvalid_1's rmse: 5.87325\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[374]\ttraining's rmse: 6.26362\tvalid_1's rmse: 5.87388\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[375]\ttraining's rmse: 6.26344\tvalid_1's rmse: 5.87445\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[376]\ttraining's rmse: 6.26322\tvalid_1's rmse: 5.87506\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[377]\ttraining's rmse: 6.26301\tvalid_1's rmse: 5.87515\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[378]\ttraining's rmse: 6.26115\tvalid_1's rmse: 5.87286\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[379]\ttraining's rmse: 6.26094\tvalid_1's rmse: 5.87348\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[380]\ttraining's rmse: 6.26071\tvalid_1's rmse: 5.87363\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[381]\ttraining's rmse: 6.26054\tvalid_1's rmse: 5.87429\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[382]\ttraining's rmse: 6.26021\tvalid_1's rmse: 5.87464\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[383]\ttraining's rmse: 6.2585\tvalid_1's rmse: 5.87205\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[384]\ttraining's rmse: 6.25823\tvalid_1's rmse: 5.87234\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[385]\ttraining's rmse: 6.25789\tvalid_1's rmse: 5.8728\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[386]\ttraining's rmse: 6.25772\tvalid_1's rmse: 5.87343\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[387]\ttraining's rmse: 6.25743\tvalid_1's rmse: 5.8737\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[388]\ttraining's rmse: 6.25579\tvalid_1's rmse: 5.87129\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[389]\ttraining's rmse: 6.25557\tvalid_1's rmse: 5.87194\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[390]\ttraining's rmse: 6.25529\tvalid_1's rmse: 5.87206\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[391]\ttraining's rmse: 6.25508\tvalid_1's rmse: 5.87257\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[392]\ttraining's rmse: 6.25348\tvalid_1's rmse: 5.87012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[393]\ttraining's rmse: 6.25326\tvalid_1's rmse: 5.87074\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[394]\ttraining's rmse: 6.25293\tvalid_1's rmse: 5.87121\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[395]\ttraining's rmse: 6.25255\tvalid_1's rmse: 5.87097\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[396]\ttraining's rmse: 6.25234\tvalid_1's rmse: 5.8716\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[397]\ttraining's rmse: 6.25078\tvalid_1's rmse: 5.8692\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[398]\ttraining's rmse: 6.25055\tvalid_1's rmse: 5.86984\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[399]\ttraining's rmse: 6.25033\tvalid_1's rmse: 5.87048\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[400]\ttraining's rmse: 6.25006\tvalid_1's rmse: 5.87084\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[401]\ttraining's rmse: 6.2499\tvalid_1's rmse: 5.8714\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[402]\ttraining's rmse: 6.24834\tvalid_1's rmse: 5.86902\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[403]\ttraining's rmse: 6.24805\tvalid_1's rmse: 5.86939\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[404]\ttraining's rmse: 6.24782\tvalid_1's rmse: 5.87\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[405]\ttraining's rmse: 6.24741\tvalid_1's rmse: 5.87063\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[406]\ttraining's rmse: 6.24717\tvalid_1's rmse: 5.87085\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[407]\ttraining's rmse: 6.24557\tvalid_1's rmse: 5.86838\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[408]\ttraining's rmse: 6.24512\tvalid_1's rmse: 5.86901\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[409]\ttraining's rmse: 6.24486\tvalid_1's rmse: 5.86945\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[410]\ttraining's rmse: 6.24448\tvalid_1's rmse: 5.87006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[411]\ttraining's rmse: 6.24423\tvalid_1's rmse: 5.87015\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[412]\ttraining's rmse: 6.2427\tvalid_1's rmse: 5.8678\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[413]\ttraining's rmse: 6.24243\tvalid_1's rmse: 5.86815\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[414]\ttraining's rmse: 6.24203\tvalid_1's rmse: 5.86886\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[415]\ttraining's rmse: 6.2418\tvalid_1's rmse: 5.86918\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[416]\ttraining's rmse: 6.24034\tvalid_1's rmse: 5.86695\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[417]\ttraining's rmse: 6.23993\tvalid_1's rmse: 5.86779\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[418]\ttraining's rmse: 6.23966\tvalid_1's rmse: 5.86816\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[419]\ttraining's rmse: 6.23943\tvalid_1's rmse: 5.86839\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[420]\ttraining's rmse: 6.23907\tvalid_1's rmse: 5.86893\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[421]\ttraining's rmse: 6.23757\tvalid_1's rmse: 5.86654\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[422]\ttraining's rmse: 6.23717\tvalid_1's rmse: 5.86717\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[423]\ttraining's rmse: 6.23691\tvalid_1's rmse: 5.86753\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[424]\ttraining's rmse: 6.23658\tvalid_1's rmse: 5.86828\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[425]\ttraining's rmse: 6.23633\tvalid_1's rmse: 5.86858\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[426]\ttraining's rmse: 6.23484\tvalid_1's rmse: 5.8661\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[427]\ttraining's rmse: 6.23445\tvalid_1's rmse: 5.86672\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[428]\ttraining's rmse: 6.23421\tvalid_1's rmse: 5.86705\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[429]\ttraining's rmse: 6.23388\tvalid_1's rmse: 5.86771\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[430]\ttraining's rmse: 6.23365\tvalid_1's rmse: 5.86799\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[431]\ttraining's rmse: 6.23217\tvalid_1's rmse: 5.86561\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[432]\ttraining's rmse: 6.23178\tvalid_1's rmse: 5.86621\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[433]\ttraining's rmse: 6.23156\tvalid_1's rmse: 5.86658\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[434]\ttraining's rmse: 6.23123\tvalid_1's rmse: 5.8672\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[435]\ttraining's rmse: 6.23101\tvalid_1's rmse: 5.86753\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[436]\ttraining's rmse: 6.22957\tvalid_1's rmse: 5.86532\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[437]\ttraining's rmse: 6.22923\tvalid_1's rmse: 5.86608\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[438]\ttraining's rmse: 6.22897\tvalid_1's rmse: 5.86646\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[439]\ttraining's rmse: 6.22872\tvalid_1's rmse: 5.86669\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[440]\ttraining's rmse: 6.22726\tvalid_1's rmse: 5.86465\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[441]\ttraining's rmse: 6.22691\tvalid_1's rmse: 5.86534\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[442]\ttraining's rmse: 6.22664\tvalid_1's rmse: 5.86565\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[443]\ttraining's rmse: 6.22641\tvalid_1's rmse: 5.86598\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[444]\ttraining's rmse: 6.22611\tvalid_1's rmse: 5.86653\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[445]\ttraining's rmse: 6.22468\tvalid_1's rmse: 5.86421\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[446]\ttraining's rmse: 6.22439\tvalid_1's rmse: 5.86453\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[447]\ttraining's rmse: 6.22417\tvalid_1's rmse: 5.86482\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[448]\ttraining's rmse: 6.22386\tvalid_1's rmse: 5.86541\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[449]\ttraining's rmse: 6.22249\tvalid_1's rmse: 5.86316\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[450]\ttraining's rmse: 6.22224\tvalid_1's rmse: 5.86361\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[451]\ttraining's rmse: 6.22204\tvalid_1's rmse: 5.86422\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[452]\ttraining's rmse: 6.2218\tvalid_1's rmse: 5.86457\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[453]\ttraining's rmse: 6.22162\tvalid_1's rmse: 5.86496\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[454]\ttraining's rmse: 6.22022\tvalid_1's rmse: 5.86279\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[455]\ttraining's rmse: 6.21999\tvalid_1's rmse: 5.86321\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[456]\ttraining's rmse: 6.21965\tvalid_1's rmse: 5.86385\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[457]\ttraining's rmse: 6.21942\tvalid_1's rmse: 5.86419\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[458]\ttraining's rmse: 6.21808\tvalid_1's rmse: 5.86206\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[459]\ttraining's rmse: 6.21781\tvalid_1's rmse: 5.86255\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[460]\ttraining's rmse: 6.21759\tvalid_1's rmse: 5.86301\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[461]\ttraining's rmse: 6.21727\tvalid_1's rmse: 5.86361\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[462]\ttraining's rmse: 6.21705\tvalid_1's rmse: 5.86391\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[463]\ttraining's rmse: 6.2157\tvalid_1's rmse: 5.86169\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[464]\ttraining's rmse: 6.2154\tvalid_1's rmse: 5.86235\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[465]\ttraining's rmse: 6.21517\tvalid_1's rmse: 5.8626\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[466]\ttraining's rmse: 6.21496\tvalid_1's rmse: 5.86285\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[467]\ttraining's rmse: 6.21366\tvalid_1's rmse: 5.86083\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[468]\ttraining's rmse: 6.21334\tvalid_1's rmse: 5.8615\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[469]\ttraining's rmse: 6.21312\tvalid_1's rmse: 5.86189\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[470]\ttraining's rmse: 6.2129\tvalid_1's rmse: 5.86225\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[471]\ttraining's rmse: 6.21271\tvalid_1's rmse: 5.86262\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[472]\ttraining's rmse: 6.21141\tvalid_1's rmse: 5.86057\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[473]\ttraining's rmse: 6.21111\tvalid_1's rmse: 5.86123\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[474]\ttraining's rmse: 6.21089\tvalid_1's rmse: 5.86158\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[475]\ttraining's rmse: 6.21072\tvalid_1's rmse: 5.86211\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[476]\ttraining's rmse: 6.20946\tvalid_1's rmse: 5.86002\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[477]\ttraining's rmse: 6.20915\tvalid_1's rmse: 5.86069\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[478]\ttraining's rmse: 6.20893\tvalid_1's rmse: 5.86107\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[479]\ttraining's rmse: 6.20878\tvalid_1's rmse: 5.86154\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[480]\ttraining's rmse: 6.20864\tvalid_1's rmse: 5.86192\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[481]\ttraining's rmse: 6.20736\tvalid_1's rmse: 5.85981\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[482]\ttraining's rmse: 6.20716\tvalid_1's rmse: 5.86028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[483]\ttraining's rmse: 6.207\tvalid_1's rmse: 5.8606\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[484]\ttraining's rmse: 6.20681\tvalid_1's rmse: 5.86095\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[485]\ttraining's rmse: 6.20558\tvalid_1's rmse: 5.85901\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[486]\ttraining's rmse: 6.20537\tvalid_1's rmse: 5.85969\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[487]\ttraining's rmse: 6.20516\tvalid_1's rmse: 5.86006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[488]\ttraining's rmse: 6.205\tvalid_1's rmse: 5.86058\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[489]\ttraining's rmse: 6.20482\tvalid_1's rmse: 5.86088\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[490]\ttraining's rmse: 6.20353\tvalid_1's rmse: 5.85878\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[491]\ttraining's rmse: 6.20333\tvalid_1's rmse: 5.85956\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[492]\ttraining's rmse: 6.20318\tvalid_1's rmse: 5.85992\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[493]\ttraining's rmse: 6.20297\tvalid_1's rmse: 5.86014\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[494]\ttraining's rmse: 6.2018\tvalid_1's rmse: 5.85839\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[495]\ttraining's rmse: 6.2015\tvalid_1's rmse: 5.85906\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[496]\ttraining's rmse: 6.20128\tvalid_1's rmse: 5.85947\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[497]\ttraining's rmse: 6.20101\tvalid_1's rmse: 5.85976\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[498]\ttraining's rmse: 6.20086\tvalid_1's rmse: 5.86008\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[499]\ttraining's rmse: 6.19965\tvalid_1's rmse: 5.85812\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[500]\ttraining's rmse: 6.19946\tvalid_1's rmse: 5.85869\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's rmse: 6.19946\tvalid_1's rmse: 5.85869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_1=model_1.predict(test_x)\n",
        "\n",
        "# rmes 식 지정\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "def rmse(y_pred, y_test):\n",
        "    return np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "rmse(test_y, pred_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L02afS0gKIYY",
        "outputId": "089d9445-c9e7-44d3-b927-f17f9d83f2ee"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.858688358329336"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) 하이퍼 파라미터 조정"
      ],
      "metadata": {
        "id": "Wpfzc0Evz_9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "lightGBM 에서 조정할 수 있는 하이퍼 파라미터는 다음과 같다.\n",
        "\n",
        "**<중요 파라미터>**\n",
        "\n",
        "- learning_rate: 중요한 매개변수인 학습률은 일반적으로 학습률이 낮을수록 더 좋지만 모델 학습 속도가 느려진다.learning_rate는 낮추고 num_estimators는 크게 하여 최상의 결과가 나올 수 았다.\n",
        "\n",
        "- min_data_in_leaf : 과적 합을 줄이는 방법으로 모델이 너무 구체적이되지 않도록 각 리프에 지정된 수의 관측치가 있어야 한다.\n",
        "\n",
        "- min_child_samples : 파라미터는 최종 결정 클래스인 Leaf Node가 되기 위해서 최소한으로 필요한 데이터 개체의 수를 의미하며, 과적합을 제어하는 파라미터이다. 이 파라미터의 최적값은 훈련 데이터의 개수와 num_leaves에 의해 결정된다. 너무 큰 숫자로 설정하면 under-fitting이 일어날 수 있으며, 아주 큰 데이터셋이라면 적어도 수백~수천 정도로 가정하는 것이 편리하다.\n",
        "\n",
        "- max_depth: 개별 트리의 복잡성은 과적 합의 결정 요인일 수 있기에 지정할 수 있다. 트리의 최대 깊이를 지정한다.\n",
        "\n",
        "- num_leaves: 트리가 가질 수있는 최대 리프 수를 제한한다. LightGBM은 잎 모양의 나무 성장을 조정하므로이 max_depth와 함께 조정하는 것이 중요하다. 과적합을 방지하기 위해 num_leaves는 2^(max_depth)보다 작아야 한다.\n",
        "\n",
        "- sub_sample : 과적합을 제어하기 위해 데이터를 샘플링하는 비율을 의미한다.\n",
        "\n",
        "- feature_fraction : 모델이 너무 구체적이지 않도록 방지하며 각 반복에서 무작위로 선택되는 특성의 비율을 나타낸다.\n",
        "\n",
        "< 보조 파라미터>\n",
        "\n",
        "- Bagging_fraction: 무작위로 선택된 행 샘플을 각 반복에서 사용할 수 있다. feature_fraction과 유사하지만 행의 경우이다. \n",
        "\n",
        "- bagging_freq : 선택한 행을 업데이트하기위한 반복 빈도를 지정한다.\n",
        "\n",
        "- colsample_bytree : 개별 트리를 학습할 때마다 무작위로 선택하는 피쳐의 비율을 제어한다. \n",
        "\n",
        "- reg_alpha : L1 규제를, \n",
        "\n",
        "- reg_lambda: L2 규제를 의미한다. 이들은 과적합을 제어하기에 좋은 옵션들이다.\n",
        "\n",
        "\n",
        "- LightGBM은 L1 및 L2 정규화를 모두 지원한다."
      ],
      "metadata": {
        "id": "OfsADLwsR-GI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번에는 GridSearchCV 를 사용해서 구해보겠다. \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**<lightGBM 모델 디폴트 설정>**\n",
        "\n",
        "def def __init__(boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=100, subsample_for_bin=200000, objective=None, class_weight=None, min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, n_jobs=-1, silent=True, importance_type='split', **kwargs)\n",
        "LightGBM classifier."
      ],
      "metadata": {
        "id": "LpXHRhKkJFYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) 직접 파라미터 조정 진행\n",
        "params_2 = { \n",
        "          'learning_rate': 0.6, # 변경\n",
        "          'max_depth': 5, \n",
        "          'boosting': 'gbdt', # traditional gradient boosting decision tree\n",
        "          'objective': 'regression', \n",
        "          'metric': 'rmse',\n",
        "          'is_training_metric': True,\n",
        "          #'min_data_in_leaf':600,\n",
        "          #'feature_fraction':0.3,\n",
        "          #'bagging_fraction':0.8,\n",
        "          #'bagging_freq':2,\n",
        "          #'max_depth':5,\n",
        "          #'num_leaves':8,\n",
        "         }\n",
        "\n",
        "\n",
        "model_2 = lgb.train(params_2, \n",
        "                    train_ds, \n",
        "                    num_boost_round=500, # 부스팅 수\n",
        "                    valid_sets=[train_ds, test_ds ],\n",
        "                    early_stopping_rounds=100, # 조기종료 설정\n",
        "                    verbose_eval=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQb4kobSQsc0",
        "outputId": "df63610b-3e7d-4998-a795-6a761848c6bd"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001062 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 632\n",
            "[LightGBM] [Info] Number of data points in the train set: 25347, number of used features: 316\n",
            "[LightGBM] [Info] Start training from score 4.880972\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[100]\ttraining's rmse: 6.15361\tvalid_1's rmse: 5.85868\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[200]\ttraining's rmse: 6.01772\tvalid_1's rmse: 5.81763\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[300]\ttraining's rmse: 5.96338\tvalid_1's rmse: 5.81914\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Early stopping, best iteration is:\n",
            "[262]\ttraining's rmse: 5.98293\tvalid_1's rmse: 5.80668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_2=model_2.predict(test_x)\n",
        "\n",
        "# rmes 식 지정\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "def rmse(y_pred, y_test):\n",
        "    return np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "rmse(test_y, pred_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgE9DUi6UxoA",
        "outputId": "9901713f-be5a-4f7c-a27b-6c8cd13e94b8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.80668183414789"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습률을 조정한 결과 5.811058577878222 -> 5.80668183414789 가 조정된 것이 확인된다. \n",
        "\n",
        "나머지 변수들의 조합으로는 RMSE 를 더 낮추지 못하였다."
      ],
      "metadata": {
        "id": "Dfc0SjsBXdw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model_3=lgb.LGBMClassifier()\n",
        "\n",
        "# 2) GridSearchCV 사용\n",
        "params_3 = { \n",
        "          'learning_rate': [0.1, 0.5], \n",
        "          'min_child_samples': [10, 30],\n",
        "          'max_depth': [-1,4], \n",
        "          'boosting': ['gbdt', 'dart'],\n",
        "          'n_jobs': [1],\n",
        "          'reg_alpha' : [0.0, 0.1],\n",
        "          'reg_lambda' : [0,0, 0.1],   \n",
        "         }\n",
        "\n",
        "grid = GridSearchCV(model_3, params_3 , verbose=200)"
      ],
      "metadata": {
        "id": "FcD9SOTwGMsv"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid.fit(train_x, train_y, early_stopping_rounds=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUsWdYG4fisb",
        "outputId": "281e1cd7-9ba8-4921-ec7e-6726e3f8986d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.9s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.4s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.3s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    2.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    3.3s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    3.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    4.3s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    4.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    5.3s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    5.7s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    6.1s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    6.6s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    7.0s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    7.5s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    7.9s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    8.4s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    8.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    9.2s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    9.6s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:   10.1s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:   10.6s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   11.0s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   11.4s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:   11.9s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   12.3s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:   12.7s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:   13.1s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   13.6s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:   14.0s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:   14.4s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:   14.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:   15.3s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:   15.7s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:   16.2s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:   16.6s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:   17.0s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:   17.4s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:   17.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:   18.3s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:   18.7s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:   19.1s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed:   19.5s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   20.0s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed:   20.4s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed:   20.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:   21.2s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:   21.6s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   22.0s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed:   22.4s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:   22.9s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed:   23.3s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:   23.7s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  55 out of  55 | elapsed:   24.1s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  56 out of  56 | elapsed:   24.5s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  57 out of  57 | elapsed:   24.9s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  58 out of  58 | elapsed:   25.3s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  59 out of  59 | elapsed:   25.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   26.2s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  61 out of  61 | elapsed:   26.6s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  62 out of  62 | elapsed:   27.0s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:   27.4s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:   27.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:   28.2s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  66 out of  66 | elapsed:   28.6s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  67 out of  67 | elapsed:   29.0s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  68 out of  68 | elapsed:   29.4s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  69 out of  69 | elapsed:   29.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:   30.3s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  71 out of  71 | elapsed:   30.7s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:   31.1s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  73 out of  73 | elapsed:   31.5s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  74 out of  74 | elapsed:   31.9s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:   32.3s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  76 out of  76 | elapsed:   32.7s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  77 out of  77 | elapsed:   33.2s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  78 out of  78 | elapsed:   33.6s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  79 out of  79 | elapsed:   34.0s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:   34.4s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed:   34.9s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  82 out of  82 | elapsed:   35.3s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  83 out of  83 | elapsed:   35.7s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  84 out of  84 | elapsed:   36.1s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  85 out of  85 | elapsed:   36.5s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  86 out of  86 | elapsed:   36.9s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  87 out of  87 | elapsed:   37.4s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  88 out of  88 | elapsed:   37.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  89 out of  89 | elapsed:   38.2s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:   38.6s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  91 out of  91 | elapsed:   39.0s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  92 out of  92 | elapsed:   39.4s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  93 out of  93 | elapsed:   39.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  94 out of  94 | elapsed:   40.1s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  95 out of  95 | elapsed:   40.5s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  96 out of  96 | elapsed:   40.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  97 out of  97 | elapsed:   41.2s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  98 out of  98 | elapsed:   41.6s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done  99 out of  99 | elapsed:   42.0s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   42.4s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 101 out of 101 | elapsed:   42.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 102 out of 102 | elapsed:   43.3s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 103 out of 103 | elapsed:   43.7s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 104 out of 104 | elapsed:   44.1s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 105 out of 105 | elapsed:   44.4s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 106 out of 106 | elapsed:   44.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 107 out of 107 | elapsed:   45.2s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed:   45.5s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 109 out of 109 | elapsed:   45.9s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 110 out of 110 | elapsed:   46.3s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 111 out of 111 | elapsed:   46.7s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 112 out of 112 | elapsed:   47.1s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 113 out of 113 | elapsed:   47.5s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 114 out of 114 | elapsed:   47.9s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 115 out of 115 | elapsed:   48.2s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 116 out of 116 | elapsed:   48.6s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 117 out of 117 | elapsed:   49.1s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 118 out of 118 | elapsed:   49.5s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 119 out of 119 | elapsed:   49.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   50.2s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done 121 out of 121 | elapsed:   50.7s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done 122 out of 122 | elapsed:   51.2s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done 123 out of 123 | elapsed:   51.7s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done 124 out of 124 | elapsed:   52.2s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:   52.7s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done 126 out of 126 | elapsed:   53.2s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done 127 out of 127 | elapsed:   53.7s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done 128 out of 128 | elapsed:   54.2s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done 129 out of 129 | elapsed:   54.6s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done 130 out of 130 | elapsed:   55.1s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done 131 out of 131 | elapsed:   55.6s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done 132 out of 132 | elapsed:   56.1s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done 133 out of 133 | elapsed:   56.6s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 134 out of 134 | elapsed:   57.0s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 135 out of 135 | elapsed:   57.5s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 136 out of 136 | elapsed:   57.9s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 137 out of 137 | elapsed:   58.3s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 138 out of 138 | elapsed:   58.8s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 139 out of 139 | elapsed:   59.2s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 140 out of 140 | elapsed:   59.6s remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done 141 out of 141 | elapsed:  1.0min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done 142 out of 142 | elapsed:  1.0min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 143 out of 143 | elapsed:  1.0min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 144 out of 144 | elapsed:  1.0min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 145 out of 145 | elapsed:  1.0min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 146 out of 146 | elapsed:  1.0min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 147 out of 147 | elapsed:  1.0min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 148 out of 148 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 149 out of 149 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.5s\n",
            "[Parallel(n_jobs=1)]: Done 151 out of 151 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 152 out of 152 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 153 out of 153 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 154 out of 154 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 155 out of 155 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 156 out of 156 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 157 out of 157 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 158 out of 158 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 159 out of 159 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 161 out of 161 | elapsed:  1.1min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 163 out of 163 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 164 out of 164 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 165 out of 165 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 166 out of 166 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 167 out of 167 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 168 out of 168 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 169 out of 169 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 170 out of 170 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 171 out of 171 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 172 out of 172 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 173 out of 173 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 174 out of 174 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 175 out of 175 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 176 out of 176 | elapsed:  1.2min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 177 out of 177 | elapsed:  1.3min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 178 out of 178 | elapsed:  1.3min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 179 out of 179 | elapsed:  1.3min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:  1.3min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 181 out of 181 | elapsed:  1.3min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 182 out of 182 | elapsed:  1.3min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 183 out of 183 | elapsed:  1.3min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   1.0s\n",
            "[Parallel(n_jobs=1)]: Done 184 out of 184 | elapsed:  1.3min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 185 out of 185 | elapsed:  1.3min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 186 out of 186 | elapsed:  1.3min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 187 out of 187 | elapsed:  1.3min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 188 out of 188 | elapsed:  1.3min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 189 out of 189 | elapsed:  1.3min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 190 out of 190 | elapsed:  1.4min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 191 out of 191 | elapsed:  1.4min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 192 out of 192 | elapsed:  1.4min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 193 out of 193 | elapsed:  1.4min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 194 out of 194 | elapsed:  1.4min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 195 out of 195 | elapsed:  1.4min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 196 out of 196 | elapsed:  1.4min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 197 out of 197 | elapsed:  1.4min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 198 out of 198 | elapsed:  1.4min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[Parallel(n_jobs=1)]: Done 199 out of 199 | elapsed:  1.4min remaining:    0.0s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.5s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.3s\n",
            "[CV] boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[CV]  boosting=gbdt, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=nan, total=   0.4s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.375, total=  18.7s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.033, total=  19.6s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.175, total=  15.4s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.548, total=  16.9s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.046, total=  18.7s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.375, total=  18.0s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.033, total=  19.6s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.175, total=  15.5s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.548, total=  16.9s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.046, total=  18.8s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.550, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.552, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.551, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.554, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.553, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.190, total=  17.6s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.144, total=  15.6s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.039, total=  16.1s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.186, total=  14.7s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.556, total=  19.7s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.190, total=  17.6s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.144, total=  15.6s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.039, total=  16.1s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.186, total=  14.9s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.556, total=  19.8s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.552, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.554, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.552, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.554, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.554, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.509, total=  19.3s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.231, total=  19.6s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.143, total=  23.6s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.127, total=  18.2s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.040, total=  22.6s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.509, total=  19.1s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.231, total=  19.8s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.143, total=  23.7s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.127, total=  18.4s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.040, total=  22.8s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.556, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.555, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.556, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.555, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.556, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.008, total=  18.1s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.003, total=  24.7s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.193, total=  15.1s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.187, total=  32.5s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.219, total=  14.6s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.008, total=  18.2s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.003, total=  24.8s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.193, total=  15.1s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.187, total=  33.2s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.219, total=  14.5s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.556, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.555, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.556, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.556, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.555, total= 1.1min\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.048, total=  12.3s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.012, total=  11.8s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.001, total=  10.0s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.006, total=   9.7s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.257, total=  11.0s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.048, total=  12.2s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.012, total=  11.7s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.001, total=  10.2s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.006, total=   9.8s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.257, total=  11.1s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.556, total=  34.2s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.555, total=  34.0s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.556, total=  33.7s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.556, total=  33.7s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.556, total=  33.1s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.025, total=   9.3s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.072, total=  10.7s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.037, total=  12.5s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.370, total=  10.9s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.000, total=  11.9s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.025, total=   9.4s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.072, total=  10.8s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.037, total=  12.3s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.370, total=  10.9s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.000, total=  11.7s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.555, total=  34.0s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.555, total=  33.9s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.556, total=  33.4s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.556, total=  33.1s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.556, total=  32.6s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.001, total=  13.6s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.000, total=   9.9s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.273, total=  12.1s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.032, total=  11.2s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.031, total=  13.8s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.001, total=  13.5s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.000, total=   9.9s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.273, total=  12.0s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.032, total=  11.0s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.031, total=  14.0s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.556, total=  34.3s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.555, total=  34.4s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.556, total=  34.1s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.556, total=  33.7s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.555, total=  33.1s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.052, total=  11.6s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.121, total=  11.0s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.385, total=  12.6s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.014, total=  10.2s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.041, total=  11.6s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.052, total=  11.3s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.121, total=  11.1s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.385, total=  12.9s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.014, total=  10.2s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.041, total=  11.4s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.556, total=  33.7s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.555, total=  33.6s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.556, total=  33.3s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.556, total=  32.8s\n",
            "[CV] boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.1, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.556, total=  33.1s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.000, total=  11.9s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.319, total=  11.4s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.080, total=  13.2s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.004, total=  12.1s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.327, total=  12.4s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.000, total=  12.0s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.319, total=  11.4s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.080, total=  13.2s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.004, total=  12.3s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.327, total=  12.5s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.539, total= 1.2min\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.538, total= 1.2min\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.544, total= 1.2min\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.540, total= 1.2min\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.540, total= 1.2min\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.000, total=  11.3s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.000, total=  10.9s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.037, total=   9.9s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.190, total=  10.6s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.091, total=  10.9s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.000, total=  11.4s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.000, total=  11.0s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.037, total=   9.6s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.190, total=  10.7s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.091, total=  10.7s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.540, total= 1.0min\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.539, total=  59.2s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.547, total=  59.1s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.538, total=  57.1s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.542, total=  59.0s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.000, total=  11.7s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.541, total=  11.0s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.005, total=  11.2s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.000, total=  10.7s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.273, total=  11.5s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.000, total=  11.4s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.541, total=  10.6s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.005, total=  11.0s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.000, total=  11.0s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.273, total=  11.8s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.548, total= 1.2min\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.546, total= 1.3min\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.551, total= 1.3min\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.548, total= 1.2min\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.547, total= 1.3min\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.008, total=  11.9s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.043, total=  10.2s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.547, total=   9.4s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.546, total=   9.8s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.000, total=  10.3s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.008, total=  12.2s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.043, total=  10.5s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.547, total=   9.5s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.546, total=   9.9s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.000, total=  10.2s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.551, total=  58.2s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.549, total=  57.4s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.551, total=  57.7s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.551, total=  57.7s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=-1, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.549, total=  56.8s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.007, total=   9.3s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.534, total=   8.7s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.000, total=   9.1s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.001, total=   8.0s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.244, total=   8.4s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.007, total=   9.3s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.534, total=   9.0s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.000, total=   8.9s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.001, total=   7.9s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.244, total=   8.4s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.550, total=  35.3s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.551, total=  35.2s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.549, total=  35.2s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.548, total=  34.7s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.553, total=  34.9s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.000, total=   9.6s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.000, total=   8.1s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.001, total=   8.0s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.048, total=   8.0s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.421, total=   7.9s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.000, total=   9.4s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.000, total=   8.4s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.001, total=   8.0s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.048, total=   7.9s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.421, total=   8.1s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.552, total=  32.0s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.552, total=  31.6s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.549, total=  31.4s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.552, total=  31.4s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=10, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.553, total=  31.1s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.005, total=   8.8s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.000, total=   9.7s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.551, total=   9.1s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.003, total=   8.3s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.015, total=   7.7s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.005, total=   9.0s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.000, total=  10.0s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.551, total=   9.2s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.003, total=   8.4s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0, score=0.015, total=   7.9s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.555, total=  36.3s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.554, total=  36.0s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.554, total=  36.4s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.553, total=  36.2s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.0, reg_lambda=0.1, score=0.555, total=  35.4s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.103, total=   8.9s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.008, total=   8.9s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.000, total=   8.2s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.547, total=   7.6s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.499, total=  11.0s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.103, total=   8.8s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.008, total=   8.4s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.000, total=   8.0s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.547, total=   7.6s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0, score=0.499, total=  11.1s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.554, total=  31.6s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.555, total=  31.9s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.554, total=  31.5s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.554, total=  31.5s\n",
            "[CV] boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1 \n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[CV]  boosting=dart, learning_rate=0.5, max_depth=4, min_child_samples=30, n_jobs=1, reg_alpha=0.1, reg_lambda=0.1, score=0.555, total=  31.1s\n",
            "[Parallel(n_jobs=1)]: Done 480 out of 480 | elapsed: 101.4min finished\n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
              "                                      colsample_bytree=1.0,\n",
              "                                      importance_type='split',\n",
              "                                      learning_rate=0.1, max_depth=-1,\n",
              "                                      min_child_samples=20,\n",
              "                                      min_child_weight=0.001,\n",
              "                                      min_split_gain=0.0, n_estimators=100,\n",
              "                                      n_jobs=-1, num_leaves=31, objective=None,\n",
              "                                      random_state=None, reg_alpha=0.0,\n",
              "                                      reg_lambda=0.0, silent='warn',\n",
              "                                      subsample=1.0, subsample_for_bin=200000,\n",
              "                                      subsample_freq=0),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'boosting': ['gbdt', 'dart'],\n",
              "                         'learning_rate': [0.1, 0.5], 'max_depth': [-1, 4],\n",
              "                         'min_child_samples': [10, 30], 'n_jobs': [1],\n",
              "                         'reg_alpha': [0.0, 0.1], 'reg_lambda': [0, 0, 0.1]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=200)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적의 파라미터 찾기\n",
        "print(grid.best_params_)\n",
        "print(grid.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwNt2kcS7t7M",
        "outputId": "98234fa4-6e0c-43ec-c909-82414bf474d9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'boosting': 'dart', 'learning_rate': 0.1, 'max_depth': 4, 'min_child_samples': 30, 'n_jobs': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
            "0.5556081732836364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearchCV 사용으로 찾은 최적 파라미터\n",
        "params_3 = {'boosting': 'dart', \n",
        "            'learning_rate': 0.1, \n",
        "            'max_depth': 4, \n",
        "            'min_child_samples': 30, \n",
        "            'n_jobs': 1, \n",
        "            'reg_alpha': 0.1, \n",
        "            'reg_lambda': 0.1}\n",
        "\n",
        "\n",
        "model_3 = lgb.train(params_3, \n",
        "                    train_ds, \n",
        "                    num_boost_round=500, # 부스팅 수\n",
        "                    valid_sets=[train_ds, test_ds ],\n",
        "                    early_stopping_rounds=100, # 조기종료 설정\n",
        "                    verbose_eval=100)"
      ],
      "metadata": {
        "id": "OOffzANzeAWt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "788f1585-3053-419a-a949-3f805e5e4d77"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001615 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 632\n",
            "[LightGBM] [Info] Number of data points in the train set: 25347, number of used features: 316\n",
            "[LightGBM] [Info] Start training from score 4.880972\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[100]\ttraining's l2: 45.6577\tvalid_1's l2: 37.424\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[200]\ttraining's l2: 45.2707\tvalid_1's l2: 37.1598\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[300]\ttraining's l2: 45.1036\tvalid_1's l2: 37.0997\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[400]\ttraining's l2: 44.9842\tvalid_1's l2: 37.0677\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[500]\ttraining's l2: 44.9116\tvalid_1's l2: 37.0437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_3=model_3.predict(test_x)\n",
        "\n",
        "# rmes 식 지정\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "def rmse(y_pred, y_test):\n",
        "    return np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "rmse(test_y, pred_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40b672b-4f7f-4aac-d339-e0de91fd2ce9",
        "id": "N4xSMurNGB1x"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.086349958675941"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV 사용해서 여러 파라미터 조합을 해 보았지만 \n",
        "\n",
        "기존에 직접 파라미터를 입력해서 조정한 모델의 성능이 가장 좋은 것으로 확인된다. (model_2)"
      ],
      "metadata": {
        "id": "Q0A7oZHBHtQe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 결과 예측\n",
        "\n",
        "이제 실제 데이콘에서 제공한 테스트 데이터셋의 물류예측량을 확인해보겠다. \n",
        "\n",
        "먼제 테스트 데이터셋을 가공한다."
      ],
      "metadata": {
        "id": "CjECrFz1N1so"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submit=pd.concat([sample[['index']],pd.DataFrame(model_2 .predict(test_input),columns={'운송장_건수'})],axis=1)\n",
        "submit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "bNFZonXm_fSw",
        "outputId": "fc735c1c-0d66-48c5-e9de-3ab241675350"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-df90e773-71b9-4c3d-beba-a04c94eac787\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>운송장_건수</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>4.555737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4.001992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5.149797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>5.207789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.792291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7915</th>\n",
              "      <td>7915</td>\n",
              "      <td>4.386892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7916</th>\n",
              "      <td>7916</td>\n",
              "      <td>3.029003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7917</th>\n",
              "      <td>7917</td>\n",
              "      <td>4.012402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7918</th>\n",
              "      <td>7918</td>\n",
              "      <td>4.315659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7919</th>\n",
              "      <td>7919</td>\n",
              "      <td>3.615535</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7920 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df90e773-71b9-4c3d-beba-a04c94eac787')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df90e773-71b9-4c3d-beba-a04c94eac787 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df90e773-71b9-4c3d-beba-a04c94eac787');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      index    운송장_건수\n",
              "0         0  4.555737\n",
              "1         1  4.001992\n",
              "2         2  5.149797\n",
              "3         3  5.207789\n",
              "4         4  4.792291\n",
              "...     ...       ...\n",
              "7915   7915  4.386892\n",
              "7916   7916  3.029003\n",
              "7917   7917  4.012402\n",
              "7918   7918  4.315659\n",
              "7919   7919  3.615535\n",
              "\n",
              "[7920 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 저장\n",
        "submit.to_csv(path+'submit_result.csv',index=False)"
      ],
      "metadata": {
        "id": "QhbmtwTwJl91"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "< 최종결과 >\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "결과적으로 Dacon 사이트에서 테스트 데이터셋으로 RMSE 를 확인하였을 때  publice: 5.9492552829, private: 5.6387866466 의 성능을 보이는 것이 확인되었다."
      ],
      "metadata": {
        "id": "qgf-VUz5NN3g"
      }
    }
  ]
}